\section{Conclusions and Future Work}
\label{sec:conclusions}

Here we have presented a novel continuation method for the treatment of \glspl{mmop}. The Enhanced Directed Search (\gls{eds}), as we call our method, follows the ideas proposed by the original Directed Search (\gls{ds}) method \cite{directed_search}. Nevertheless, as indicated by its name, the \gls{eds} method has several improvements over the classical \gls{ds} method. Namely that the \gls{eds} method has a better, more reliable mechanism for determining critical points than the one in the \gls{ds} method (the $\delta$ threshold). Furthermore, the \gls{eds} method is capable of solving \glspl{mmop} through a strategy of rounding which, according the experiments conducted in this work, proved to be efficient and effective. In addition, the performance of the \gls{eds} method can be improved through the use of neighborhood information. 

The experiments conducted here also demonstrated that the \gls{eds} method performs better than its closest competitor, the \gls{dzz} method. A major difference between these two methods is that the former can be used for problems where $k > 2$. This provides clear evidence that the \gls{eds} can be applied to problems that can be solved by the \gls{dzz} and obtain as good results as it and furthermore, that the \gls{eds} method can be applied for solving problems that are impossible to solve for the \gls{dzz} method.

For future work it is intended to test on some other corrector techniques as well as a detailed analysis of convergence of the \gls{eds} method. A version of the \gls{eds} method that does not rely so much on problem dependent parameters is also desirable. The treatment of constrained problems is equally interesting. For the latter task some ideas are being currently explored, nevertheless, they are left out of the scope of this paper. We believe this task to be key for the success of the method in real-world applications.

Another interesting topic that arises from the development of the \gls{eds} method is that of parallelization. Given the way predictors and correctors are computed (Sections \ref{sec:predictor} and \ref{sec:corrector}) and thanks to the successfully implementation of the data structure proposed in \cite{pareto_tracer} we believe that parallelizing the computation of predictors and correctors is an attainable task. A parallel implementation of the \gls{eds} method should boost the speed and the overall performance of it, allowing it to deal in a more efficient way with problems whose function evaluation time is high.

Finally, we would like to stress that the \gls{eds} method (as all continuation methods) is of local nature. It is thus conceivable to hybridize the algorithm with a global strategy such as specialized \glspl{moea} in order to obtain a fast and reliable procedure. Furthermore, the use of neighboring information can be exploited more with the use of memetic strategies where the solutions computed by the \gls{moea} can be reused.

All in all, we strongly believe that the \gls{eds} method has some serious potential for real-world applications, nevertheless, further experiments and some additional features are needed in order to guarantee its success when dealing with real-world problems.