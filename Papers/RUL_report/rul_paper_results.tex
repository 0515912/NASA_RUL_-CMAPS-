\section{Experimental Results}
\label{sec:results}

In this chapter we present the numerical results obtained with the \gls{eds} method on unconstrained, box constrained and mixed-integer problems up to three objectives. The \gls{eds} method is compared against the \gls{dzz} method \cite{zigzag_discrete} and \gls{nsga2} algorithm \cite{nsga2}. We chose to compare against the \gls{dzz} method since it is a state-of-the-art algorithm in the field of mixed-integer multi-objective optimization. As for \gls{nsga2}, it is one of the most widely used algorithms for solving \glspl{mop}. Although we are aware that there is no ``fair'' comparison between \gls{nsga2} and \gls{eds} algorithms given that the former is a \emph{global} optimization method while the latter is of \emph{local} nature, we consider this comparison necessary in order to show the quality of the solutions obtained by our method. 

\subsection{General Setting}

We will now describe the general setting of our experiments. \gls{dzz} version used in this experiment was provided by Dr. Honggang Wang from Rutgers University, being this the better version up to date. \gls{nsga2} algorithm was downloaded from \cite{ngpm_code} which is version of \gls{nsga2} with support for mixed-integer problems \cite{ngpm}. For each of the problems a similar number of solutions was computed by each algorithm in order to make a fairer comparison. For the case of \gls{nsga2} a budget of approximately four times the number of function evaluations spent by \gls{eds} was assigned as stopping criteria. In the case of the \gls{dzz} method the First Pareto Solution (\gls{fps}) is given in order to restrict the comparison to the continuation method (Zig and Zag steps). For each of the test problems the three algorithms were run ten times and the better solution of each of them is used for the comparison.

For each of the solved problems a table summarizing key information for the comparison is presented. We put special emphasis on the number of function evaluations used by each algorithm displayed in the \emph{Feval} column and on the value of the $\bigtriangleup_2$ and $\bigtriangleup_3$ performance indicators \cite{delta_p}. A ratio of function evaluations per solution is shown on the column \emph{Funeval/sol}.

Finally, for the computation of the $\bigtriangleup_p$ performance indicator the real Pareto front was used in all of the cases except for the last function presented in this section, where the Pareto front was approximated by performing ten \emph{long} runs of the \gls{nsga2} algorithm and keeping the non-dominated points among all of the runs.

\subsection{DTLZ2 Continuous Problem}

We now consider the tri-objective problem DTLZ1\cite{evolutionary_algorithms} which is a multimodal function with box constraints. It is defined as follows:

\begin{eqnarray}
& f_1(x) = & \frac{1}{2}x_1 x_2 (1 + g(x)) \nonumber \\
& f_2(x) = & \frac{1}{2}x_1 (1 - x_2) (1 + g(x)) \nonumber \\
& f_3(x) = & \frac{1}{2}(1 - x_1) (1 + g(x))\\
& g(x) = & 100(10 + \sum_{i = 3}^n(x_i - 0.5)^2 - cos(20 \pi (x_i - 0.5)))\nonumber \\
& s.t. & 0 \leq x_i \leq 1, \quad i = 1,\ldots,n. \nonumber
\end{eqnarray}

For this example we set $n = 3$. As in the previous example \gls{dzz} is not applicable to this function, hence the comparison is only made between the \gls{eds} method and \gls{nsga2} algorithm. Results are shown in Table \ref{table:results_dtlz1}.

\begin{table}[!htb]
\centering
\begin{tabular}{| l  r  r  r  r  r  r  r |}
	\hline
	Algorithm & Int. Var. & Real Var. & Sols & Feval & $\triangle_2$ & $\triangle_3$ & Funeval/Sol\\  
  	\hline
  	EDS & 0 & 3  & 870 & 5991  & 0.0085 & 0.0082 & 7\\
  	NSGA-II & 0 & 3 & 900 & 23400  & 0.0093 & 0.0094 & 26\\
  	\hline
\end{tabular}
\caption{Summarized results for DTLZ1 function}
\label{table:results_dtlz1}
\end{table}

Once again, as indicated by the results in Table \ref{table:results_dtlz1} the \gls{eds} method performs better than the \gls{nsga2} algorithm, despite the latter uses about four times more function evaluations. Figure \ref{Fig:dtlz1_function_pf} shows the Pareto fronts computed by both methods.

\begin{comment}

 \begin{figure}[H]
   \centering
	\hspace*{-0.5in}
    \subfloat[EDS]{%
      \includegraphics[width = 60mm, height = 60mm]{img/fronts/pf_dtlz1_eds.png}
    }
    \subfloat[NSGA-II]{%
      \includegraphics[width = 60mm, height = 60mm]{img/fronts/pf_dtlz1_ga.png}
    }
    \caption{Pareto fronts of the DTLZ2 function computed by the different methods}
    \label{Fig:dtlz1_function_pf}
\end{figure}

\end{comment}

\subsection{ZDT1 Integer Function}

Now we test on a discretized version of the ZDT1 function which proposed by Dr. Wang for his experiments with the \gls{dzz} method on \cite{zigzag_discrete}. We will use the same setting as the one proposed in \cite{zigzag_discrete}, the function is defined in the following way:

\begin{eqnarray}
& f_1(x) = & \frac{x_1}{100} \nonumber \\
& f_2(x) = & g(x) \left(1 - \sqrt{\frac{f_1(x)}{g(x)}} \right) \\
& g(x) = & 1 + 9 \cdot \frac{x_2 - x_1}{100}^2 \nonumber \\
& s.t. & 0 \leq x_i \leq 100, \quad i = 1, \ldots, n. \nonumber
\end{eqnarray}

where $n = 2$ and $x \in \mathbb{Z}^n$. This function has a convex Pareto front, the solution set is contained within the domain $[0,100] \times [0,100]$. The results for the three methods are displayed in Table \ref{table:results_zdt1Integer_function}.

\begin{table}[!htb]
\centering
\begin{tabular}{| l  r  r  r  r  r  r  r |}
	\hline
	Algorithm & Int. Var. & Real Var. & Sols & Feval & $\triangle_2$ & $\triangle_3$ & Funeval/Sol\\  
  	\hline
  	EDS & 0 & 2  & 122 & 268 & 0.0168 & 0.0324 & 2\\
  	NSGA-II & 0 & 2 & 120 & 1080  & 0.0165 & 0.0295 & 9\\
  	DZZ & 0 & 2 & 100 & 400 & 0.0100 & 0.0214 & 4\\
  	\hline
\end{tabular}
\caption{Summarized results for ZDT1 Integer function}
\label{table:results_zdt1Integer_function}
\end{table}

It can be observed by the results presented in Table \ref{table:results_zdt1Integer_function} that the three methods computed good solutions, being the $\bigtriangleup_p$ values of the three quite similar. Nevertheless, it can also be observed that the \gls{eds} method was the most efficient of the three methods, using up to four times less function evaluations than \gls{nsga2} and half the number of function evaluations of the \gls{dzz} method. The Pareto fronts obtained by each method are shown in Figure \ref{Fig:zdt1Integer_function_pf}.

\begin{comment}

\begin{figure}[H]
   \centering
	\hspace*{-0.5in}
    \subfloat[EDS]{%
      \includegraphics[width = 50mm, height = 50mm]{img/fronts/pf_ijocCase1_eds.png}
    }
    \subfloat[NSGA-II]{%
      \includegraphics[width = 50mm, height = 50mm]{img/fronts/pf_ijocCase1_ga.png}
    }
    \subfloat[DZZ]{%
      \includegraphics[width = 50mm, height = 50mm]{img/fronts/pf_ijocCase1_dzz.png}
    }
    \caption{Pareto fronts of the ZDT1 integer function computed by the different methods}
    \label{Fig:zdt1Integer_function_pf}
\end{figure}

\end{comment}

\subsection{ZDT2 Integer Function}

Our next test is conducted on a discretized version of the ZDT2 function proposed in \cite{zigzag_discrete}. Once again we will use the same setting as the one proposed in \cite{zigzag_discrete}. The function is defined in the as follows:

\begin{eqnarray}
& f_1(x) = & \frac{x_1}{100} \nonumber \\
& f_2(x) = & g(x) \cdot \left(1 - \sqrt{\frac{f_1(x)}{g(x)}} \right)^2 \\
& g(x) = & 1 + \left(\frac{x_2 }{100} \right)^\frac{1}{4} \nonumber \\
& s.t. & 0 \leq x_i \leq 100, \quad i = 1, \ldots, n. \nonumber
\end{eqnarray}

where $n = 2$ and $x \in \mathbb{Z}^n$. This function has a concave Pareto front, the solution set is contained within the square $[0,100] \times [0,100]$. The results for the three methods are displayed in Table \ref{table:results_zdt2Integer_function}.

\begin{table}[!htb]
\centering
\begin{tabular}{| l  r  r  r  r  r  r  r |}
	\hline
	Algorithm & Int. Var. & Real Var. & Sols & Feval & $\triangle_2$ & $\triangle_3$ & Funeval/Sol\\  
  	\hline
  	EDS & 0 & 2  & 24 & 49 & 0.044 & 0.065 & 2\\
  	NSGA-II & 0 & 2 & 20 & 200  & 0.15 & 0.21 & 10\\
  	DZZ & 0 & 2 & 26 & 106 & 0.031 & 0.051 & 4\\
  	\hline
\end{tabular}
\caption{Summarized results for ZDT2 Integer function}
\label{table:results_zdt2Integer_function}
\end{table}

The results presented in Table \ref{table:results_zdt2Integer_function} demonstrate, once again, that the results obtained by the \gls{eds} and the \gls{dzz} methods are similar with respect to the $\bigtriangleup_p$ indicator. Nevertheless, the \gls{eds} method uses half of the function evaluations that the \gls{dzz} method uses. \gls{nsga2} is again outperformed by both methods. The Pareto fronts obtained by each method are shown in Figure \ref{Fig:zdt2Integer_function_pf}.

\begin{comment}

\begin{figure}[H]
	\centering
	\hspace*{-0.5in}
    \subfloat[EDS]{%
      \includegraphics[width = 50mm, height = 50mm]{img/fronts/pf_ijocCase2_eds.png}
    }
    \subfloat[NSGA-II]{%
      \includegraphics[width = 50mm, height = 50mm]{img/fronts/pf_ijocCase2_ga.png}
    }
    \subfloat[DZZ]{%
      \includegraphics[width = 50mm, height = 50mm]{img/fronts/pf_ijocCase2_dzz.png}
    }
    \caption{Pareto fronts of the ZDT2 Integer function computed by the different methods}
    \label{Fig:zdt2Integer_function_pf}
\end{figure}

\end{comment}

\subsection{A Mixed-Integer Model}

Finally, in this section we present one mixed-integer problem solved by the \gls{eds} method. A comparison between \gls{eds} and \gls{nsga2} algorithms is presented. No comparison against the \gls{dzz} method is possible since this is a tri-objective. Its definition is as follows:

\begin{eqnarray}
f_1(x) = || x - a_1 ||_2^2 \nonumber \\
f_2(x) = || x - a_2 ||_2^2 \\
f_3(x) = || x - a_3 ||_2^2,\nonumber
\label{eq:f3d_mip_fun}
\end{eqnarray}

for $a_1 = (20, \ldots, 20) \in \mathbb{R}^d$, $a_2 = -a_1$ and $a_3 = (\underbrace{20, \ldots, 20}_\text{m times}, \underbrace{-20, \ldots, -20}_\text{n-m times}) \in \mathbb{R}^d$ for $m = ceil(d/2)$, $d = d_1 + d_2$, $d_1 = 3$, $d_2 = 2$, and $x \in \mathbb{R}^{d_1} \times \mathbb{Z}^{d_2}$. This function has a convex Pareto front. Since comparison against \gls{dzz} is possible only the comparison against \gls{nsga2} is presented. The results of such comparison are shown in Table \ref{table:results_binh3mip}.

\begin{table}[!htb]
\centering
\begin{tabular}{| l  r  r  r  r  r  r  r |}
	\hline
	Algorithm & Int. Var. & Real Var. & Sols & Feval & $\triangle_2$ & $\triangle_3$ & Funeval/Sol\\  
  	\hline
  	EDS & 2 & 3  & 434 & 6995  & 135.88 & 150.74 & 9\\
  	NSGA-II & 2 & 3 & 450 & 27000  & 136.69 & 145.36 & 38\\
  	\hline
\end{tabular}
\caption{Summarized results for Binh3 MI function}
\label{table:results_binh3mip}
\end{table}

As the data in Table \ref{table:results_binh3mip} shows, both methods, the \gls{eds} method and the \gls{nsga2} algorithm deliver similar quality solutions. Nevertheless it is important to note that the \gls{eds} method used four times less function evaluations than \gls{nsga2} to reach the same quality of solutions. The high values on the $\bigtriangleup_p$ values of each method are due to the scale of the objective space, going up to 8000 units in one of the objective functions. The fronts computed by both methods are shown in Figure \ref{Fig:binh3mip_function_pf}.

\begin{comment}

 \begin{figure}[H]
 	\centering
	\hspace*{-0.5in}
    \subfloat[EDS]{%
      \includegraphics[width = 60mm, height = 60mm]{img/fronts/pf_f3dmip_eds.png}
    }
    \subfloat[NSGA-II]{%
      \includegraphics[width = 60mm, height = 60mm]{img/fronts/pf_f3dmip_ga.png}
    }
    \caption{Pareto fronts of the Binh3 MI function computed by the different methods}
    \label{Fig:binh3mip_function_pf}
\end{figure}

\end{comment}

It can be observed in the above pictures that the \gls{eds} method had some difficulties computing the narrow parts of the Pareto front, nevertheless, it can also be observed that the solutions of the \gls{eds} method are more evenly distributed than those computed by the \gls{nsga2}. This explains why the $\bigtriangleup_p$ values of both methods are similar. The higher values of the $\bigtriangleup_3$ indicator on the \gls{eds} method are due to the fact that as $p$ increases in the $p$-norm, outliers are penalized more (see \cite{delta_p}).