{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Test notebook for the DataHandlers. Test the CMAPSS DataHandler\n",
    "\n",
    "First we import the necessary packages and create the global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlaredorazo/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_handler_CMAPS import CMAPSDataHandler\n",
    "from tunable_model import SequenceTunableModelRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D, LSTM\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "import CMAPSAuxFunctions\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define different types of Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2_lambda_regularization = 0.4\n",
    "\n",
    "def RULmodel_SN_5(input_shape):\n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), \n",
    "                    name='fc1'))\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), \n",
    "                    name='fc2'))\n",
    "    model.add(Dense(1, activation='linear', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(0.1), name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def test_model(input_shape):\n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', \n",
    "                    kernel_initializer=keras.initializers.glorot_normal(seed=0), \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), name='fc1'))\n",
    "    model.add(Dense(1, activation='linear', \n",
    "                    kernel_initializer=keras.initializers.glorot_normal(seed=0), \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), name='out'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Data Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Selected as per CNN paper\n",
    "features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "selected_features = list(features[i] for i in selected_indices-1)\n",
    "data_folder = '../CMAPSSData'\n",
    "\n",
    "window_size = 30\n",
    "window_stride = 1\n",
    "max_rul = 125\n",
    "\n",
    "dHandler_cmaps = CMAPSDataHandler(data_folder, 1, selected_features, max_rul, window_size, window_stride)\n",
    "#dHandler_cmaps.load_data(verbose=1, cross_validation_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tunable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "#min_max_scaler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_compiled_model(shape, model_type='ann'):\n",
    "    \n",
    "    K.clear_session()  #Clear the previous tensorflow graph\n",
    "    \n",
    "    #To test the model without randomness\n",
    "\n",
    "    \n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0,beta_1=0.5)\n",
    "    \n",
    "    lossFunction = \"mean_squared_error\"\n",
    "    metrics = [\"mse\"]\n",
    "    model = None\n",
    "\n",
    "    #Create and compile the models\n",
    "    model = RULmodel_SN_5(shape)\n",
    "    model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = len(selected_features)\n",
    "\n",
    "shape = len(selected_features)*window_size\n",
    "model = get_compiled_model(shape, model_type='ann')\n",
    "tModel = SequenceTunableModelRegression('ModelRUL_SN_1', model, lib_type='keras', data_handler=dHandler_cmaps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tModel.data_handler.sequence_length = 24\n",
    "#tModel.data_handler.sequence_length = maxWindowSize[datasetNumber]\n",
    "tModel.data_handler.sequence_stride = 1\n",
    "tModel.data_handler.max_rul = 129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0.2\n",
      "Loading data from file and computing dataframes\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(14738, 336)\n",
      "(14738, 1)\n",
      "Cross-Validation data (X, y)\n",
      "(20, 336)\n",
      "(20, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.44295302 -0.32685422 -0.37676609 ... -0.63636364  0.03875969\n",
      "   0.39314799]\n",
      " [-0.02684564 -0.18158568 -0.35753532 ... -0.63636364  0.17829457\n",
      "   0.42151081]\n",
      " [-0.42281879 -0.50332481 -0.26020408 ... -0.63636364  0.34883721\n",
      "   0.07413648]\n",
      " [-0.13422819 -0.53554987 -0.46978022 ... -0.45454545  0.28682171\n",
      "   0.35551811]\n",
      " [-0.48993289 -0.46598465 -0.53689168 ... -0.45454545  0.19379845\n",
      "   0.44622297]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Cross-Validation data (X, y)\n",
      "[[ 0.00671141 -0.11202046 -0.20800628 ... -0.63636364 -0.1627907\n",
      "   0.25414209]\n",
      " [-0.19463087 -0.2629156  -0.31475667 ... -0.45454545  0.25581395\n",
      "   0.43583263]\n",
      " [ 0.20805369  0.18772379  0.24097331 ... -0.09090909 -0.08527132\n",
      "   0.05784892]\n",
      " [ 0.09395973  0.07774936  0.19505495 ... -0.09090909  0.06976744\n",
      "  -0.028082  ]\n",
      " [ 0.12751678 -0.08286445  0.04277865 ... -0.27272727  0.11627907\n",
      "   0.04689694]]\n",
      "[[136.]\n",
      " [203.]\n",
      " [118.]\n",
      " [ 37.]\n",
      " [111.]]\n",
      "Testing data (X, y)\n",
      "[[-0.10738255 -0.49616368 -0.26844584 ... -0.27272727  0.03875969\n",
      "   0.29458017]\n",
      " [-0.12751678 -0.18158568  0.02197802 ... -0.63636364  0.03875969\n",
      "   0.0322943 ]\n",
      " [ 0.06711409 -0.05473146  0.13814757 ...  0.09090909  0.2248062\n",
      "   0.06655434]\n",
      " [-0.1409396   0.15294118  0.00353218 ...  0.09090909 -0.31782946\n",
      "   0.02190396]\n",
      " [-0.01342282  0.03273657  0.2032967  ... -0.09090909 -0.05426357\n",
      "   0.45324347]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n"
     ]
    }
   ],
   "source": [
    "#Load Non sequenced data (unroll sequence into a single feature vector)\n",
    "\n",
    "tModel.data_handler.data_scaler = None\n",
    "tModel.data_scaler = min_max_scaler\n",
    "\n",
    "tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0.2)\n",
    "#tModel.data_handler.print_data()\n",
    "tModel.print_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model and test some Tunable Model functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with cv\n",
      "Train on 14738 samples, validate on 20 samples\n",
      "Epoch 1/200\n",
      "14738/14738 [==============================] - 0s 28us/step - loss: 8321.9466 - mean_squared_error: 8298.5884 - val_loss: 12782.1387 - val_mean_squared_error: 12757.7080\n",
      "Epoch 2/200\n",
      "14738/14738 [==============================] - 0s 10us/step - loss: 6188.5992 - mean_squared_error: 6161.5292 - val_loss: 8316.6016 - val_mean_squared_error: 8285.7373\n",
      "Epoch 3/200\n",
      "14738/14738 [==============================] - 0s 10us/step - loss: 2927.5910 - mean_squared_error: 2892.2183 - val_loss: 3852.5461 - val_mean_squared_error: 3812.7407\n",
      "Epoch 4/200\n",
      "14738/14738 [==============================] - 0s 8us/step - loss: 1357.0860 - mean_squared_error: 1315.0553 - val_loss: 2112.1934 - val_mean_squared_error: 2068.5957\n",
      "Epoch 5/200\n",
      "14738/14738 [==============================] - 0s 8us/step - loss: 858.9078 - mean_squared_error: 814.5180 - val_loss: 1490.2571 - val_mean_squared_error: 1445.3029\n",
      "Epoch 6/200\n",
      "14738/14738 [==============================] - 0s 10us/step - loss: 665.4186 - mean_squared_error: 620.1211 - val_loss: 1272.3138 - val_mean_squared_error: 1226.7455\n",
      "Epoch 7/200\n",
      "14738/14738 [==============================] - 0s 10us/step - loss: 593.0174 - mean_squared_error: 547.2855 - val_loss: 1189.9064 - val_mean_squared_error: 1143.9545\n",
      "Epoch 8/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 552.3513 - mean_squared_error: 506.1781 - val_loss: 1161.2405 - val_mean_squared_error: 1114.7830\n",
      "Epoch 9/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 522.1270 - mean_squared_error: 475.2982 - val_loss: 1139.4755 - val_mean_squared_error: 1092.1003\n",
      "Epoch 10/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 496.5594 - mean_squared_error: 448.5822 - val_loss: 1112.4087 - val_mean_squared_error: 1063.6479\n",
      "Epoch 11/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 473.8785 - mean_squared_error: 424.3520 - val_loss: 1096.9213 - val_mean_squared_error: 1046.3756\n",
      "Epoch 12/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 455.3992 - mean_squared_error: 404.0216 - val_loss: 1119.4004 - val_mean_squared_error: 1067.1642\n",
      "Epoch 13/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 439.6885 - mean_squared_error: 386.6319 - val_loss: 1117.6112 - val_mean_squared_error: 1063.7395\n",
      "Epoch 14/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 425.0479 - mean_squared_error: 370.4726 - val_loss: 1098.4454 - val_mean_squared_error: 1043.1361\n",
      "Epoch 15/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 412.5407 - mean_squared_error: 356.5813 - val_loss: 1125.0251 - val_mean_squared_error: 1068.3346\n",
      "Epoch 16/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 401.1204 - mean_squared_error: 343.8332 - val_loss: 1075.7051 - val_mean_squared_error: 1017.7155\n",
      "Epoch 17/200\n",
      "14738/14738 [==============================] - 0s 8us/step - loss: 390.3976 - mean_squared_error: 331.8248 - val_loss: 1130.8551 - val_mean_squared_error: 1071.7113\n",
      "Epoch 18/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 380.3667 - mean_squared_error: 320.6809 - val_loss: 1134.4519 - val_mean_squared_error: 1074.1842\n",
      "Epoch 19/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 371.5648 - mean_squared_error: 310.8005 - val_loss: 1093.4779 - val_mean_squared_error: 1032.2010\n",
      "Epoch 20/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 363.6492 - mean_squared_error: 301.9780 - val_loss: 1167.9797 - val_mean_squared_error: 1105.8871\n",
      "Epoch 21/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 355.7806 - mean_squared_error: 293.3243 - val_loss: 1120.0466 - val_mean_squared_error: 1057.2487\n",
      "Epoch 22/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 349.1659 - mean_squared_error: 286.1371 - val_loss: 1105.6289 - val_mean_squared_error: 1042.2052\n",
      "Epoch 23/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 343.0888 - mean_squared_error: 279.4946 - val_loss: 1131.1578 - val_mean_squared_error: 1067.3711\n",
      "Epoch 24/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 338.0250 - mean_squared_error: 274.0528 - val_loss: 1148.9207 - val_mean_squared_error: 1084.8586\n",
      "Epoch 25/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 333.1908 - mean_squared_error: 269.1015 - val_loss: 1174.2551 - val_mean_squared_error: 1110.1372\n",
      "Epoch 26/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 329.3297 - mean_squared_error: 265.3475 - val_loss: 1120.1526 - val_mean_squared_error: 1056.3271\n",
      "Epoch 27/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 326.8439 - mean_squared_error: 263.1789 - val_loss: 1094.7274 - val_mean_squared_error: 1031.2279\n",
      "Epoch 28/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 324.4892 - mean_squared_error: 261.2523 - val_loss: 1145.1621 - val_mean_squared_error: 1082.0779\n",
      "Epoch 29/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 321.7791 - mean_squared_error: 258.9830 - val_loss: 1159.6257 - val_mean_squared_error: 1097.1173\n",
      "Epoch 30/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 319.8743 - mean_squared_error: 257.5966 - val_loss: 1141.3276 - val_mean_squared_error: 1079.3540\n",
      "Epoch 31/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 317.3006 - mean_squared_error: 255.6055 - val_loss: 1124.1461 - val_mean_squared_error: 1062.7732\n",
      "Epoch 32/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 315.4774 - mean_squared_error: 254.3672 - val_loss: 1153.2832 - val_mean_squared_error: 1092.5038\n",
      "Epoch 33/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 313.8570 - mean_squared_error: 253.3471 - val_loss: 1137.0919 - val_mean_squared_error: 1076.9080\n",
      "Epoch 34/200\n",
      "14738/14738 [==============================] - 0s 9us/step - loss: 311.4896 - mean_squared_error: 251.6305 - val_loss: 1198.0272 - val_mean_squared_error: 1138.4415\n",
      "Epoch 35/200\n",
      "14738/14738 [==============================] - 0s 9us/step - loss: 310.8676 - mean_squared_error: 251.5921 - val_loss: 1134.8037 - val_mean_squared_error: 1075.8558\n",
      "Epoch 36/200\n",
      "14738/14738 [==============================] - 0s 9us/step - loss: 308.6970 - mean_squared_error: 250.0310 - val_loss: 1166.7327 - val_mean_squared_error: 1108.4109\n",
      "Epoch 37/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 307.0768 - mean_squared_error: 249.0232 - val_loss: 1198.7876 - val_mean_squared_error: 1141.0363\n",
      "Epoch 38/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 305.5599 - mean_squared_error: 248.0341 - val_loss: 1127.5596 - val_mean_squared_error: 1070.2979\n",
      "Epoch 39/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 304.2657 - mean_squared_error: 247.2944 - val_loss: 1119.1801 - val_mean_squared_error: 1062.4675\n",
      "Epoch 40/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 302.2434 - mean_squared_error: 245.8167 - val_loss: 1155.3577 - val_mean_squared_error: 1099.2336\n",
      "Epoch 41/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 301.0343 - mean_squared_error: 245.1921 - val_loss: 1176.5999 - val_mean_squared_error: 1121.0315\n",
      "Epoch 42/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 299.6455 - mean_squared_error: 244.3508 - val_loss: 1206.0120 - val_mean_squared_error: 1151.0353\n",
      "Epoch 43/200\n",
      "14738/14738 [==============================] - 0s 8us/step - loss: 298.2310 - mean_squared_error: 243.5148 - val_loss: 1152.0134 - val_mean_squared_error: 1097.5559\n",
      "Epoch 44/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 296.8815 - mean_squared_error: 242.6969 - val_loss: 1189.2749 - val_mean_squared_error: 1135.4182\n",
      "Epoch 45/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 296.0155 - mean_squared_error: 242.4169 - val_loss: 1152.0667 - val_mean_squared_error: 1098.7010\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14738/14738 [==============================] - 0s 7us/step - loss: 295.1219 - mean_squared_error: 242.0289 - val_loss: 1187.1406 - val_mean_squared_error: 1134.3561\n",
      "Epoch 47/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 293.6972 - mean_squared_error: 241.1168 - val_loss: 1187.9762 - val_mean_squared_error: 1135.6321\n",
      "Epoch 48/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 292.3437 - mean_squared_error: 240.2298 - val_loss: 1135.8352 - val_mean_squared_error: 1083.9812\n",
      "Epoch 49/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 291.3738 - mean_squared_error: 239.7755 - val_loss: 1140.5223 - val_mean_squared_error: 1089.1677\n",
      "Epoch 50/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 290.1068 - mean_squared_error: 239.0175 - val_loss: 1147.3268 - val_mean_squared_error: 1096.5081\n",
      "Epoch 51/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 289.1501 - mean_squared_error: 238.5380 - val_loss: 1214.6451 - val_mean_squared_error: 1164.3049\n",
      "Epoch 52/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 287.9573 - mean_squared_error: 237.7891 - val_loss: 1217.8735 - val_mean_squared_error: 1168.0044\n",
      "Epoch 53/200\n",
      "14738/14738 [==============================] - 0s 8us/step - loss: 287.1248 - mean_squared_error: 237.4457 - val_loss: 1205.4852 - val_mean_squared_error: 1156.0580\n",
      "Epoch 54/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 286.8396 - mean_squared_error: 237.5793 - val_loss: 1153.5532 - val_mean_squared_error: 1104.5166\n",
      "Epoch 55/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 285.9094 - mean_squared_error: 237.1133 - val_loss: 1134.9070 - val_mean_squared_error: 1086.2900\n",
      "Epoch 56/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 284.3618 - mean_squared_error: 235.9556 - val_loss: 1140.3672 - val_mean_squared_error: 1092.1698\n",
      "Epoch 57/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 283.2365 - mean_squared_error: 235.2709 - val_loss: 1163.2037 - val_mean_squared_error: 1115.4242\n",
      "Epoch 58/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 282.9747 - mean_squared_error: 235.4057 - val_loss: 1187.8976 - val_mean_squared_error: 1140.5280\n",
      "Epoch 59/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 281.9295 - mean_squared_error: 234.7506 - val_loss: 1125.6228 - val_mean_squared_error: 1078.6277\n",
      "Epoch 60/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 281.4076 - mean_squared_error: 234.6337 - val_loss: 1116.0271 - val_mean_squared_error: 1069.3678\n",
      "Epoch 61/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 280.6338 - mean_squared_error: 234.2074 - val_loss: 1178.2274 - val_mean_squared_error: 1132.0490\n",
      "Epoch 62/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 280.6436 - mean_squared_error: 234.5813 - val_loss: 1170.3619 - val_mean_squared_error: 1124.5105\n",
      "Epoch 63/200\n",
      "14738/14738 [==============================] - 0s 8us/step - loss: 278.8078 - mean_squared_error: 233.0715 - val_loss: 1237.2192 - val_mean_squared_error: 1191.7340\n",
      "Epoch 64/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 278.0449 - mean_squared_error: 232.6890 - val_loss: 1146.8907 - val_mean_squared_error: 1101.6692\n",
      "Epoch 65/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 277.1047 - mean_squared_error: 232.0686 - val_loss: 1155.6016 - val_mean_squared_error: 1110.7112\n",
      "Epoch 66/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 277.3454 - mean_squared_error: 232.6198 - val_loss: 1153.8909 - val_mean_squared_error: 1109.3610\n",
      "Epoch 67/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 275.8453 - mean_squared_error: 231.4611 - val_loss: 1191.5096 - val_mean_squared_error: 1147.2924\n",
      "Epoch 68/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 275.3220 - mean_squared_error: 231.2400 - val_loss: 1126.9463 - val_mean_squared_error: 1082.9888\n",
      "Epoch 69/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 274.7973 - mean_squared_error: 231.0128 - val_loss: 1117.9580 - val_mean_squared_error: 1074.2859\n",
      "Epoch 70/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 274.1205 - mean_squared_error: 230.6245 - val_loss: 1119.8159 - val_mean_squared_error: 1076.4484\n",
      "Epoch 71/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 273.3479 - mean_squared_error: 230.1257 - val_loss: 1138.5724 - val_mean_squared_error: 1095.5360\n",
      "Epoch 72/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 272.6494 - mean_squared_error: 229.7560 - val_loss: 1127.2593 - val_mean_squared_error: 1084.4415\n",
      "Epoch 73/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 272.2177 - mean_squared_error: 229.5681 - val_loss: 1079.8158 - val_mean_squared_error: 1037.2756\n",
      "Epoch 74/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 272.1322 - mean_squared_error: 229.7620 - val_loss: 1127.3533 - val_mean_squared_error: 1085.0674\n",
      "Epoch 75/200\n",
      "14738/14738 [==============================] - ETA: 0s - loss: 277.1799 - mean_squared_error: 234.99 - 0s 6us/step - loss: 271.8158 - mean_squared_error: 229.6900 - val_loss: 1167.0029 - val_mean_squared_error: 1125.0109\n",
      "Epoch 76/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 270.2214 - mean_squared_error: 228.3366 - val_loss: 1275.5692 - val_mean_squared_error: 1233.8848\n",
      "Epoch 77/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 270.6308 - mean_squared_error: 229.0175 - val_loss: 1202.6375 - val_mean_squared_error: 1161.1343\n",
      "Epoch 78/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 269.8574 - mean_squared_error: 228.4318 - val_loss: 1108.2280 - val_mean_squared_error: 1066.8660\n",
      "Epoch 79/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 269.7238 - mean_squared_error: 228.5420 - val_loss: 1128.3007 - val_mean_squared_error: 1087.1985\n",
      "Epoch 80/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 268.4594 - mean_squared_error: 227.5312 - val_loss: 1127.4591 - val_mean_squared_error: 1086.6282\n",
      "Epoch 81/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 268.0378 - mean_squared_error: 227.3411 - val_loss: 1108.9680 - val_mean_squared_error: 1068.3162\n",
      "Epoch 82/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 267.9398 - mean_squared_error: 227.4604 - val_loss: 1243.2737 - val_mean_squared_error: 1202.9398\n",
      "Epoch 83/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 266.4728 - mean_squared_error: 226.2009 - val_loss: 1163.5015 - val_mean_squared_error: 1123.2894\n",
      "Epoch 84/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 266.9033 - mean_squared_error: 226.8127 - val_loss: 1180.6500 - val_mean_squared_error: 1140.6555\n",
      "Epoch 85/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 266.0829 - mean_squared_error: 226.2079 - val_loss: 1205.0538 - val_mean_squared_error: 1165.2366\n",
      "Epoch 86/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 266.0395 - mean_squared_error: 226.3030 - val_loss: 1222.2649 - val_mean_squared_error: 1182.6696\n",
      "Epoch 87/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 265.4719 - mean_squared_error: 225.9383 - val_loss: 1224.4270 - val_mean_squared_error: 1184.9973\n",
      "Epoch 88/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 265.1599 - mean_squared_error: 225.8228 - val_loss: 1178.8169 - val_mean_squared_error: 1139.5894\n",
      "Epoch 89/200\n",
      "14738/14738 [==============================] - ETA: 0s - loss: 262.1535 - mean_squared_error: 222.95 - 0s 6us/step - loss: 264.6990 - mean_squared_error: 225.5068 - val_loss: 1128.4076 - val_mean_squared_error: 1089.2550\n",
      "Epoch 90/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 264.3182 - mean_squared_error: 225.3219 - val_loss: 1163.4763 - val_mean_squared_error: 1124.5372\n",
      "Epoch 91/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14738/14738 [==============================] - 0s 6us/step - loss: 263.7958 - mean_squared_error: 224.9637 - val_loss: 1189.1454 - val_mean_squared_error: 1150.3683\n",
      "Epoch 92/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 263.3469 - mean_squared_error: 224.6519 - val_loss: 1186.2175 - val_mean_squared_error: 1147.6581\n",
      "Epoch 93/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 263.6447 - mean_squared_error: 225.1080 - val_loss: 1240.1346 - val_mean_squared_error: 1201.6952\n",
      "Epoch 94/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 262.8495 - mean_squared_error: 224.4819 - val_loss: 1181.5387 - val_mean_squared_error: 1143.2272\n",
      "Epoch 95/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 261.7715 - mean_squared_error: 223.5234 - val_loss: 1140.5387 - val_mean_squared_error: 1102.3190\n",
      "Epoch 96/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 262.0923 - mean_squared_error: 223.9614 - val_loss: 1239.9427 - val_mean_squared_error: 1201.9651\n",
      "Epoch 97/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 261.0163 - mean_squared_error: 223.0605 - val_loss: 1219.1509 - val_mean_squared_error: 1181.2448\n",
      "Epoch 98/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 260.6712 - mean_squared_error: 222.7983 - val_loss: 1128.8982 - val_mean_squared_error: 1091.0629\n",
      "Epoch 99/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 260.3661 - mean_squared_error: 222.6169 - val_loss: 1199.8040 - val_mean_squared_error: 1162.1855\n",
      "Epoch 100/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 260.1750 - mean_squared_error: 222.6143 - val_loss: 1113.2570 - val_mean_squared_error: 1075.6550\n",
      "Epoch 101/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 258.6065 - mean_squared_error: 221.0583 - val_loss: 1181.3427 - val_mean_squared_error: 1143.8079\n",
      "Epoch 102/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 258.2066 - mean_squared_error: 220.6867 - val_loss: 1197.9775 - val_mean_squared_error: 1160.4663\n",
      "Epoch 103/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 258.1386 - mean_squared_error: 220.6262 - val_loss: 1199.6656 - val_mean_squared_error: 1162.1644\n",
      "Epoch 104/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 258.1180 - mean_squared_error: 220.6243 - val_loss: 1196.6696 - val_mean_squared_error: 1159.1793\n",
      "Epoch 105/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 258.1769 - mean_squared_error: 220.6875 - val_loss: 1188.5210 - val_mean_squared_error: 1151.0414\n",
      "Epoch 106/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 258.0401 - mean_squared_error: 220.5633 - val_loss: 1194.0592 - val_mean_squared_error: 1156.5967\n",
      "Epoch 107/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 257.9867 - mean_squared_error: 220.5213 - val_loss: 1188.2589 - val_mean_squared_error: 1150.8014\n",
      "Epoch 108/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 257.8333 - mean_squared_error: 220.3787 - val_loss: 1219.6909 - val_mean_squared_error: 1182.2664\n",
      "Epoch 109/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 257.9673 - mean_squared_error: 220.5286 - val_loss: 1198.2485 - val_mean_squared_error: 1160.8215\n",
      "Epoch 110/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 257.8052 - mean_squared_error: 220.3788 - val_loss: 1172.5553 - val_mean_squared_error: 1135.1249\n",
      "Epoch 111/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 257.8008 - mean_squared_error: 220.3862 - val_loss: 1185.1630 - val_mean_squared_error: 1147.7501\n",
      "Epoch 112/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 257.8305 - mean_squared_error: 220.4279 - val_loss: 1194.2704 - val_mean_squared_error: 1156.8718\n",
      "Epoch 113/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 257.7010 - mean_squared_error: 220.3098 - val_loss: 1174.0127 - val_mean_squared_error: 1136.6163\n",
      "Epoch 114/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 257.8149 - mean_squared_error: 220.4418 - val_loss: 1171.0774 - val_mean_squared_error: 1133.6929\n",
      "Epoch 115/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 257.7084 - mean_squared_error: 220.3393 - val_loss: 1207.3407 - val_mean_squared_error: 1169.9935\n",
      "Epoch 116/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 257.7341 - mean_squared_error: 220.3828 - val_loss: 1185.4331 - val_mean_squared_error: 1148.0852\n",
      "Epoch 117/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 257.5720 - mean_squared_error: 220.2317 - val_loss: 1182.3669 - val_mean_squared_error: 1145.0308\n",
      "Epoch 118/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 257.5913 - mean_squared_error: 220.2741 - val_loss: 1177.7595 - val_mean_squared_error: 1140.4348\n",
      "Epoch 119/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 257.4787 - mean_squared_error: 220.1638 - val_loss: 1190.1859 - val_mean_squared_error: 1152.8784\n",
      "Epoch 120/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 257.5035 - mean_squared_error: 220.2081 - val_loss: 1189.2416 - val_mean_squared_error: 1151.9456\n",
      "Epoch 121/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 257.5238 - mean_squared_error: 220.2379 - val_loss: 1171.9771 - val_mean_squared_error: 1134.6831\n",
      "Epoch 122/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 257.4217 - mean_squared_error: 220.1476 - val_loss: 1198.8704 - val_mean_squared_error: 1161.6113\n",
      "Epoch 123/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 257.3868 - mean_squared_error: 220.1261 - val_loss: 1189.1201 - val_mean_squared_error: 1151.8638\n",
      "Epoch 124/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 257.3652 - mean_squared_error: 220.1193 - val_loss: 1188.9862 - val_mean_squared_error: 1151.7468\n",
      "Epoch 125/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 257.2615 - mean_squared_error: 220.0316 - val_loss: 1184.5986 - val_mean_squared_error: 1147.3678\n",
      "Epoch 126/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 257.3264 - mean_squared_error: 220.1076 - val_loss: 1187.7826 - val_mean_squared_error: 1150.5692\n",
      "Epoch 127/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 257.2155 - mean_squared_error: 220.0116 - val_loss: 1204.8105 - val_mean_squared_error: 1167.6301\n",
      "Epoch 128/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 257.1989 - mean_squared_error: 220.0134 - val_loss: 1205.4404 - val_mean_squared_error: 1168.2704\n",
      "Epoch 129/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 257.1597 - mean_squared_error: 219.9875 - val_loss: 1196.6713 - val_mean_squared_error: 1159.5105\n",
      "Epoch 130/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 257.0834 - mean_squared_error: 219.9312 - val_loss: 1196.0737 - val_mean_squared_error: 1158.9207\n",
      "Epoch 131/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 257.0051 - mean_squared_error: 219.8578 - val_loss: 1201.6364 - val_mean_squared_error: 1164.5049\n",
      "Epoch 132/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 256.9898 - mean_squared_error: 219.8592 - val_loss: 1178.6577 - val_mean_squared_error: 1141.5233\n",
      "Epoch 133/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 256.9415 - mean_squared_error: 219.8236 - val_loss: 1174.1790 - val_mean_squared_error: 1137.0530\n",
      "Epoch 134/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 256.8944 - mean_squared_error: 219.7805 - val_loss: 1172.0774 - val_mean_squared_error: 1134.9681\n",
      "Epoch 135/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.9102 - mean_squared_error: 219.8156 - val_loss: 1195.1556 - val_mean_squared_error: 1158.0797\n",
      "Epoch 136/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.8549 - mean_squared_error: 219.7783 - val_loss: 1200.6995 - val_mean_squared_error: 1163.6467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 256.8370 - mean_squared_error: 219.7831 - val_loss: 1193.8151 - val_mean_squared_error: 1156.7677\n",
      "Epoch 138/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.7491 - mean_squared_error: 219.6989 - val_loss: 1188.0486 - val_mean_squared_error: 1151.0116\n",
      "Epoch 139/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.6654 - mean_squared_error: 219.6300 - val_loss: 1209.4231 - val_mean_squared_error: 1172.4192\n",
      "Epoch 140/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.6633 - mean_squared_error: 219.6484 - val_loss: 1191.7128 - val_mean_squared_error: 1154.7089\n",
      "Epoch 141/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.6544 - mean_squared_error: 219.6594 - val_loss: 1183.2083 - val_mean_squared_error: 1146.2043\n",
      "Epoch 142/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.5843 - mean_squared_error: 219.5975 - val_loss: 1192.5200 - val_mean_squared_error: 1155.5413\n",
      "Epoch 143/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.5418 - mean_squared_error: 219.5629 - val_loss: 1187.1079 - val_mean_squared_error: 1150.1401\n",
      "Epoch 144/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.5031 - mean_squared_error: 219.5411 - val_loss: 1192.6752 - val_mean_squared_error: 1155.7249\n",
      "Epoch 145/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.4607 - mean_squared_error: 219.5164 - val_loss: 1183.8547 - val_mean_squared_error: 1146.9143\n",
      "Epoch 146/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.4096 - mean_squared_error: 219.4810 - val_loss: 1160.1038 - val_mean_squared_error: 1123.1566\n",
      "Epoch 147/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.5176 - mean_squared_error: 219.5986 - val_loss: 1206.8705 - val_mean_squared_error: 1169.9736\n",
      "Epoch 148/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.3563 - mean_squared_error: 219.4503 - val_loss: 1179.0129 - val_mean_squared_error: 1142.1150\n",
      "Epoch 149/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 256.2369 - mean_squared_error: 219.3532 - val_loss: 1210.4606 - val_mean_squared_error: 1173.5997\n",
      "Epoch 150/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.2584 - mean_squared_error: 219.3909 - val_loss: 1191.9875 - val_mean_squared_error: 1155.1243\n",
      "Epoch 151/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.2146 - mean_squared_error: 219.3576 - val_loss: 1181.8171 - val_mean_squared_error: 1144.9628\n",
      "Epoch 152/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.1460 - mean_squared_error: 219.3004 - val_loss: 1197.8131 - val_mean_squared_error: 1160.9930\n",
      "Epoch 153/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.1058 - mean_squared_error: 219.2870 - val_loss: 1186.1028 - val_mean_squared_error: 1149.2847\n",
      "Epoch 154/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.0444 - mean_squared_error: 219.2247 - val_loss: 1203.8433 - val_mean_squared_error: 1167.0568\n",
      "Epoch 155/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 255.9838 - mean_squared_error: 219.1903 - val_loss: 1169.2502 - val_mean_squared_error: 1132.4452\n",
      "Epoch 156/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 256.0791 - mean_squared_error: 219.2936 - val_loss: 1189.9656 - val_mean_squared_error: 1153.1953\n",
      "Epoch 157/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 255.9901 - mean_squared_error: 219.2218 - val_loss: 1157.5969 - val_mean_squared_error: 1120.8135\n",
      "Epoch 158/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 256.0531 - mean_squared_error: 219.2930 - val_loss: 1185.8346 - val_mean_squared_error: 1149.0875\n",
      "Epoch 159/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 255.8680 - mean_squared_error: 219.1282 - val_loss: 1204.7725 - val_mean_squared_error: 1168.0565\n",
      "Epoch 160/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 255.7996 - mean_squared_error: 219.0784 - val_loss: 1191.0786 - val_mean_squared_error: 1154.3676\n",
      "Epoch 161/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 255.6857 - mean_squared_error: 218.9817 - val_loss: 1190.3838 - val_mean_squared_error: 1153.6833\n",
      "Epoch 162/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 255.7307 - mean_squared_error: 219.0430 - val_loss: 1169.9025 - val_mean_squared_error: 1133.2050\n",
      "Epoch 163/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 255.9220 - mean_squared_error: 219.2423 - val_loss: 1190.8094 - val_mean_squared_error: 1154.1373\n",
      "Epoch 164/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 255.6997 - mean_squared_error: 219.0315 - val_loss: 1164.6998 - val_mean_squared_error: 1128.0356\n",
      "Epoch 165/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 255.6040 - mean_squared_error: 218.9580 - val_loss: 1201.5339 - val_mean_squared_error: 1164.9117\n",
      "Epoch 166/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 255.4589 - mean_squared_error: 218.8327 - val_loss: 1211.7469 - val_mean_squared_error: 1175.1438\n",
      "Epoch 167/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 255.5089 - mean_squared_error: 218.8960 - val_loss: 1167.5511 - val_mean_squared_error: 1130.9236\n",
      "Epoch 168/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 255.4547 - mean_squared_error: 218.8498 - val_loss: 1196.8582 - val_mean_squared_error: 1160.2697\n",
      "Epoch 169/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 255.3728 - mean_squared_error: 218.7872 - val_loss: 1177.0513 - val_mean_squared_error: 1140.4609\n",
      "Epoch 170/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 255.3340 - mean_squared_error: 218.7581 - val_loss: 1203.5623 - val_mean_squared_error: 1167.0110\n",
      "Epoch 171/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 255.3476 - mean_squared_error: 218.7950 - val_loss: 1179.6613 - val_mean_squared_error: 1143.1012\n",
      "Epoch 172/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 255.2413 - mean_squared_error: 218.6947 - val_loss: 1170.2312 - val_mean_squared_error: 1133.6945\n",
      "Epoch 173/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 255.2090 - mean_squared_error: 218.6799 - val_loss: 1178.7483 - val_mean_squared_error: 1142.2281\n",
      "Epoch 174/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 255.1042 - mean_squared_error: 218.5934 - val_loss: 1195.2384 - val_mean_squared_error: 1158.7458\n",
      "Epoch 175/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 255.1538 - mean_squared_error: 218.6593 - val_loss: 1179.9799 - val_mean_squared_error: 1143.4851\n",
      "Epoch 176/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.9776 - mean_squared_error: 218.4927 - val_loss: 1174.1101 - val_mean_squared_error: 1137.6300\n",
      "Epoch 177/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.9166 - mean_squared_error: 218.4483 - val_loss: 1206.2726 - val_mean_squared_error: 1169.8275\n",
      "Epoch 178/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 255.0043 - mean_squared_error: 218.5486 - val_loss: 1199.8418 - val_mean_squared_error: 1163.4148\n",
      "Epoch 179/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 254.9742 - mean_squared_error: 218.5382 - val_loss: 1194.2400 - val_mean_squared_error: 1157.8259\n",
      "Epoch 180/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 254.9043 - mean_squared_error: 218.4897 - val_loss: 1184.6926 - val_mean_squared_error: 1148.2832\n",
      "Epoch 181/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 254.7380 - mean_squared_error: 218.3335 - val_loss: 1153.0417 - val_mean_squared_error: 1116.6226\n",
      "Epoch 182/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.7981 - mean_squared_error: 218.4156 - val_loss: 1172.2177 - val_mean_squared_error: 1135.8248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.8115 - mean_squared_error: 218.4344 - val_loss: 1194.4237 - val_mean_squared_error: 1158.0602\n",
      "Epoch 184/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.8362 - mean_squared_error: 218.4721 - val_loss: 1169.6429 - val_mean_squared_error: 1133.2858\n",
      "Epoch 185/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 254.6668 - mean_squared_error: 218.3331 - val_loss: 1178.2551 - val_mean_squared_error: 1141.9113\n",
      "Epoch 186/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.5876 - mean_squared_error: 218.2620 - val_loss: 1210.5962 - val_mean_squared_error: 1174.2864\n",
      "Epoch 187/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.5601 - mean_squared_error: 218.2512 - val_loss: 1182.8966 - val_mean_squared_error: 1146.5817\n",
      "Epoch 188/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.5315 - mean_squared_error: 218.2312 - val_loss: 1207.5812 - val_mean_squared_error: 1171.3086\n",
      "Epoch 189/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.5863 - mean_squared_error: 218.3021 - val_loss: 1203.8035 - val_mean_squared_error: 1167.5515\n",
      "Epoch 190/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.4783 - mean_squared_error: 218.2195 - val_loss: 1204.5106 - val_mean_squared_error: 1168.2666\n",
      "Epoch 191/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.3959 - mean_squared_error: 218.1486 - val_loss: 1190.3837 - val_mean_squared_error: 1154.1404\n",
      "Epoch 192/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.3469 - mean_squared_error: 218.1089 - val_loss: 1205.9476 - val_mean_squared_error: 1169.7429\n",
      "Epoch 193/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.3762 - mean_squared_error: 218.1539 - val_loss: 1196.0472 - val_mean_squared_error: 1159.8542\n",
      "Epoch 194/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.3111 - mean_squared_error: 218.1162 - val_loss: 1187.6193 - val_mean_squared_error: 1151.4271\n",
      "Epoch 195/200\n",
      "14738/14738 [==============================] - 0s 6us/step - loss: 254.0763 - mean_squared_error: 217.8853 - val_loss: 1236.2042 - val_mean_squared_error: 1200.0586\n",
      "Epoch 196/200\n",
      "14738/14738 [==============================] - 0s 8us/step - loss: 254.2517 - mean_squared_error: 218.0798 - val_loss: 1203.7499 - val_mean_squared_error: 1167.6047\n",
      "Epoch 197/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.1089 - mean_squared_error: 217.9635 - val_loss: 1166.2013 - val_mean_squared_error: 1130.0250\n",
      "Epoch 198/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.0217 - mean_squared_error: 217.8766 - val_loss: 1198.6837 - val_mean_squared_error: 1162.5605\n",
      "Epoch 199/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.0773 - mean_squared_error: 217.9549 - val_loss: 1160.1265 - val_mean_squared_error: 1123.9813\n",
      "Epoch 200/200\n",
      "14738/14738 [==============================] - 0s 7us/step - loss: 254.0944 - mean_squared_error: 217.9840 - val_loss: 1200.2311 - val_mean_squared_error: 1164.1351\n"
     ]
    }
   ],
   "source": [
    "nFeatures = len(selected_features)\n",
    "\n",
    "lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "\n",
    "shape = nFeatures*tModel.data_handler.sequence_length\n",
    "\n",
    "\n",
    "model = get_compiled_model(shape, model_type='ann')\n",
    "tModel.change_model('ModelRUL_SN_1', model, 'keras')\n",
    "\n",
    "\n",
    "tModel.epochs = 200\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "tModel.train_model(learningRate_scheduler=lrate, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 40us/step\n",
      "scores\n",
      "Engine 1, Predicted RUL 124.41279602050781, Rounded RUL 124.0, Real RUL 112.0\n",
      "Engine 2, Predicted RUL 146.202392578125, Rounded RUL 146.0, Real RUL 98.0\n",
      "Engine 3, Predicted RUL 133.16619873046875, Rounded RUL 133.0, Real RUL 69.0\n",
      "Engine 4, Predicted RUL 31.11128044128418, Rounded RUL 31.0, Real RUL 82.0\n",
      "Engine 5, Predicted RUL 106.24877166748047, Rounded RUL 106.0, Real RUL 91.0\n",
      "Engine 6, Predicted RUL 118.80476379394531, Rounded RUL 118.0, Real RUL 93.0\n",
      "Engine 7, Predicted RUL 102.56932067871094, Rounded RUL 102.0, Real RUL 91.0\n",
      "Engine 8, Predicted RUL 108.11844635009766, Rounded RUL 108.0, Real RUL 95.0\n",
      "Engine 9, Predicted RUL 26.169109344482422, Rounded RUL 26.0, Real RUL 111.0\n",
      "Engine 10, Predicted RUL 80.682861328125, Rounded RUL 80.0, Real RUL 96.0\n",
      "Engine 11, Predicted RUL 93.05181121826172, Rounded RUL 93.0, Real RUL 97.0\n",
      "Engine 12, Predicted RUL 122.34523010253906, Rounded RUL 122.0, Real RUL 124.0\n",
      "Engine 13, Predicted RUL 103.5378189086914, Rounded RUL 103.0, Real RUL 95.0\n",
      "Engine 14, Predicted RUL 106.39788818359375, Rounded RUL 106.0, Real RUL 107.0\n",
      "Engine 15, Predicted RUL 86.26438903808594, Rounded RUL 86.0, Real RUL 83.0\n",
      "Engine 16, Predicted RUL 77.55294799804688, Rounded RUL 77.0, Real RUL 84.0\n",
      "Engine 17, Predicted RUL 98.42384338378906, Rounded RUL 98.0, Real RUL 50.0\n",
      "Engine 18, Predicted RUL 113.93510437011719, Rounded RUL 113.0, Real RUL 28.0\n",
      "Engine 19, Predicted RUL 113.77520751953125, Rounded RUL 113.0, Real RUL 87.0\n",
      "Engine 20, Predicted RUL 62.07697677612305, Rounded RUL 62.0, Real RUL 16.0\n",
      "{'loss': 1200.2310791015625, 'score_1': 1164.1351318359375, 'rhs': 37.029692465678366, 'rmse': 34.264413025761876}\n",
      "RMSE2: 34.264413025761876\n",
      "RHS: 37.029692465678366\n",
      "Time : 33.017503000000005 seconds\n"
     ]
    }
   ],
   "source": [
    "tModel.evaluate_model(['rhs', 'rmse'], round=2, cross_validation=True)\n",
    "print(\"scores\")\n",
    "\n",
    "cScores = tModel.scores\n",
    "#rmse = math.sqrt(cScores['score_1'])\n",
    "rmse2 = cScores['rmse']\n",
    "rhs = cScores['rhs']\n",
    "time = tModel.train_time\n",
    "\n",
    "i = range(1,len(tModel.y_test)+1)\n",
    "\n",
    "\n",
    "for i, rul_prediction, rul_prediction_rounded, true_rul in zip(i, np.ravel(tModel.y_predicted), tModel.y_predicted_rounded, np.ravel(tModel.y_test)):\n",
    "    print('Engine {}, Predicted RUL {}, Rounded RUL {}, Real RUL {}'.format(i, rul_prediction, \n",
    "                                                                    rul_prediction_rounded, \n",
    "                                                                    true_rul))\n",
    "\n",
    "print(cScores)\n",
    "#print(\"RMSE: {}\".format(rmse))\n",
    "print(\"RMSE2: {}\".format(rmse2))\n",
    "print(\"RHS: {}\".format(rhs))\n",
    "print(\"Time : {} seconds\".format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 92us/step\n",
      "scores\n",
      "Engine 1, Predicted RUL 111.69953918457031, Rounded RUL 111.0, Real RUL 112.0\n",
      "Engine 2, Predicted RUL 128.86669921875, Rounded RUL 128.0, Real RUL 98.0\n",
      "Engine 3, Predicted RUL 48.9747314453125, Rounded RUL 48.0, Real RUL 69.0\n",
      "Engine 4, Predicted RUL 79.33831024169922, Rounded RUL 79.0, Real RUL 82.0\n",
      "Engine 5, Predicted RUL 89.0667724609375, Rounded RUL 89.0, Real RUL 91.0\n",
      "Engine 6, Predicted RUL 110.11637115478516, Rounded RUL 110.0, Real RUL 93.0\n",
      "Engine 7, Predicted RUL 107.16773223876953, Rounded RUL 107.0, Real RUL 91.0\n",
      "Engine 8, Predicted RUL 93.62696075439453, Rounded RUL 93.0, Real RUL 95.0\n",
      "Engine 9, Predicted RUL 117.41218566894531, Rounded RUL 117.0, Real RUL 111.0\n",
      "Engine 10, Predicted RUL 96.13442993164062, Rounded RUL 96.0, Real RUL 96.0\n",
      "Engine 11, Predicted RUL 85.25056457519531, Rounded RUL 85.0, Real RUL 97.0\n",
      "Engine 12, Predicted RUL 97.95358276367188, Rounded RUL 97.0, Real RUL 124.0\n",
      "Engine 13, Predicted RUL 92.29791259765625, Rounded RUL 92.0, Real RUL 95.0\n",
      "Engine 14, Predicted RUL 103.64868927001953, Rounded RUL 103.0, Real RUL 107.0\n",
      "Engine 15, Predicted RUL 109.44371032714844, Rounded RUL 109.0, Real RUL 83.0\n",
      "Engine 16, Predicted RUL 112.34132385253906, Rounded RUL 112.0, Real RUL 84.0\n",
      "Engine 17, Predicted RUL 59.816829681396484, Rounded RUL 59.0, Real RUL 50.0\n",
      "Engine 18, Predicted RUL 25.125192642211914, Rounded RUL 25.0, Real RUL 28.0\n",
      "Engine 19, Predicted RUL 93.03372192382812, Rounded RUL 93.0, Real RUL 87.0\n",
      "Engine 20, Predicted RUL 15.843259811401367, Rounded RUL 15.0, Real RUL 16.0\n",
      "Engine 21, Predicted RUL 84.21501159667969, Rounded RUL 84.0, Real RUL 57.0\n",
      "Engine 22, Predicted RUL 125.83919525146484, Rounded RUL 125.0, Real RUL 111.0\n",
      "Engine 23, Predicted RUL 128.88377380371094, Rounded RUL 128.0, Real RUL 113.0\n",
      "Engine 24, Predicted RUL 9.372186660766602, Rounded RUL 9.0, Real RUL 20.0\n",
      "Engine 25, Predicted RUL 111.52433013916016, Rounded RUL 111.0, Real RUL 145.0\n",
      "Engine 26, Predicted RUL 115.70384216308594, Rounded RUL 115.0, Real RUL 119.0\n",
      "Engine 27, Predicted RUL 106.30654907226562, Rounded RUL 106.0, Real RUL 66.0\n",
      "Engine 28, Predicted RUL 113.07254028320312, Rounded RUL 113.0, Real RUL 97.0\n",
      "Engine 29, Predicted RUL 98.64939880371094, Rounded RUL 98.0, Real RUL 90.0\n",
      "Engine 30, Predicted RUL 108.63465881347656, Rounded RUL 108.0, Real RUL 115.0\n",
      "Engine 31, Predicted RUL 9.149749755859375, Rounded RUL 9.0, Real RUL 8.0\n",
      "Engine 32, Predicted RUL 52.830833435058594, Rounded RUL 52.0, Real RUL 48.0\n",
      "Engine 33, Predicted RUL 109.50325775146484, Rounded RUL 109.0, Real RUL 106.0\n",
      "Engine 34, Predicted RUL 9.588700294494629, Rounded RUL 9.0, Real RUL 7.0\n",
      "Engine 35, Predicted RUL 10.619242668151855, Rounded RUL 10.0, Real RUL 11.0\n",
      "Engine 36, Predicted RUL 24.230571746826172, Rounded RUL 24.0, Real RUL 19.0\n",
      "Engine 37, Predicted RUL 15.634790420532227, Rounded RUL 15.0, Real RUL 21.0\n",
      "Engine 38, Predicted RUL 53.35161209106445, Rounded RUL 53.0, Real RUL 50.0\n",
      "Engine 39, Predicted RUL 130.254150390625, Rounded RUL 130.0, Real RUL 142.0\n",
      "Engine 40, Predicted RUL 25.460203170776367, Rounded RUL 25.0, Real RUL 28.0\n",
      "Engine 41, Predicted RUL 23.124418258666992, Rounded RUL 23.0, Real RUL 18.0\n",
      "Engine 42, Predicted RUL 6.97507381439209, Rounded RUL 6.0, Real RUL 10.0\n",
      "Engine 43, Predicted RUL 63.42106628417969, Rounded RUL 63.0, Real RUL 59.0\n",
      "Engine 44, Predicted RUL 113.30310821533203, Rounded RUL 113.0, Real RUL 109.0\n",
      "Engine 45, Predicted RUL 85.4986572265625, Rounded RUL 85.0, Real RUL 114.0\n",
      "Engine 46, Predicted RUL 54.56575012207031, Rounded RUL 54.0, Real RUL 47.0\n",
      "Engine 47, Predicted RUL 115.01793670654297, Rounded RUL 115.0, Real RUL 135.0\n",
      "Engine 48, Predicted RUL 99.95716857910156, Rounded RUL 99.0, Real RUL 92.0\n",
      "Engine 49, Predicted RUL 17.5953369140625, Rounded RUL 17.0, Real RUL 21.0\n",
      "Engine 50, Predicted RUL 75.51725006103516, Rounded RUL 75.0, Real RUL 79.0\n",
      "Engine 51, Predicted RUL 120.96138763427734, Rounded RUL 120.0, Real RUL 114.0\n",
      "Engine 52, Predicted RUL 31.031715393066406, Rounded RUL 31.0, Real RUL 29.0\n",
      "Engine 53, Predicted RUL 39.885494232177734, Rounded RUL 39.0, Real RUL 26.0\n",
      "Engine 54, Predicted RUL 119.11775970458984, Rounded RUL 119.0, Real RUL 97.0\n",
      "Engine 55, Predicted RUL 113.39958190917969, Rounded RUL 113.0, Real RUL 137.0\n",
      "Engine 56, Predicted RUL 16.998119354248047, Rounded RUL 16.0, Real RUL 15.0\n",
      "Engine 57, Predicted RUL 100.75032806396484, Rounded RUL 100.0, Real RUL 103.0\n",
      "Engine 58, Predicted RUL 35.463844299316406, Rounded RUL 35.0, Real RUL 37.0\n",
      "Engine 59, Predicted RUL 103.96241760253906, Rounded RUL 103.0, Real RUL 114.0\n",
      "Engine 60, Predicted RUL 120.88117218017578, Rounded RUL 120.0, Real RUL 100.0\n",
      "Engine 61, Predicted RUL 17.757431030273438, Rounded RUL 17.0, Real RUL 21.0\n",
      "Engine 62, Predicted RUL 49.80799865722656, Rounded RUL 49.0, Real RUL 54.0\n",
      "Engine 63, Predicted RUL 86.91827392578125, Rounded RUL 86.0, Real RUL 72.0\n",
      "Engine 64, Predicted RUL 22.464506149291992, Rounded RUL 22.0, Real RUL 28.0\n",
      "Engine 65, Predicted RUL 121.11334991455078, Rounded RUL 121.0, Real RUL 128.0\n",
      "Engine 66, Predicted RUL 13.410795211791992, Rounded RUL 13.0, Real RUL 14.0\n",
      "Engine 67, Predicted RUL 113.10857391357422, Rounded RUL 113.0, Real RUL 77.0\n",
      "Engine 68, Predicted RUL 5.817591667175293, Rounded RUL 5.0, Real RUL 8.0\n",
      "Engine 69, Predicted RUL 108.62911224365234, Rounded RUL 108.0, Real RUL 121.0\n",
      "Engine 70, Predicted RUL 96.17615509033203, Rounded RUL 96.0, Real RUL 94.0\n",
      "Engine 71, Predicted RUL 107.66683197021484, Rounded RUL 107.0, Real RUL 118.0\n",
      "Engine 72, Predicted RUL 61.188499450683594, Rounded RUL 61.0, Real RUL 50.0\n",
      "Engine 73, Predicted RUL 115.89042663574219, Rounded RUL 115.0, Real RUL 131.0\n",
      "Engine 74, Predicted RUL 105.32341003417969, Rounded RUL 105.0, Real RUL 126.0\n",
      "Engine 75, Predicted RUL 108.98014068603516, Rounded RUL 108.0, Real RUL 113.0\n",
      "Engine 76, Predicted RUL 7.593197822570801, Rounded RUL 7.0, Real RUL 10.0\n",
      "Engine 77, Predicted RUL 24.830581665039062, Rounded RUL 24.0, Real RUL 34.0\n",
      "Engine 78, Predicted RUL 130.68955993652344, Rounded RUL 130.0, Real RUL 107.0\n",
      "Engine 79, Predicted RUL 91.53302001953125, Rounded RUL 91.0, Real RUL 63.0\n",
      "Engine 80, Predicted RUL 97.16167449951172, Rounded RUL 97.0, Real RUL 90.0\n",
      "Engine 81, Predicted RUL 4.599731922149658, Rounded RUL 4.0, Real RUL 8.0\n",
      "Engine 82, Predicted RUL 8.498360633850098, Rounded RUL 8.0, Real RUL 9.0\n",
      "Engine 83, Predicted RUL 122.10983276367188, Rounded RUL 122.0, Real RUL 137.0\n",
      "Engine 84, Predicted RUL 71.4455795288086, Rounded RUL 71.0, Real RUL 58.0\n",
      "Engine 85, Predicted RUL 127.81651306152344, Rounded RUL 127.0, Real RUL 118.0\n",
      "Engine 86, Predicted RUL 107.98942565917969, Rounded RUL 107.0, Real RUL 89.0\n",
      "Engine 87, Predicted RUL 114.04645538330078, Rounded RUL 114.0, Real RUL 116.0\n",
      "Engine 88, Predicted RUL 118.66400909423828, Rounded RUL 118.0, Real RUL 115.0\n",
      "Engine 89, Predicted RUL 114.49974060058594, Rounded RUL 114.0, Real RUL 136.0\n",
      "Engine 90, Predicted RUL 28.012863159179688, Rounded RUL 28.0, Real RUL 28.0\n",
      "Engine 91, Predicted RUL 23.330167770385742, Rounded RUL 23.0, Real RUL 38.0\n",
      "Engine 92, Predicted RUL 22.00609588623047, Rounded RUL 22.0, Real RUL 20.0\n",
      "Engine 93, Predicted RUL 58.20905685424805, Rounded RUL 58.0, Real RUL 85.0\n",
      "Engine 94, Predicted RUL 60.687747955322266, Rounded RUL 60.0, Real RUL 55.0\n",
      "Engine 95, Predicted RUL 109.27716827392578, Rounded RUL 109.0, Real RUL 128.0\n",
      "Engine 96, Predicted RUL 103.35615539550781, Rounded RUL 103.0, Real RUL 137.0\n",
      "Engine 97, Predicted RUL 87.01110076904297, Rounded RUL 87.0, Real RUL 82.0\n",
      "Engine 98, Predicted RUL 84.6989974975586, Rounded RUL 84.0, Real RUL 59.0\n",
      "Engine 99, Predicted RUL 111.21141815185547, Rounded RUL 111.0, Real RUL 117.0\n",
      "Engine 100, Predicted RUL 9.117345809936523, Rounded RUL 9.0, Real RUL 20.0\n",
      "{'loss': 248.86673889160156, 'score_1': 212.770830078125, 'rhs': 3.5025303128026155, 'rmse': 14.558502670261115}\n",
      "RMSE2: 14.558502670261115\n",
      "RHS: 3.5025303128026155\n",
      "Time : 33.017503000000005 seconds\n"
     ]
    }
   ],
   "source": [
    "tModel.evaluate_model(['rhs', 'rmse'], round=2, cross_validation=False)\n",
    "print(\"scores\")\n",
    "\n",
    "cScores = tModel.scores\n",
    "#rmse = math.sqrt(cScores['score_1'])\n",
    "rmse2 = cScores['rmse']\n",
    "rhs = cScores['rhs']\n",
    "time = tModel.train_time\n",
    "\n",
    "i = range(1,len(tModel.y_test)+1)\n",
    "\n",
    "\n",
    "for i, rul_prediction, rul_prediction_rounded, true_rul in zip(i, np.ravel(tModel.y_predicted), tModel.y_predicted_rounded, np.ravel(tModel.y_test)):\n",
    "    print('Engine {}, Predicted RUL {}, Rounded RUL {}, Real RUL {}'.format(i, rul_prediction, \n",
    "                                                                    rul_prediction_rounded, \n",
    "                                                                    true_rul))\n",
    "\n",
    "print(cScores)\n",
    "#print(\"RMSE: {}\".format(rmse))\n",
    "print(\"RMSE2: {}\".format(rmse2))\n",
    "print(\"RHS: {}\".format(rhs))\n",
    "print(\"Time : {} seconds\".format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
