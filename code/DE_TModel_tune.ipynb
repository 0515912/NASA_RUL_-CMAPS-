{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Test notebook for the C-MAPPS benchmark. Get best parameters for each dataset. \n",
    "\n",
    "First we import the necessary packages and create the global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import csv\n",
    "from data_handler_CMAPS import CMAPSDataHandler\n",
    "from tunable_model import SequenceTunableModelRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from tunable_model import SequenceTunableModelRegression\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "import CMAPSAuxFunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RULmodel_SN(input_shape):\n",
    "    \n",
    "    lambda_regularization = 0.20\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(lambda_regularization), name='fc1'))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Data Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selected as per CNN paper\n",
    "features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "selected_features = list(features[i] for i in selected_indices-1)\n",
    "data_folder = '../CMAPSSData'\n",
    "\n",
    "window_size = 30\n",
    "window_stride = 1\n",
    "max_rul = 125\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "dHandler_cmaps = CMAPSDataHandler(data_folder, 1, selected_features, max_rul, window_size, \n",
    "                                  window_stride, data_scaler=min_max_scaler)\n",
    "#dHandler_cmaps.load_data(verbose=1, cross_validation_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create theTunable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "#min_max_scaler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(shape, model_type='ann'):\n",
    "\n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0, beta_1=0.5)\n",
    "    lossFunction = \"mean_squared_error\"\n",
    "    metrics = [\"mse\"]\n",
    "    model = None\n",
    "\n",
    "    #Create and compile the models\n",
    "\n",
    "    if model_type=='ann':\n",
    "        model = RULmodel_SN(shape)\n",
    "        model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    elif model_type=='lstm':\n",
    "        \"\"\"nFeatures = len(selected_features)\n",
    "        shapeLSTM = (window_size, nFeatures)\n",
    "        model = RULmodel_LSTM(shapeLSTM)\n",
    "        model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\"\"\"\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFeatures = len(selected_features)\n",
    "shapeSN = nFeatures*window_size\n",
    "modelRULSN = get_compiled_model(shapeSN, model_type='ann')\n",
    "tModel = SequenceTunableModelRegression('ModelRUL_SN_1', modelRULSN, lib_type='keras', data_handler=dHandler_cmaps)\n",
    "#tModel = SequenceTunableModelRegression('ModelRUL_LSTM_1', modelRULLSTM, lib_type='keras', data_handler=dHandler_cmaps)\n",
    "tModel.data_handler.data_scaler = min_max_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define objective function\n",
    "\n",
    "Define the function that evaluates each set of data-related params and returns the RMSE as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_optmize_fun(x, tModel, verbose=0, epochs=250, saveToFile = None, iterations = 0):\n",
    "    \n",
    "    #Clear the previous tensorflow graph\n",
    "    K.clear_session()\n",
    "    \n",
    "    maxWindowSize = {'1':30, '2':20, '3':30, '4':18}\n",
    "    \n",
    "    #Extract the tunning variables from the input vector\n",
    "    #Round the values to the nearest integer since this implementation is for real numbers\n",
    "    x = x.astype(int)\n",
    "\n",
    "    #load the data using the selected parameters\n",
    "    tModel.data_handler.sequence_length = x[0]\n",
    "    #tModel.data_handler.sequence_length = maxWindowSize[datasetNumber]\n",
    "    tModel.data_handler.sequence_stride = x[1]\n",
    "    tModel.data_handler.max_rul = x[2]\n",
    "    \n",
    "    tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0)\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Training model\")\n",
    "    \n",
    "    #Create new model\n",
    "    lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "    nFeatures = len(selected_features)\n",
    "    model_shape = nFeatures*tModel.data_handler.sequence_length\n",
    "    modelRULSN = get_compiled_model(model_shape, model_type='ann')\n",
    "    tModel.change_model('ModelRUL_SN_1', modelRULSN, 'keras')\n",
    "    \n",
    "    #Train model\n",
    "    tModel.train_model(learningRate_scheduler=lrate, verbose=0)\n",
    "    time = tModel.train_time\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Training time {}\".format(time))\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Assesing model performance\")\n",
    "    #Assess the model performance\n",
    "    tModel.evaluate_model([\"rhs\"], round=2)\n",
    "    cScores = tModel.scores\n",
    "    rmse = math.sqrt(cScores['score_1'])\n",
    "    rhs = cScores['rhs']\n",
    "    #print(\"The score for this model is: {}\".format(rmse))\n",
    "    \n",
    "    msgStr = \"The model variables are \" + str(x) + \"\\tThe scores are: [RMSE:{:.4f}, RHS:{:.4f}]\\n\".format(rmse, rhs)\n",
    "    row = x.tolist() + [rmse, rhs]\n",
    "    \n",
    "    if saveToFile is not None:\n",
    "        #print(msgStr)\n",
    "        writer = csv.writer(saveToFile)\n",
    "        #row = x.append(rmse)\n",
    "        #row = x.append(rhs)\n",
    "        writer.writerow(row)\n",
    "        #saveToFile.write(msgStr)\n",
    "    else:\n",
    "        print(row)\n",
    "    \n",
    "    #Return RMSE as the performance metric to steer the search\n",
    "    return rmse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize the parameters for the NN using DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunning for dataset 1\n",
      "Loading data for dataset 1 with window_size of 24, stride of 2 and maxRUL of 100. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n",
      "100/100 [==============================] - 0s 224us/step\n",
      "Loading data for dataset 1 with window_size of 18, stride of 9 and maxRUL of 111. Cros-Validation ratio 0\n",
      "Loading data from memory and recomputing dataframes\n",
      "100/100 [==============================] - 0s 195us/step\n",
      "Loading data for dataset 1 with window_size of 1, stride of 4 and maxRUL of 128. Cros-Validation ratio 0\n",
      "Loading data from memory and recomputing dataframes\n",
      "100/100 [==============================] - 0s 195us/step\n",
      "Loading data for dataset 1 with window_size of 5, stride of 5 and maxRUL of 137. Cros-Validation ratio 0\n",
      "Loading data from memory and recomputing dataframes\n"
     ]
    }
   ],
   "source": [
    "#Optimize the parameters for the NN using DE\n",
    "\n",
    "#maxWindowSize = {'1':30, '2':20, '3':30, '4':18}\n",
    "maxWindowSize = {'1':30, '2':20} #Do it only for datasets 1 and 2\n",
    "totalTime = {'1':0, '2':0, '3':0, '4':0}\n",
    "results = {'1':0, '2':0, '3':0, '4':0}\n",
    "\n",
    "#datasetNumber = '1'\n",
    "\n",
    "selected_features = ['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'htBleed', 'W31', 'W32']\n",
    "\n",
    "\n",
    "\n",
    "for datasetNumber in maxWindowSize:\n",
    "    \n",
    "    print(\"Tunning for dataset \"+datasetNumber)\n",
    "    file = open(\"results/MLP/intermediateResults_refactorized_\"+datasetNumber+\".csv\", \"w\")\n",
    "\n",
    "    windowSizeBounds = [1,maxWindowSize[datasetNumber]]\n",
    "    windowStrideBounds = [1,10]\n",
    "    constantRULBounds = [90,140]\n",
    "\n",
    "    bounds = [windowSizeBounds, windowStrideBounds, constantRULBounds]\n",
    "    #bounds = [windowStrideBounds, constantRULBounds] #Optimize only 2 variabes\n",
    "    \n",
    "    tModel.data_handler.change_dataset(datasetNumber)\n",
    "\n",
    "    startTime = time.clock()\n",
    "    tempResults = differential_evolution(nn_optmize_fun, bounds, \n",
    "                                     args=(tModel, 0, 20, file, 1),\n",
    "                                    strategy='best1bin', maxiter=30, popsize=4, disp=True, polish=False)\n",
    "    results[datasetNumber] = tempResults\n",
    "    endTime = time.clock()\n",
    "\n",
    "    file.close()\n",
    "    totalTime[datasetNumber] = endTime - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'totalTime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9b53b964db5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Total time {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotalTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'totalTime' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Total time {}\".format(totalTime))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
