{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Test notebook for the C-MAPPS benchmark. Get best parameters for each dataset. \n",
    "\n",
    "First we import the necessary packages and create the global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import csv\n",
    "from data_handler_CMAPS import CMAPSDataHandler\n",
    "from tunable_model import SequenceTunableModelRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from tunable_model import SequenceTunableModelRegression\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "import CMAPSAuxFunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RULmodel_SN(input_shape):\n",
    "    \n",
    "    lambda_regularization = 0.20\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(lambda_regularization), name='fc1'))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Data Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selected as per CNN paper\n",
    "features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "selected_features = list(features[i] for i in selected_indices-1)\n",
    "data_folder = '../CMAPSSData'\n",
    "\n",
    "window_size = 30\n",
    "window_stride = 1\n",
    "max_rul = 125\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "dHandler_cmaps = CMAPSDataHandler(data_folder, 1, selected_features, max_rul, window_size, \n",
    "                                  window_stride, data_scaler=min_max_scaler)\n",
    "#dHandler_cmaps.load_data(verbose=1, cross_validation_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create theTunable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "#min_max_scaler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(shape, model_type='ann'):\n",
    "\n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0, beta_1=0.5)\n",
    "    lossFunction = \"mean_squared_error\"\n",
    "    metrics = [\"mse\"]\n",
    "    model = None\n",
    "\n",
    "    #Create and compile the models\n",
    "\n",
    "    if model_type=='ann':\n",
    "        model = RULmodel_SN(shape)\n",
    "        model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    elif model_type=='lstm':\n",
    "        \"\"\"nFeatures = len(selected_features)\n",
    "        shapeLSTM = (window_size, nFeatures)\n",
    "        model = RULmodel_LSTM(shapeLSTM)\n",
    "        model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\"\"\"\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFeatures = len(selected_features)\n",
    "shapeSN = nFeatures*window_size\n",
    "modelRULSN = get_compiled_model(shapeSN, model_type='ann')\n",
    "tModel = SequenceTunableModelRegression('ModelRUL_SN_1', modelRULSN, lib_type='keras', data_handler=dHandler_cmaps)\n",
    "#tModel = SequenceTunableModelRegression('ModelRUL_LSTM_1', modelRULLSTM, lib_type='keras', data_handler=dHandler_cmaps)\n",
    "tModel.data_handler.data_scaler = min_max_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define objective function\n",
    "\n",
    "Define the function that evaluates each set of data-related params and returns the RMSE as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_optmize_fun(x, tModel, verbose=0, epochs=250, saveToFile = None, iterations = 0):\n",
    "    \n",
    "    #Clear the previous tensorflow graph\n",
    "    K.clear_session()\n",
    "    \n",
    "    maxWindowSize = {'1':30, '2':20, '3':30, '4':18}\n",
    "    \n",
    "    #Extract the tunning variables from the input vector\n",
    "    #Round the values to the nearest integer since this implementation is for real numbers\n",
    "    x = x.astype(int)\n",
    "\n",
    "    #load the data using the selected parameters\n",
    "    tModel.data_handler.sequence_length = x[0]\n",
    "    #tModel.data_handler.sequence_length = maxWindowSize[datasetNumber]\n",
    "    tModel.data_handler.sequence_stride = x[1]\n",
    "    tModel.data_handler.max_rul = x[2]\n",
    "    \n",
    "    tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0)\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Training model\")\n",
    "    \n",
    "    #Create new model\n",
    "    lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "    nFeatures = len(selected_features)\n",
    "    model_shape = nFeatures*tModel.data_handler.sequence_length\n",
    "    modelRULSN = get_compiled_model(model_shape, model_type='ann')\n",
    "    tModel.change_model('ModelRUL_SN_1', modelRULSN, 'keras')\n",
    "    \n",
    "    #Train model\n",
    "    tModel.train_model(learningRate_scheduler=lrate, verbose=1)\n",
    "    time = tModel.train_time\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Training time {}\".format(time))\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Assesing model performance\")\n",
    "    #Assess the model performance\n",
    "    tModel.evaluate_model([\"rhs\"], round=2)\n",
    "    cScores = tModel.scores\n",
    "    rmse = math.sqrt(cScores['score_1'])\n",
    "    rhs = cScores['rhs']\n",
    "    #print(\"The score for this model is: {}\".format(rmse))\n",
    "    \n",
    "    msgStr = \"The model variables are \" + str(x) + \"\\tThe scores are: [RMSE:{:.4f}, RHS:{:.4f}]\\n\".format(rmse, rhs)\n",
    "    row = x.tolist() + [rmse, rhs]\n",
    "    \n",
    "    if saveToFile is not None:\n",
    "        #print(msgStr)\n",
    "        writer = csv.writer(saveToFile)\n",
    "        #row = x.append(rmse)\n",
    "        #row = x.append(rhs)\n",
    "        writer.writerow(row)\n",
    "        #saveToFile.write(msgStr)\n",
    "    else:\n",
    "        print(row)\n",
    "    \n",
    "    #Return RMSE as the performance metric to steer the search\n",
    "    return rmse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize the parameters for the NN using DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunning for dataset 2\n",
      "Loading data for dataset 2 with window_size of 9, stride of 5 and maxRUL of 91. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n",
      "Epoch 1/250\n",
      "10447/10447 [==============================] - 0s 47us/step - loss: 5535.4322 - mean_squared_error: 5528.4105\n",
      "Epoch 2/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 5164.0660 - mean_squared_error: 5156.8241\n",
      "Epoch 3/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 4721.1045 - mean_squared_error: 4713.3754\n",
      "Epoch 4/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 4243.4526 - mean_squared_error: 4234.9583\n",
      "Epoch 5/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 3762.7519 - mean_squared_error: 3753.2385\n",
      "Epoch 6/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 3303.7071 - mean_squared_error: 3292.9685\n",
      "Epoch 7/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 2884.4745 - mean_squared_error: 2872.3720\n",
      "Epoch 8/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 2516.0832 - mean_squared_error: 2502.5259\n",
      "Epoch 9/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 2207.6285 - mean_squared_error: 2192.6299\n",
      "Epoch 10/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1959.0285 - mean_squared_error: 1942.6597\n",
      "Epoch 11/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1765.4456 - mean_squared_error: 1747.8416\n",
      "Epoch 12/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 1619.5447 - mean_squared_error: 1600.8598\n",
      "Epoch 13/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1511.4331 - mean_squared_error: 1491.8400\n",
      "Epoch 14/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 1432.8551 - mean_squared_error: 1412.5684\n",
      "Epoch 15/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1374.8780 - mean_squared_error: 1354.0800\n",
      "Epoch 16/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1331.1423 - mean_squared_error: 1309.9625\n",
      "Epoch 17/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1297.4789 - mean_squared_error: 1276.0261\n",
      "Epoch 18/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1270.5621 - mean_squared_error: 1248.9933\n",
      "Epoch 19/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1247.9835 - mean_squared_error: 1226.3154\n",
      "Epoch 20/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1228.6574 - mean_squared_error: 1206.9050\n",
      "Epoch 21/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1212.1758 - mean_squared_error: 1190.4382\n",
      "Epoch 22/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1197.3992 - mean_squared_error: 1175.6750\n",
      "Epoch 23/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1183.7237 - mean_squared_error: 1161.9726\n",
      "Epoch 24/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1171.1317 - mean_squared_error: 1149.3962\n",
      "Epoch 25/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1159.2472 - mean_squared_error: 1137.5289\n",
      "Epoch 26/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1147.9473 - mean_squared_error: 1126.1754\n",
      "Epoch 27/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1137.1130 - mean_squared_error: 1115.3449\n",
      "Epoch 28/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 1126.6935 - mean_squared_error: 1104.9015\n",
      "Epoch 29/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1116.3906 - mean_squared_error: 1094.5534\n",
      "Epoch 30/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1106.3600 - mean_squared_error: 1084.4555\n",
      "Epoch 31/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1096.4690 - mean_squared_error: 1074.4560\n",
      "Epoch 32/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1086.8350 - mean_squared_error: 1064.7491\n",
      "Epoch 33/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 1077.1365 - mean_squared_error: 1054.8919\n",
      "Epoch 34/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 1067.6048 - mean_squared_error: 1045.2120\n",
      "Epoch 35/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1058.2578 - mean_squared_error: 1035.7057\n",
      "Epoch 36/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1048.8852 - mean_squared_error: 1026.1410\n",
      "Epoch 37/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1039.6209 - mean_squared_error: 1016.6995\n",
      "Epoch 38/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1030.3373 - mean_squared_error: 1007.2226\n",
      "Epoch 39/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 1021.1196 - mean_squared_error: 997.7585\n",
      "Epoch 40/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1012.0340 - mean_squared_error: 988.4158\n",
      "Epoch 41/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 1002.8787 - mean_squared_error: 979.0367\n",
      "Epoch 42/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 993.8550 - mean_squared_error: 969.7321\n",
      "Epoch 43/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 984.8330 - mean_squared_error: 960.4171\n",
      "Epoch 44/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 975.7849 - mean_squared_error: 951.0511\n",
      "Epoch 45/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 966.8180 - mean_squared_error: 941.7662\n",
      "Epoch 46/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 957.7969 - mean_squared_error: 932.3682\n",
      "Epoch 47/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 948.8570 - mean_squared_error: 923.0638\n",
      "Epoch 48/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 939.9535 - mean_squared_error: 913.7847\n",
      "Epoch 49/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 931.1079 - mean_squared_error: 904.5655\n",
      "Epoch 50/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 922.2013 - mean_squared_error: 895.2242\n",
      "Epoch 51/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 912.5682 - mean_squared_error: 885.1185\n",
      "Epoch 52/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 903.1333 - mean_squared_error: 875.1720\n",
      "Epoch 53/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 893.6315 - mean_squared_error: 865.1480\n",
      "Epoch 54/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 883.8478 - mean_squared_error: 854.7903\n",
      "Epoch 55/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 873.6205 - mean_squared_error: 844.0016\n",
      "Epoch 56/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 863.1762 - mean_squared_error: 832.8543\n",
      "Epoch 57/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 852.5523 - mean_squared_error: 821.5191\n",
      "Epoch 58/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 841.7179 - mean_squared_error: 809.9135\n",
      "Epoch 59/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 830.7202 - mean_squared_error: 798.1758\n",
      "Epoch 60/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 819.5264 - mean_squared_error: 786.1361\n",
      "Epoch 61/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 808.3659 - mean_squared_error: 774.1352\n",
      "Epoch 62/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 797.3086 - mean_squared_error: 762.2117\n",
      "Epoch 63/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 786.0399 - mean_squared_error: 750.0486\n",
      "Epoch 64/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 775.1028 - mean_squared_error: 738.2102\n",
      "Epoch 65/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 764.2017 - mean_squared_error: 726.3535\n",
      "Epoch 66/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 753.2487 - mean_squared_error: 714.5069\n",
      "Epoch 67/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10447/10447 [==============================] - 0s 2us/step - loss: 742.6820 - mean_squared_error: 702.9828\n",
      "Epoch 68/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 732.2042 - mean_squared_error: 691.5648\n",
      "Epoch 69/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 721.7205 - mean_squared_error: 680.0917\n",
      "Epoch 70/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 711.7587 - mean_squared_error: 669.2131\n",
      "Epoch 71/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 701.7700 - mean_squared_error: 658.2822\n",
      "Epoch 72/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 692.0735 - mean_squared_error: 647.6465\n",
      "Epoch 73/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 682.7607 - mean_squared_error: 637.3936\n",
      "Epoch 74/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 673.3613 - mean_squared_error: 627.0389\n",
      "Epoch 75/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 664.4154 - mean_squared_error: 617.1700\n",
      "Epoch 76/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 655.4430 - mean_squared_error: 607.3077\n",
      "Epoch 77/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 646.9053 - mean_squared_error: 597.8827\n",
      "Epoch 78/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 638.5971 - mean_squared_error: 588.6571\n",
      "Epoch 79/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 630.3622 - mean_squared_error: 579.5476\n",
      "Epoch 80/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 622.5922 - mean_squared_error: 570.8989\n",
      "Epoch 81/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 614.8438 - mean_squared_error: 562.3127\n",
      "Epoch 82/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 607.2405 - mean_squared_error: 553.8786\n",
      "Epoch 83/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 599.6593 - mean_squared_error: 545.5060\n",
      "Epoch 84/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 592.1610 - mean_squared_error: 537.1679\n",
      "Epoch 85/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 584.9772 - mean_squared_error: 529.1683\n",
      "Epoch 86/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 578.0639 - mean_squared_error: 521.4634\n",
      "Epoch 87/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 571.1403 - mean_squared_error: 513.7779\n",
      "Epoch 88/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 564.5804 - mean_squared_error: 506.4456\n",
      "Epoch 89/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 558.1227 - mean_squared_error: 499.2484\n",
      "Epoch 90/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 551.7662 - mean_squared_error: 492.1208\n",
      "Epoch 91/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 545.5188 - mean_squared_error: 485.1594\n",
      "Epoch 92/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 539.2875 - mean_squared_error: 478.2196\n",
      "Epoch 93/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 533.4639 - mean_squared_error: 471.7351\n",
      "Epoch 94/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 527.6334 - mean_squared_error: 465.1692\n",
      "Epoch 95/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 521.8494 - mean_squared_error: 458.7248\n",
      "Epoch 96/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 516.3217 - mean_squared_error: 452.5328\n",
      "Epoch 97/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 510.9578 - mean_squared_error: 446.5508\n",
      "Epoch 98/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 505.5712 - mean_squared_error: 440.5064\n",
      "Epoch 99/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 500.4874 - mean_squared_error: 434.8255\n",
      "Epoch 100/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 495.4904 - mean_squared_error: 429.1884\n",
      "Epoch 101/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 492.0196 - mean_squared_error: 425.3850\n",
      "Epoch 102/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 491.4777 - mean_squared_error: 424.7852\n",
      "Epoch 103/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 490.9718 - mean_squared_error: 424.2200\n",
      "Epoch 104/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 490.4563 - mean_squared_error: 423.6451\n",
      "Epoch 105/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 489.9726 - mean_squared_error: 423.1081\n",
      "Epoch 106/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 489.4900 - mean_squared_error: 422.5625\n",
      "Epoch 107/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 488.9870 - mean_squared_error: 422.0052\n",
      "Epoch 108/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 488.4998 - mean_squared_error: 421.4573\n",
      "Epoch 109/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 488.0481 - mean_squared_error: 420.9507\n",
      "Epoch 110/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 487.5623 - mean_squared_error: 420.4018\n",
      "Epoch 111/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 487.0794 - mean_squared_error: 419.8653\n",
      "Epoch 112/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 486.5913 - mean_squared_error: 419.3182\n",
      "Epoch 113/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 486.1168 - mean_squared_error: 418.7892\n",
      "Epoch 114/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 485.6552 - mean_squared_error: 418.2758\n",
      "Epoch 115/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 485.1562 - mean_squared_error: 417.7194\n",
      "Epoch 116/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 484.6957 - mean_squared_error: 417.2038\n",
      "Epoch 117/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 484.2117 - mean_squared_error: 416.6610\n",
      "Epoch 118/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 483.7243 - mean_squared_error: 416.1152\n",
      "Epoch 119/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 483.2594 - mean_squared_error: 415.5960\n",
      "Epoch 120/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 482.7777 - mean_squared_error: 415.0667\n",
      "Epoch 121/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 482.2849 - mean_squared_error: 414.5168\n",
      "Epoch 122/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 481.8210 - mean_squared_error: 413.9939\n",
      "Epoch 123/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 481.3616 - mean_squared_error: 413.4806\n",
      "Epoch 124/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 480.8911 - mean_squared_error: 412.9539\n",
      "Epoch 125/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 480.4110 - mean_squared_error: 412.4209\n",
      "Epoch 126/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 479.9538 - mean_squared_error: 411.9077\n",
      "Epoch 127/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 479.4629 - mean_squared_error: 411.3590\n",
      "Epoch 128/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 479.0122 - mean_squared_error: 410.8575\n",
      "Epoch 129/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 478.5230 - mean_squared_error: 410.3135\n",
      "Epoch 130/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 478.0340 - mean_squared_error: 409.7715\n",
      "Epoch 131/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 477.5842 - mean_squared_error: 409.2700\n",
      "Epoch 132/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 477.0845 - mean_squared_error: 408.7111\n",
      "Epoch 133/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 476.6563 - mean_squared_error: 408.2371\n",
      "Epoch 134/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 476.1425 - mean_squared_error: 407.6665\n",
      "Epoch 135/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10447/10447 [==============================] - 0s 2us/step - loss: 475.6848 - mean_squared_error: 407.1526\n",
      "Epoch 136/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 475.2014 - mean_squared_error: 406.6204\n",
      "Epoch 137/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 474.7302 - mean_squared_error: 406.0954\n",
      "Epoch 138/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 474.2770 - mean_squared_error: 405.5915\n",
      "Epoch 139/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 473.7950 - mean_squared_error: 405.0516\n",
      "Epoch 140/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 473.3166 - mean_squared_error: 404.5256\n",
      "Epoch 141/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 472.8433 - mean_squared_error: 403.9955\n",
      "Epoch 142/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 472.4044 - mean_squared_error: 403.5016\n",
      "Epoch 143/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 471.9058 - mean_squared_error: 402.9567\n",
      "Epoch 144/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 471.4332 - mean_squared_error: 402.4332\n",
      "Epoch 145/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 470.9415 - mean_squared_error: 401.8862\n",
      "Epoch 146/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 470.3943 - mean_squared_error: 401.2845\n",
      "Epoch 147/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 469.8652 - mean_squared_error: 400.7040\n",
      "Epoch 148/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 469.3445 - mean_squared_error: 400.1336\n",
      "Epoch 149/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 468.8301 - mean_squared_error: 399.5669\n",
      "Epoch 150/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 468.3466 - mean_squared_error: 399.0298\n",
      "Epoch 151/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 467.8420 - mean_squared_error: 398.4773\n",
      "Epoch 152/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 467.3337 - mean_squared_error: 397.9094\n",
      "Epoch 153/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 466.8329 - mean_squared_error: 397.3558\n",
      "Epoch 154/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 466.3461 - mean_squared_error: 396.8155\n",
      "Epoch 155/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 465.8671 - mean_squared_error: 396.2931\n",
      "Epoch 156/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 465.3575 - mean_squared_error: 395.7224\n",
      "Epoch 157/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 464.8578 - mean_squared_error: 395.1747\n",
      "Epoch 158/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 464.3517 - mean_squared_error: 394.6227\n",
      "Epoch 159/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 463.8490 - mean_squared_error: 394.0628\n",
      "Epoch 160/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 463.3690 - mean_squared_error: 393.5317\n",
      "Epoch 161/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 462.8826 - mean_squared_error: 392.9951\n",
      "Epoch 162/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 462.3903 - mean_squared_error: 392.4479\n",
      "Epoch 163/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 461.9196 - mean_squared_error: 391.9231\n",
      "Epoch 164/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 461.4052 - mean_squared_error: 391.3635\n",
      "Epoch 165/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 460.9305 - mean_squared_error: 390.8375\n",
      "Epoch 166/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 460.4461 - mean_squared_error: 390.3028\n",
      "Epoch 167/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 459.9651 - mean_squared_error: 389.7714\n",
      "Epoch 168/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 459.4882 - mean_squared_error: 389.2516\n",
      "Epoch 169/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 458.9898 - mean_squared_error: 388.7061\n",
      "Epoch 170/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 458.5449 - mean_squared_error: 388.2091\n",
      "Epoch 171/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 458.0414 - mean_squared_error: 387.6593\n",
      "Epoch 172/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 457.5521 - mean_squared_error: 387.1217\n",
      "Epoch 173/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 457.1037 - mean_squared_error: 386.6209\n",
      "Epoch 174/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 456.6324 - mean_squared_error: 386.0969\n",
      "Epoch 175/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 456.1352 - mean_squared_error: 385.5482\n",
      "Epoch 176/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 455.6372 - mean_squared_error: 385.0000\n",
      "Epoch 177/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 455.1626 - mean_squared_error: 384.4760\n",
      "Epoch 178/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 454.7228 - mean_squared_error: 383.9895\n",
      "Epoch 179/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 454.2376 - mean_squared_error: 383.4579\n",
      "Epoch 180/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 453.7548 - mean_squared_error: 382.9273\n",
      "Epoch 181/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 453.2472 - mean_squared_error: 382.3706\n",
      "Epoch 182/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 452.7832 - mean_squared_error: 381.8588\n",
      "Epoch 183/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 452.3312 - mean_squared_error: 381.3665\n",
      "Epoch 184/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 451.8719 - mean_squared_error: 380.8554\n",
      "Epoch 185/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 451.4095 - mean_squared_error: 380.3460\n",
      "Epoch 186/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 450.8964 - mean_squared_error: 379.7840\n",
      "Epoch 187/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 450.4360 - mean_squared_error: 379.2738\n",
      "Epoch 188/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 449.9524 - mean_squared_error: 378.7521\n",
      "Epoch 189/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 449.4996 - mean_squared_error: 378.2493\n",
      "Epoch 190/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 449.0172 - mean_squared_error: 377.7226\n",
      "Epoch 191/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 448.5471 - mean_squared_error: 377.2056\n",
      "Epoch 192/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 448.0237 - mean_squared_error: 376.6377\n",
      "Epoch 193/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 447.5371 - mean_squared_error: 376.1029\n",
      "Epoch 194/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 447.0606 - mean_squared_error: 375.5861\n",
      "Epoch 195/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 446.5690 - mean_squared_error: 375.0409\n",
      "Epoch 196/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 446.0777 - mean_squared_error: 374.5023\n",
      "Epoch 197/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 445.5998 - mean_squared_error: 373.9846\n",
      "Epoch 198/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 445.1090 - mean_squared_error: 373.4445\n",
      "Epoch 199/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 444.6197 - mean_squared_error: 372.9111\n",
      "Epoch 200/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 444.1647 - mean_squared_error: 372.4095\n",
      "Epoch 201/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 443.6732 - mean_squared_error: 371.8796\n",
      "Epoch 202/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10447/10447 [==============================] - 0s 2us/step - loss: 443.1916 - mean_squared_error: 371.3515\n",
      "Epoch 203/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 442.7137 - mean_squared_error: 370.8266\n",
      "Epoch 204/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 442.2306 - mean_squared_error: 370.3014\n",
      "Epoch 205/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 441.7425 - mean_squared_error: 369.7736\n",
      "Epoch 206/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 441.2367 - mean_squared_error: 369.2225\n",
      "Epoch 207/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 440.7451 - mean_squared_error: 368.6836\n",
      "Epoch 208/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 440.2415 - mean_squared_error: 368.1334\n",
      "Epoch 209/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 439.7435 - mean_squared_error: 367.5919\n",
      "Epoch 210/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 439.2518 - mean_squared_error: 367.0608\n",
      "Epoch 211/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 438.7741 - mean_squared_error: 366.5390\n",
      "Epoch 212/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 438.2770 - mean_squared_error: 365.9960\n",
      "Epoch 213/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 437.8110 - mean_squared_error: 365.4882\n",
      "Epoch 214/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 437.3387 - mean_squared_error: 364.9736\n",
      "Epoch 215/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 436.8765 - mean_squared_error: 364.4740\n",
      "Epoch 216/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 436.3894 - mean_squared_error: 363.9376\n",
      "Epoch 217/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 435.9707 - mean_squared_error: 363.4771\n",
      "Epoch 218/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 435.4679 - mean_squared_error: 362.9365\n",
      "Epoch 219/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 435.0098 - mean_squared_error: 362.4358\n",
      "Epoch 220/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 434.5540 - mean_squared_error: 361.9422\n",
      "Epoch 221/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 434.0983 - mean_squared_error: 361.4456\n",
      "Epoch 222/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 433.6271 - mean_squared_error: 360.9367\n",
      "Epoch 223/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 433.1714 - mean_squared_error: 360.4351\n",
      "Epoch 224/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 432.7125 - mean_squared_error: 359.9316\n",
      "Epoch 225/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 432.2540 - mean_squared_error: 359.4329\n",
      "Epoch 226/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 431.8033 - mean_squared_error: 358.9476\n",
      "Epoch 227/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 431.3466 - mean_squared_error: 358.4568\n",
      "Epoch 228/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 430.9103 - mean_squared_error: 357.9744\n",
      "Epoch 229/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 430.4582 - mean_squared_error: 357.4867\n",
      "Epoch 230/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 430.0223 - mean_squared_error: 357.0139\n",
      "Epoch 231/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 429.5784 - mean_squared_error: 356.5328\n",
      "Epoch 232/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 429.1384 - mean_squared_error: 356.0500\n",
      "Epoch 233/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 428.7104 - mean_squared_error: 355.5845\n",
      "Epoch 234/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 428.2376 - mean_squared_error: 355.0764\n",
      "Epoch 235/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 427.8125 - mean_squared_error: 354.6200\n",
      "Epoch 236/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 427.3817 - mean_squared_error: 354.1489\n",
      "Epoch 237/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 426.9325 - mean_squared_error: 353.6583\n",
      "Epoch 238/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 426.4982 - mean_squared_error: 353.1875\n",
      "Epoch 239/250\n",
      "10447/10447 [==============================] - 0s 3us/step - loss: 426.0619 - mean_squared_error: 352.7206\n",
      "Epoch 240/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 425.6142 - mean_squared_error: 352.2332\n",
      "Epoch 241/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 425.2010 - mean_squared_error: 351.7815\n",
      "Epoch 242/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 424.7971 - mean_squared_error: 351.3439\n",
      "Epoch 243/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 424.3523 - mean_squared_error: 350.8671\n",
      "Epoch 244/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 423.8952 - mean_squared_error: 350.3719\n",
      "Epoch 245/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 423.5094 - mean_squared_error: 349.9500\n",
      "Epoch 246/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 423.0728 - mean_squared_error: 349.4877\n",
      "Epoch 247/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 422.6603 - mean_squared_error: 349.0360\n",
      "Epoch 248/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 422.2232 - mean_squared_error: 348.5607\n",
      "Epoch 249/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 421.7996 - mean_squared_error: 348.1096\n",
      "Epoch 250/250\n",
      "10447/10447 [==============================] - 0s 2us/step - loss: 421.3990 - mean_squared_error: 347.6666\n",
      "259/259 [==============================] - 0s 68us/step\n",
      "Loading data for dataset 2 with window_size of 11, stride of 6 and maxRUL of 120. Cros-Validation ratio 0\n",
      "Loading data from memory and recomputing dataframes\n",
      "Epoch 1/250\n",
      "8631/8631 [==============================] - 0s 15us/step - loss: 14256.5614 - mean_squared_error: 14249.5881\n",
      "Epoch 2/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 13839.0796 - mean_squared_error: 13832.0379\n",
      "Epoch 3/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 13345.8858 - mean_squared_error: 13338.5556\n",
      "Epoch 4/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 12787.9184 - mean_squared_error: 12780.0708\n",
      "Epoch 5/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 12176.4799 - mean_squared_error: 12167.8906\n",
      "Epoch 6/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 11519.1473 - mean_squared_error: 11509.5992\n",
      "Epoch 7/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 10824.0330 - mean_squared_error: 10813.3309\n",
      "Epoch 8/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 10101.4321 - mean_squared_error: 10089.3798\n",
      "Epoch 9/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 9361.9169 - mean_squared_error: 9348.3465\n",
      "Epoch 10/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 8616.6269 - mean_squared_error: 8601.3807\n",
      "Epoch 11/250\n",
      "8631/8631 [==============================] - 0s 3us/step - loss: 7877.3344 - mean_squared_error: 7860.2688\n",
      "Epoch 12/250\n",
      "8631/8631 [==============================] - 0s 3us/step - loss: 7154.9314 - mean_squared_error: 7135.9382\n",
      "Epoch 13/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 6459.6433 - mean_squared_error: 6438.6281\n",
      "Epoch 14/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 5800.2470 - mean_squared_error: 5777.1574\n",
      "Epoch 15/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 5183.7837 - mean_squared_error: 5158.5761\n",
      "Epoch 16/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 4616.1272 - mean_squared_error: 4588.8003\n",
      "Epoch 17/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 4100.6621 - mean_squared_error: 4071.2502\n",
      "Epoch 18/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8631/8631 [==============================] - 0s 3us/step - loss: 3639.2451 - mean_squared_error: 3607.8016\n",
      "Epoch 19/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 3231.9252 - mean_squared_error: 3198.5249\n",
      "Epoch 20/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 2876.8062 - mean_squared_error: 2841.5576\n",
      "Epoch 21/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 2570.9785 - mean_squared_error: 2533.9933\n",
      "Epoch 22/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 2310.3989 - mean_squared_error: 2271.8184\n",
      "Epoch 23/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 2090.0989 - mean_squared_error: 2050.0575\n",
      "Epoch 24/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1905.5180 - mean_squared_error: 1864.1675\n",
      "Epoch 25/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1751.6713 - mean_squared_error: 1709.1493\n",
      "Epoch 26/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1623.7611 - mean_squared_error: 1580.2100\n",
      "Epoch 27/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1517.5894 - mean_squared_error: 1473.1345\n",
      "Epoch 28/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1429.2974 - mean_squared_error: 1384.0687\n",
      "Epoch 29/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1355.7847 - mean_squared_error: 1309.8819\n",
      "Epoch 30/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1294.1218 - mean_squared_error: 1247.6684\n",
      "Epoch 31/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1242.0955 - mean_squared_error: 1195.1903\n",
      "Epoch 32/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1197.8921 - mean_squared_error: 1150.6016\n",
      "Epoch 33/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1160.0791 - mean_squared_error: 1112.4838\n",
      "Epoch 34/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1127.4891 - mean_squared_error: 1079.6414\n",
      "Epoch 35/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1099.1992 - mean_squared_error: 1051.1890\n",
      "Epoch 36/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1074.5405 - mean_squared_error: 1026.3776\n",
      "Epoch 37/250\n",
      "8631/8631 [==============================] - 0s 3us/step - loss: 1052.7354 - mean_squared_error: 1004.4961\n",
      "Epoch 38/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1033.4355 - mean_squared_error: 985.1350\n",
      "Epoch 39/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1016.2322 - mean_squared_error: 967.9119\n",
      "Epoch 40/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 1000.7109 - mean_squared_error: 952.3946\n",
      "Epoch 41/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 986.6958 - mean_squared_error: 938.4009\n",
      "Epoch 42/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 973.9092 - mean_squared_error: 925.6804\n",
      "Epoch 43/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 962.1910 - mean_squared_error: 914.0219\n",
      "Epoch 44/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 951.3828 - mean_squared_error: 903.2765\n",
      "Epoch 45/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 941.3385 - mean_squared_error: 893.2959\n",
      "Epoch 46/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 931.9191 - mean_squared_error: 883.9659\n",
      "Epoch 47/250\n",
      "8631/8631 [==============================] - 0s 3us/step - loss: 923.0554 - mean_squared_error: 875.1991\n",
      "Epoch 48/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 914.6928 - mean_squared_error: 866.9318\n",
      "Epoch 49/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 906.7086 - mean_squared_error: 859.0543\n",
      "Epoch 50/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 899.0991 - mean_squared_error: 851.5588\n",
      "Epoch 51/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 891.7660 - mean_squared_error: 844.2982\n",
      "Epoch 52/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 884.7141 - mean_squared_error: 837.3418\n",
      "Epoch 53/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 877.8940 - mean_squared_error: 830.6106\n",
      "Epoch 54/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 871.1961 - mean_squared_error: 824.0104\n",
      "Epoch 55/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 864.7779 - mean_squared_error: 817.6795\n",
      "Epoch 56/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 858.4882 - mean_squared_error: 811.4886\n",
      "Epoch 57/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 852.2716 - mean_squared_error: 805.3439\n",
      "Epoch 58/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 846.2199 - mean_squared_error: 799.3577\n",
      "Epoch 59/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 840.2854 - mean_squared_error: 793.4791\n",
      "Epoch 60/250\n",
      "8631/8631 [==============================] - 0s 3us/step - loss: 834.4806 - mean_squared_error: 787.7463\n",
      "Epoch 61/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 828.6735 - mean_squared_error: 782.0155\n",
      "Epoch 62/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 822.9996 - mean_squared_error: 776.3703\n",
      "Epoch 63/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 817.4227 - mean_squared_error: 770.8446\n",
      "Epoch 64/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 811.9163 - mean_squared_error: 765.3701\n",
      "Epoch 65/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 806.4440 - mean_squared_error: 759.9226\n",
      "Epoch 66/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 801.0718 - mean_squared_error: 754.5744\n",
      "Epoch 67/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 795.7624 - mean_squared_error: 749.2719\n",
      "Epoch 68/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 790.4830 - mean_squared_error: 744.0277\n",
      "Epoch 69/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 785.2537 - mean_squared_error: 738.7881\n",
      "Epoch 70/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 780.1802 - mean_squared_error: 733.7429\n",
      "Epoch 71/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 775.0289 - mean_squared_error: 728.5608\n",
      "Epoch 72/250\n",
      "8631/8631 [==============================] - 0s 2us/step - loss: 770.0099 - mean_squared_error: 723.5130\n",
      "Epoch 73/250\n",
      " 512/8631 [>.............................] - ETA: 0s - loss: 743.8296 - mean_squared_error: 697.3306"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9e8d77c79d2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     tempResults = differential_evolution(nn_optmize_fun, bounds, \n\u001b[0;32m     31\u001b[0m                                      \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                                     strategy='best1bin', maxiter=30, popsize=4, disp=True, polish=False)\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdatasetNumber\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtempResults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mendTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py\u001b[0m in \u001b[0;36mdifferential_evolution\u001b[1;34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, callback, disp, polish, init, atol)\u001b[0m\n\u001b[0;32m    211\u001b[0m                                          \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m                                          disp=disp, init=init, atol=atol)\n\u001b[1;32m--> 213\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[1;31m# initial energies to be calculated (the following loop isn't run).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation_energies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calculate_population_energies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;31m# do the optimisation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py\u001b[0m in \u001b[0;36m_calculate_population_energies\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scale_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m             self.population_energies[index] = self.func(parameters,\n\u001b[1;32m--> 590\u001b[1;33m                                                         *self.args)\n\u001b[0m\u001b[0;32m    591\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-8ee4342b1987>\u001b[0m in \u001b[0;36mnn_optmize_fun\u001b[1;34m(x, tModel, verbose, epochs, saveToFile, iterations)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m#Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mtModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearningRate_scheduler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\NASA_RUL_-CMAPS-\\code\\tunable_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self, verbose, learningRate_scheduler)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mlearningRate_scheduler\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlearningRate_scheduler\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    203\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[0;32m    117\u001b[0m            (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[1;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[0;32m   4117\u001b[0m     \"\"\"\n\u001b[0;32m   4118\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[1;32m-> 4119\u001b[1;33m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[0;32m   4120\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4121\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   4031\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4033\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4034\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_median\u001b[1;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[0;32m   4150\u001b[0m             \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4152\u001b[1;33m         \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4154\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    658\u001b[0m     \"\"\"\n\u001b[0;32m    659\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 660\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    661\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Optimize the parameters for the NN using DE\n",
    "\n",
    "#maxWindowSize = {'1':30, '2':20, '3':30, '4':18}\n",
    "maxWindowSize = {'1':30, '2':20} #Do it only for datasets 1 and 2\n",
    "totalTime = {'1':0, '2':0, '3':0, '4':0}\n",
    "results = {'1':0, '2':0, '3':0, '4':0}\n",
    "\n",
    "#datasetNumber = '1'\n",
    "\n",
    "selected_features = ['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'htBleed', 'W31', 'W32']\n",
    "\n",
    "\n",
    "\n",
    "for datasetNumber in maxWindowSize:\n",
    "    \n",
    "    print(\"Tunning for dataset \"+datasetNumber)\n",
    "    file = open(\"results/MLP/intermediateResults_refactorized_\"+datasetNumber+\".csv\", \"w\")\n",
    "\n",
    "    windowSizeBounds = [1,maxWindowSize[datasetNumber]]\n",
    "    windowStrideBounds = [1,10]\n",
    "    constantRULBounds = [90,140]\n",
    "\n",
    "    bounds = [windowSizeBounds, windowStrideBounds, constantRULBounds]\n",
    "    #bounds = [windowStrideBounds, constantRULBounds] #Optimize only 2 variabes\n",
    "    \n",
    "    tModel.data_handler.change_dataset(datasetNumber)\n",
    "\n",
    "    startTime = time.clock()\n",
    "    tempResults = differential_evolution(nn_optmize_fun, bounds, \n",
    "                                     args=(tModel, 0, 20, file, 1),\n",
    "                                    strategy='best1bin', maxiter=30, popsize=4, disp=True, polish=False)\n",
    "    results[datasetNumber] = tempResults\n",
    "    endTime = time.clock()\n",
    "\n",
    "    file.close()\n",
    "    totalTime[datasetNumber] = endTime - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'totalTime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9b53b964db5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Total time {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotalTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'totalTime' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Total time {}\".format(totalTime))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
