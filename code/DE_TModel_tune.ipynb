{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import custom_scores\n",
    "import CMAPSAuxFunctions\n",
    "from tunableModels import TunableModel\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "\n",
    "from scipy.optimize import differential_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RULmodel_SN_1(input_shape):\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(250, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', name='fc1'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(50, activation='relu', kernel_initializer='glorot_normal', name='fc2'))\n",
    "    #model.add(Dense(5, activation='relu', kernel_initializer='glorot_normal', name='fc3'))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(Dense(10, activation='relu', name='fc3'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(10, activation='tanh', name='fc4'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    #create a placeholder for the input\n",
    "    #X_input = Input(shape=(input_shape))\n",
    "    \n",
    "    #Create the layers\n",
    "    #X = Dense(100, activation='relu', name='fc1')(X_input)\n",
    "    #X = Dense(100, activation='relu', name='fc2')(X)\n",
    "    #X = Dense(1, activation='linear', name='out')(X)\n",
    "    \n",
    "    # Create model. This creates the Keras model instance, you'll use this instance to train/test the model.\n",
    "    #model = Sequential(inputs = X_input, outputs = X, name='RUL')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_optmize_fun(x, selected_features=['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'htBleed', 'W31', 'W32'], datasetNumber = '1', scaler = None, verbose=0, epochs=250, \n",
    "                  saveToFile = None, iterations = 0):\n",
    "    \n",
    "    #Clear the previous tensorflow graph\n",
    "    K.clear_session()\n",
    "    \n",
    "    #Extract the tunning variables from the input vector\n",
    "    #Round the values to the nearest integer since this implementation is for real numbers\n",
    "    x = x.astype(int)\n",
    "    windows_size = x[0]\n",
    "    window_stride = x[1]\n",
    "    constantRUL = x[2]\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Creating model\")\n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0, beta_1=0.5)\n",
    "    lossFunction = \"mean_squared_error\"\n",
    "    metrics = [\"mse\"]\n",
    "    \n",
    "    #Define the model\n",
    "    nFeatures = len(selected_features)\n",
    "    shapeSN = nFeatures*windows_size\n",
    "    modelRULSN = RULmodel_SN_1(shapeSN)\n",
    "    modelRULSN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "    #load the data using the selected parameters\n",
    "    tModel = TunableModel(selected_features, scaler = min_max_scaler, window_stride = window_stride, \n",
    "                          window_size = windows_size, constRul = constantRUL, datasetNumber = datasetNumber, \n",
    "                         epochs=epochs, generateCrossValidation=True, crossValRatio=0.10)\n",
    "    \n",
    "    tModel.loadData()\n",
    "    \n",
    "    #Add the models to the tunableModel object\n",
    "    tModel.addModel(\"RUL_SN_1_optmizable\", modelRULSN)\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Training model\")\n",
    "    #Train the model\n",
    "    lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "    tModel.trainCurrentModel(learningRateScheduler=lrate, verbose=verbose)\n",
    "    time = tModel.getModelTimes(tModel.currentModelName)\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Training time {}\".format(time))\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Assesing model performance\")\n",
    "    #Assess the model performance\n",
    "    tModel.evaluateCurrentModel([\"rhs\"])\n",
    "    cScores = tModel.getModelScores(tModel.currentModelName)\n",
    "    rmse = math.sqrt(cScores['score_1'])\n",
    "    rhs = cScores['rhs']\n",
    "    #print(\"The score for this model is: {}\".format(rmse))\n",
    "    \n",
    "    msgStr = \"The model variables are \" + str(x) + \"\\tThe scores are: [RMSE:{:.4f}, RHS:{:.4f}]\\n\".format(rmse, rhs)\n",
    "    \n",
    "    if saveToFile is not None:\n",
    "        #print(msgStr)\n",
    "        saveToFile.write(msgStr)\n",
    "    else:\n",
    "        print(msgStr)\n",
    "    \n",
    "    #Return RMSE as the performance metric to steer the search\n",
    "    return rmse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"testFile.txt\", \"w\") \n",
    "\n",
    "#Selected as per CNN paper\n",
    "selected_features = ['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'htBleed', 'W31', 'W32']\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "#res = nn_optmize_fun(np.array([30, 1, 125]), selected_features = selected_features, scaler = min_max_scaler, \n",
    "#                     datasetNumber = '1', verbose=1, epochs=20, saveToFile = file)\n",
    "\n",
    "file.close()\n",
    "#print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\controlslab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "differential_evolution step 1: f(x)= 11.5696\n",
      "differential_evolution step 2: f(x)= 11.5696\n",
      "differential_evolution step 3: f(x)= 11.5696\n",
      "differential_evolution step 4: f(x)= 11.5696\n",
      "differential_evolution step 5: f(x)= 11.2186\n",
      "differential_evolution step 6: f(x)= 11.2186\n",
      "differential_evolution step 7: f(x)= 11.2186\n",
      "differential_evolution step 8: f(x)= 11.2186\n",
      "differential_evolution step 9: f(x)= 11.2186\n",
      "differential_evolution step 10: f(x)= 11.2186\n"
     ]
    }
   ],
   "source": [
    "file = open(\"intermediateResults.txt\", \"w\")\n",
    "\n",
    "\n",
    "#Optimize the parameters for the NN using DE\n",
    "\n",
    "maxWindowSize = {'1':30, '2':20, '3':30, '4':30}\n",
    "datasetNumber = '1'\n",
    "\n",
    "selected_features = ['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'htBleed', 'W31', 'W32']\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "windowSizeBounds = [1,maxWindowSize[datasetNumber]]\n",
    "windowStrideBounds = [1,10]\n",
    "constantRULBounds = [80,140]\n",
    "\n",
    "bounds = [windowSizeBounds, windowStrideBounds, constantRULBounds]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "startTime = time.clock()\n",
    "results = differential_evolution(nn_optmize_fun, bounds, \n",
    "                                 args=(selected_features, datasetNumber, min_max_scaler, 0, 20, file, 1),\n",
    "                                strategy='best1bin', maxiter=10, popsize=10, disp=True)\n",
    "endTime = time.clock()\n",
    "\n",
    "file.close()\n",
    "totalTime = endTime - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time 1323.4547188695046\n",
      "     fun: 11.218635586550983\n",
      " message: 'Maximum number of iterations has been exceeded.'\n",
      "    nfev: 414\n",
      "     nit: 10\n",
      " success: False\n",
      "       x: array([ 23.80222429,   2.42969551, 105.57937921])\n"
     ]
    }
   ],
   "source": [
    "print(\"Total time {}\".format(totalTime))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model\n",
      "Training model\n",
      "Epoch 1/20\n",
      "9141/9141 [==============================] - 1s 64us/step - loss: 6841.9786 - mean_squared_error: 6841.9786\n",
      "Epoch 2/20\n",
      "9141/9141 [==============================] - 1s 55us/step - loss: 1820.7925 - mean_squared_error: 1820.7925\n",
      "Epoch 3/20\n",
      "9141/9141 [==============================] - 1s 56us/step - loss: 776.8217 - mean_squared_error: 776.8217\n",
      "Epoch 4/20\n",
      "9141/9141 [==============================] - 1s 55us/step - loss: 615.7692 - mean_squared_error: 615.7692\n",
      "Epoch 5/20\n",
      "9141/9141 [==============================] - 1s 55us/step - loss: 549.4608 - mean_squared_error: 549.4608\n",
      "Epoch 6/20\n",
      "9141/9141 [==============================] - 1s 55us/step - loss: 524.5251 - mean_squared_error: 524.5251\n",
      "Epoch 7/20\n",
      "9141/9141 [==============================] - 1s 55us/step - loss: 489.4189 - mean_squared_error: 489.4189\n",
      "Epoch 8/20\n",
      "9141/9141 [==============================] - 1s 55us/step - loss: 479.3290 - mean_squared_error: 479.3290\n",
      "Epoch 9/20\n",
      "9141/9141 [==============================] - 1s 56us/step - loss: 448.7217 - mean_squared_error: 448.7217\n",
      "Epoch 10/20\n",
      "9141/9141 [==============================] - 1s 55us/step - loss: 435.1585 - mean_squared_error: 435.1585\n",
      "Epoch 11/20\n",
      "9141/9141 [==============================] - 1s 56us/step - loss: 428.9530 - mean_squared_error: 428.9530\n",
      "Epoch 12/20\n",
      "9141/9141 [==============================] - 1s 55us/step - loss: 424.6336 - mean_squared_error: 424.6336\n",
      "Epoch 13/20\n",
      "9141/9141 [==============================] - 1s 56us/step - loss: 419.2003 - mean_squared_error: 419.2003\n",
      "Epoch 14/20\n",
      "9141/9141 [==============================] - 1s 55us/step - loss: 403.6562 - mean_squared_error: 403.6562\n",
      "Epoch 15/20\n",
      "9141/9141 [==============================] - 1s 55us/step - loss: 396.9156 - mean_squared_error: 396.9156\n",
      "Epoch 16/20\n",
      "9141/9141 [==============================] - 1s 56us/step - loss: 401.9806 - mean_squared_error: 401.9806\n",
      "Epoch 17/20\n",
      "9141/9141 [==============================] - 1s 56us/step - loss: 398.3325 - mean_squared_error: 398.3325\n",
      "Epoch 18/20\n",
      "9141/9141 [==============================] - 1s 55us/step - loss: 394.1400 - mean_squared_error: 394.1400\n",
      "Epoch 19/20\n",
      "9141/9141 [==============================] - 1s 55us/step - loss: 391.2461 - mean_squared_error: 391.2461\n",
      "Epoch 20/20\n",
      "9141/9141 [==============================] - 1s 55us/step - loss: 392.1157 - mean_squared_error: 392.1157\n",
      "Training time 10.450854490907659\n",
      "Assesing model performance\n",
      "The model variables are [ 25   2 105]\tThe scores are: [RMSE:11.8365, RHS:227.4909]\n",
      "\n",
      "11.836509165237445\n"
     ]
    }
   ],
   "source": [
    "#Selected as per CNN paper\n",
    "selected_features = ['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'htBleed', 'W31', 'W32']\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "res = nn_optmize_fun(np.array([25, 2, 105]), selected_features = selected_features, scaler = min_max_scaler, \n",
    "                     datasetNumber = '1', verbose=1, epochs=20, saveToFile = None)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotRUL(cycles, rulArray, engineUnit):\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.plot(cycles, rulArray, 'bo-', label='RUL')\n",
    "    plt.xlabel(\"Time (Cycle)\")\n",
    "    plt.ylabel(\"RUL\")\n",
    "    plt.title(\"Test Engine Unit #{}\".format(engineUnit))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def plot(tModel, engineUnit, selectedFeatures, time_window, constRUL, stride, y_test):\n",
    "\n",
    "    df = tModel.df_test\n",
    "    df_engine = df[df['Unit Number'] == engineUnit]\n",
    "    \n",
    "    X_test2, _, _, _ = CMAPSAuxFunctions.create_windowed_data(df_engine, selected_features, 'test', time_window=time_window, \n",
    "                                                     constRUL=constRUL, stride=stride)\n",
    "    \n",
    "    X_test2 = tModel.dataScaler.transform(X_test2)\n",
    "    nnPred = tModel.model.predict(X_test2)\n",
    "    \n",
    "    maxCycle = X_test2.shape[0]\n",
    "    faultCycle = y_test[engineUnit-1]\n",
    "    cycles = np.arange(maxCycle)\n",
    "    rulArray = np.arange(faultCycle, maxCycle+faultCycle)\n",
    "    rulArray[rulArray > constRUL] = constRUL\n",
    "    rulArray = np.flipud(rulArray)\n",
    "    \n",
    "    plotRUL(cycles, rulArray, engineUnit)\n",
    "    plt.plot(cycles, nnPred, 'go-', label='NN Pred')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
