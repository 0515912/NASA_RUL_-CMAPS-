{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully connected NN with tensorflow\n",
    "\n",
    "First we import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from data_handler_CMAPS import CMAPSDataHandler\n",
    "#import tensorflow.contrib.layers.xavier_initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_initialization(input_shape, output_shape):\n",
    "\n",
    "\n",
    "    X = tf.placeholder(tf.float32, input_shape, name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, output_shape, name=\"y\")\n",
    "    \n",
    "    weights = {}\n",
    "    biases = {}\n",
    "    \n",
    "    #Weights declaration\n",
    "        \n",
    "    W1 = tf.Variable(name=\"W1\", shape=(input_shape[1], 20), initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b1 =  tf.Variable(name=\"b1\", shape=(1, 20), initializer=tf.zeros_initializer())\n",
    "    weights[\"W1\"] = W1\n",
    "    biases[\"b1\"] = b1\n",
    "    \n",
    "    W2 = tf.Variable(name=\"W2\", shape=(20, 20), initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b2 =  tf.Variable(name=\"b2\", shape=(1, 20), initializer=tf.zeros_initializer())\n",
    "    weights[\"W2\"] = W2\n",
    "    biases[\"b2\"] = b2\n",
    "    \n",
    "    W3 = tf.Variable(name=\"W3\", shape=(20, output_shape), initializer=xavier_initializer())\n",
    "    b3 =  tf.Variable(name=\"b3\", shape=(1, output_shape), initializer=tf.zeros_initializer())\n",
    "    weights[\"W3\"] = W3\n",
    "    biases[\"b3\"] = b3\n",
    "    \n",
    "        \n",
    "    return (X, y, weights, biases)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(X, weights, biases):\n",
    "    \n",
    "    W1, b1 = weights[\"W1\"], biases[\"b1\"]\n",
    "    W2, b2 = weights[\"W2\"], biases[\"b2\"]\n",
    "    W2, b2 = weights[\"W3\"], biases[\"b3\"]\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    \n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    \n",
    "    out = tf.add(tf.matmul(W3, A2), b3)\n",
    "    \n",
    "    return out \n",
    "\n",
    "\n",
    "def train_ann(X, y, params, epochs, batch_size, display_step = 1, lamba2 = 0.0):\n",
    "    \n",
    "    input_shape = 2\n",
    "    output_shape = 1\n",
    "    \n",
    "    X, y, weights, biases = ann_initialization(input_shape, output_shape)\n",
    "    \n",
    "    predictions = multilayer_perceptron(X, weights, biases)\n",
    "    regularizers = lamba2*(tf.nn.l2_loss(weights[\"W1\"]) + tf.nn.l2_loss(weights[\"W2\"]))\n",
    "    cost = tf.metrics.mean_squared_error(predictions, y) + regularizers\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            avg_cost = 0.0\n",
    "            total_batch = int(X.shape[0]/batch_size)\n",
    "            X_batches = np.split(X, total_batch)\n",
    "            y_batches = np.split(y, total_batch)\n",
    "            \n",
    "            #Train with the minibatches\n",
    "            for i in range(total_batch):\n",
    "                batch_x, batch_y = X_batches[i], y_batches[i]\n",
    "                \n",
    "                _, c = sess.run([optimizer, cost], feed_dict={X:batch_x, y:batch_y})\n",
    "                avg_cost += c/total_batch\n",
    "                \n",
    "                if epoch%display_step == 0:\n",
    "                    print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "                    \n",
    "        print(\"Training complete!\")\n",
    "        print(\"Epoch:Final\", \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "        \n",
    "        return params    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Data Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for dataset 1 with window_size of 30, stride of 1 and maxRUL of 125. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(17731, 420)\n",
      "(17731, 1)\n",
      "Testing data (X, y)\n",
      "(100, 420)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.63253012 -0.18639634 -0.38048616 ..., -0.66666667  0.41085271\n",
      "   0.42723005]\n",
      " [-0.43373494 -0.09396119 -0.29473329 ..., -0.33333333  0.24031008\n",
      "   0.21817178]\n",
      " [-0.31325301 -0.26095487 -0.25894666 ..., -0.33333333  0.36434109\n",
      "   0.67274234]\n",
      " [-0.31325301 -0.48768258 -0.33760972 ..., -0.33333333  0.06976744\n",
      "   0.2604253 ]\n",
      " [-0.30120482 -0.48506649 -0.19074949 ..., -0.33333333  0.03875969\n",
      "   0.14609224]]\n",
      "[[ 125.]\n",
      " [ 125.]\n",
      " [ 125.]\n",
      " [ 125.]\n",
      " [ 125.]]\n",
      "Testing data (X, y)\n",
      "[[-0.69879518 -0.24089819 -0.55536799 ..., -0.16666667  0.03875969\n",
      "   0.27312897]\n",
      " [-0.09036145 -0.21037715 -0.37744767 ..., -0.5         0.03875969\n",
      "   0.01518917]\n",
      " [-0.0060241  -0.22127752 -0.10634706 ...,  0.16666667  0.2248062\n",
      "   0.04888152]\n",
      " [-0.25301205 -0.00414214 -0.13605672 ...,  0.16666667 -0.31782946\n",
      "   0.004971  ]\n",
      " [-0.1746988   0.06256813 -0.10263336 ...,  0.         -0.05426357\n",
      "   0.42916321]]\n",
      "[[ 112.]\n",
      " [  98.]\n",
      " [  69.]\n",
      " [  82.]\n",
      " [  91.]]\n"
     ]
    }
   ],
   "source": [
    "#Selected as per CNN paper\n",
    "features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "selected_features = list(features[i] for i in selected_indices-1)\n",
    "data_folder = '../CMAPSSData'\n",
    "\n",
    "window_size = 30\n",
    "window_stride = 1\n",
    "max_rul = 125\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "dHandler_cmaps = CMAPSDataHandler(data_folder, 1, selected_features, max_rul=max_rul,\n",
    "                                  sequence_length=window_size, sequence_stride=window_stride, \n",
    "                                  data_scaler=min_max_scaler)\n",
    "dHandler_cmaps.load_data(unroll=True, verbose=1, cross_validation_ratio=0)\n",
    "dHandler_cmaps.print_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-6d6817978bae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#Create the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mann_initialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-7afddc821afc>\u001b[0m in \u001b[0;36mann_initialization\u001b[0;34m(input_shape, output_shape)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#Weights declaration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"W1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"b1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W1\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "window_size = 30\n",
    "window_stride = 1\n",
    "max_rul = 125\n",
    "num_features = len(selected_features)\n",
    "shape = num_features*window_size\n",
    "\n",
    "\n",
    "#Create the model\n",
    "model = ann_initialization(shape, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
