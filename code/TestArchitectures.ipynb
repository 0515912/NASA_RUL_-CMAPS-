{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Test notebook for the C-MAPPS benchmark. Test different MLP architectures. \n",
    "\n",
    "First we import the necessary packages and create the global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import copy\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import custom_scores\n",
    "import CMAPSAuxFunctions\n",
    "from tunableModel import TunableModel\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define architectures\n",
    "\n",
    "Define each one of the different architectures to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clear the previous tensorflow graph\n",
    "K.clear_session()\n",
    "\n",
    "def RULmodel_SN_5(input_shape):\n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', name='fc1'))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def RULmodel_SN_6(input_shape):\n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', name='fc1'))\n",
    "    model.add(Dense(5, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', name='fc2'))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def RULmodel_SN_1(input_shape):\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(30, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', name='fc1'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(10, activation='relu', kernel_initializer='glorot_normal', name='fc2'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def RULmodel_SN_2(input_shape):\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(50, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', name='fc1'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(20, activation='relu', kernel_initializer='glorot_normal', name='fc2'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def RULmodel_SN_3(input_shape):\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(100, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', name='fc1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu', kernel_initializer='glorot_normal', name='fc2'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def RULmodel_SN_4(input_shape):\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(250, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', name='fc1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu', kernel_initializer='glorot_normal', name='fc2'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shared parameters for the models\n",
    "optimizer = Adam(lr=0, beta_1=0.5)\n",
    "lossFunction = \"mean_squared_error\"\n",
    "metrics = [\"mse\"]\n",
    "\n",
    "#Selected as per CNN paper\n",
    "selected_features = ['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'htBleed', 'W31', 'W32']\n",
    "\n",
    "#Selected from the results of running DE on the old model (250->50->1)\n",
    "windowSize = 20\n",
    "stride = 2\n",
    "constRUL = 125\n",
    "\n",
    "dataFolder = '../CMAPSSData'\n",
    "\n",
    "#Create and compile the models\n",
    "nFeatures = len(selected_features)\n",
    "shapeSN = nFeatures*windowSize\n",
    "modelRULSN = RULmodel_SN_1(shapeSN)\n",
    "modelRULSN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "tModel = TunableModel('ModelRUL_SN_1', modelRULSN, selected_features, dataFolder, window_size=windowSize,\n",
    "                      scaler = min_max_scaler, window_stride=stride, constRul = constRUL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model 1\n",
      "Computing for dataset 1\n",
      "Loading data for dataset 1 with window_size of 30, stride of 1 and constRUL of -1. Cros-Validation ratio 0\n",
      "Data loaded for dataset 1\n",
      "Iteration 1\n",
      "100/100 [==============================] - 0s 808us/step\n",
      "Iteration 2\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 3\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 4\n",
      "100/100 [==============================] - 0s 63us/step\n",
      "Iteration 5\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 6\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "Iteration 7\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 8\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 9\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 10\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "DescribeResult(nobs=10, minmax=(22.707267559087775, 25.600390622019813), mean=24.446310904034636, variance=0.8776479814192042, skewness=-0.8343267358537084, kurtosis=-0.5156580310059709)\n",
      "DescribeResult(nobs=10, minmax=(5502.9922450644335, 9339.243280169005), mean=7151.669276100705, variance=1487892.7806482506, skewness=0.3285240634984479, kurtosis=-0.9523759225860395)\n",
      "DescribeResult(nobs=10, minmax=(15.167585420990235, 15.72169521509818), mean=15.315122192293256, variance=0.025776477324139804, skewness=1.7030288426942932, kurtosis=2.2640392668136284)\n",
      "For model 2\n",
      "Computing for dataset 1\n",
      "Loading data for dataset 1 with window_size of 30, stride of 1 and constRUL of -1. Cros-Validation ratio 0\n",
      "Data loaded for dataset 1\n",
      "Iteration 1\n",
      "100/100 [==============================] - 0s 878us/step\n",
      "Iteration 2\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "Iteration 3\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 4\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 5\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "Iteration 6\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 7\n",
      "100/100 [==============================] - 0s 63us/step\n",
      "Iteration 8\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "Iteration 9\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "Iteration 10\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "DescribeResult(nobs=10, minmax=(24.04953221998299, 27.135769751381662), mean=25.782102174165374, variance=1.0635638676633115, skewness=-0.27336267835608336, kurtosis=-1.047264489225323)\n",
      "DescribeResult(nobs=10, minmax=(10308.36086309252, 1805195.212611822), mean=549900.8519409362, variance=401615855376.4068, skewness=0.7649337520165488, kurtosis=-0.7013952407171304)\n",
      "DescribeResult(nobs=10, minmax=(14.832626205392671, 15.279007686816385), mean=15.074342763548021, variance=0.01757140670737383, skewness=-0.48103050979773293, kurtosis=-0.42186000016489666)\n",
      "For model 3\n",
      "Computing for dataset 1\n",
      "Loading data for dataset 1 with window_size of 30, stride of 1 and constRUL of -1. Cros-Validation ratio 0\n",
      "Data loaded for dataset 1\n",
      "Iteration 1\n",
      "100/100 [==============================] - 0s 957us/step\n",
      "Iteration 2\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "Iteration 3\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "Iteration 4\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "Iteration 5\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 6\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "Iteration 7\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 8\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 9\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 10\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "DescribeResult(nobs=10, minmax=(25.16465775646472, 29.403911304450638), mean=27.02995414842449, variance=2.1495319267438364, skewness=0.10911884911112804, kurtosis=-1.251889420275952)\n",
      "DescribeResult(nobs=10, minmax=(9660.576668029587, 447153.12693319866), mean=93226.10790255998, variance=17384576022.801838, skewness=2.162618879540316, kurtosis=3.4791843313079456)\n",
      "DescribeResult(nobs=10, minmax=(15.346622803766877, 15.556028816296703), mean=15.44199386673588, variance=0.005968599190147799, skewness=0.18554324279280157, kurtosis=-1.4786281351033481)\n",
      "For model 4\n",
      "Computing for dataset 1\n",
      "Loading data for dataset 1 with window_size of 30, stride of 1 and constRUL of -1. Cros-Validation ratio 0\n",
      "Data loaded for dataset 1\n",
      "Iteration 1\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "Iteration 2\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "Iteration 3\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 4\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 5\n",
      "100/100 [==============================] - 0s 70us/step\n",
      "Iteration 6\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 7\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 8\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 9\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 10\n",
      "100/100 [==============================] - 0s 71us/step\n",
      "DescribeResult(nobs=10, minmax=(21.072731194603133, 31.047705229211385), mean=23.61653012552838, variance=8.380560922233883, skewness=1.8504440773783264, kurtosis=2.526068423481827)\n",
      "DescribeResult(nobs=10, minmax=(3977.4144471855925, 52199.015706663835), mean=15229.4367329286, variance=213734460.3565321, skewness=1.8222453473145617, kurtosis=2.2141443024276866)\n",
      "DescribeResult(nobs=10, minmax=(15.272863695055094, 15.877193795153289), mean=15.445352947945775, variance=0.027477824191655426, skewness=1.835694533753229, kurtosis=2.922945439417857)\n",
      "For model 5\n",
      "Computing for dataset 1\n",
      "Loading data for dataset 1 with window_size of 30, stride of 1 and constRUL of -1. Cros-Validation ratio 0\n",
      "Data loaded for dataset 1\n",
      "Iteration 1\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "Iteration 2\n",
      "100/100 [==============================] - 0s 71us/step\n",
      "Iteration 3\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 4\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 5\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 6\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 7\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 8\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "Iteration 9\n",
      "100/100 [==============================] - 0s 51us/step\n",
      "Iteration 10\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "DescribeResult(nobs=10, minmax=(27.240411156955762, 33.072344942564925), mean=29.613108612886673, variance=4.455331423752391, skewness=0.5337075443243722, kurtosis=-0.8989051732142759)\n",
      "DescribeResult(nobs=10, minmax=(8778.811204709304, 29092.526190601362), mean=18443.82475619454, variance=43652083.78603516, skewness=0.18368343811171206, kurtosis=-1.0828972037772404)\n",
      "DescribeResult(nobs=10, minmax=(13.458893037979806, 13.81098765155184), mean=13.548028997690608, variance=0.010710960355387298, skewness=1.7738068693608935, kurtosis=2.302709845506569)\n",
      "For model 6\n",
      "Computing for dataset 1\n",
      "Loading data for dataset 1 with window_size of 30, stride of 1 and constRUL of -1. Cros-Validation ratio 0\n",
      "Data loaded for dataset 1\n",
      "Iteration 1\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "Iteration 2\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "Iteration 3\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 4\n",
      "100/100 [==============================] - 0s 60us/step\n",
      "Iteration 5\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 8\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 9\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 10\n",
      "100/100 [==============================] - 0s 60us/step\n",
      "DescribeResult(nobs=10, minmax=(26.031519356349524, 33.334366650650495), mean=28.72844739092803, variance=4.941456118533977, skewness=0.48641067325965504, kurtosis=0.01163919760440324)\n",
      "DescribeResult(nobs=10, minmax=(16663.145566901636, 177319.03504491347), mean=62165.145190305404, variance=2633336183.300333, skewness=1.2089053600737731, kurtosis=0.4556976617442361)\n",
      "DescribeResult(nobs=10, minmax=(14.16375152136925, 15.00340113829634), mean=14.462498317716495, variance=0.06159572840399764, skewness=0.9869233767162798, kurtosis=0.3337021099468669)\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "tModel.epochs = 100\n",
    "lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "\n",
    "windowSize = 30\n",
    "windowStride = 1\n",
    "constRul = -1\n",
    "nFeatures = len(selected_features)\n",
    "shapeSN = nFeatures*windowSize\n",
    "\n",
    "models = {1:RULmodel_SN_1,2:RULmodel_SN_2,3:RULmodel_SN_3,4:RULmodel_SN_4, 5:RULmodel_SN_5, 6:RULmodel_SN_6}\n",
    "\n",
    "file = open(\"ResultsDataset1_NoConstRUL.csv\", \"w\")\n",
    "csvfile = csv.writer(file, lineterminator='\\n')\n",
    "\n",
    "for key, model in models.items():\n",
    "    \n",
    "    print(\"For model \"+str(key))\n",
    "    #file.write(\"For model \"+str(key)+'\\n\\n')\n",
    "    \n",
    "    for i in range(1,2):\n",
    "\n",
    "        dataset = i\n",
    "        print(\"Computing for dataset \"+str(i))\n",
    "        #file.write(\"Computing for dataset \"+str(i)+'\\n\\n')\n",
    "        \n",
    "        #Create and compile the models\n",
    "        modelRULSN = model(shapeSN)\n",
    "        modelRULSN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "        tModel.changeModel('ModelRUL_SN_Dat'+str(shapeSN), modelRULSN)\n",
    "        tModel.windowSize = windowSize\n",
    "        tModel.windowStride = windowStride\n",
    "        tModel.constRul = constRul\n",
    "        tModel.changeDataset(dataset)\n",
    "        tModel.loadData(verbose=1, rectify_labels = False)\n",
    "        tempScoresRMSE = np.zeros((iterations,1))\n",
    "        tempScoresRHS = np.zeros((iterations,1))\n",
    "        tempTime = np.zeros((iterations,1))\n",
    "\n",
    "        for j in range(iterations):\n",
    "\n",
    "            print(\"Iteration \"+str(j+1))\n",
    "            #file.write(\"Iteration \"+str(j+1)+'\\n\\n')\n",
    "            tModel.trainModel(learningRateScheduler=lrate, verbose=0)\n",
    "            tModel.evaluateModel([\"rhs\"], round=2)\n",
    "\n",
    "            cScores = tModel.scores\n",
    "            rmse = math.sqrt(cScores['score_1'])\n",
    "            rmse2 = cScores['rmse']\n",
    "            rhs = cScores['rhs']\n",
    "            time = tModel.trainTime\n",
    "\n",
    "            tempScoresRMSE[j] = rmse2\n",
    "            tempScoresRHS[j] = rhs\n",
    "            tempTime[j] = time\n",
    "\n",
    "        #print(tempScoresRMSE)\n",
    "        tempScoresRMSE = np.reshape(tempScoresRMSE, (iterations,))\n",
    "        tempScoresRHS = np.reshape(tempScoresRHS, (iterations,))\n",
    "        tempTime = np.reshape(tempTime, (iterations,))\n",
    "        csvfile.writerow(tempScoresRMSE)\n",
    "        csvfile.writerow(tempScoresRHS)\n",
    "        csvfile.writerow(tempTime)\n",
    "        #file.write(str(stats.describe(tempScoresRMSE))+'\\n\\n')\n",
    "        #file.write(str(stats.describe(tempScoresRHS))+'\\n\\n')\n",
    "        #file.write(str(stats.describe(tempTime))+'\\n\\n')\n",
    "        print(stats.describe(tempScoresRMSE))\n",
    "        print(stats.describe(tempScoresRHS))\n",
    "        print(stats.describe(tempTime))\n",
    "        \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on all datasets\n",
    "\n",
    "Test the choosen model on the four datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model 5\n",
      "Computing for dataset 1\n",
      "Loading data for dataset 1 with window_size of 30, stride of 2 and constRUL of 125. Cros-Validation ratio 0\n",
      "Data loaded for dataset 1\n",
      "Iteration 1\n",
      "100/100 [==============================] - 0s 319us/step\n",
      "Iteration 2\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 3\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 4\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 5\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 6\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 7\n",
      "100/100 [==============================] - 0s 30us/step\n",
      "Iteration 8\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 9\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "Iteration 10\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "DescribeResult(nobs=10, minmax=(15.517087355557422, 16.051479682571323), mean=15.677191455539504, variance=0.02629785151018782, skewness=1.3724067797874253, kurtosis=0.8825784067903193)\n",
      "DescribeResult(nobs=10, minmax=(428.4161046734106, 532.4403160307482), mean=486.3560518442708, variance=1645.271973234857, skewness=-0.07006598021031034, kurtosis=-1.6423539327881957)\n",
      "DescribeResult(nobs=10, minmax=(7.038685449076979, 7.399176851389484), mean=7.262922740766465, variance=0.016486327233843794, skewness=-0.9454162145236346, kurtosis=-0.6083106758085775)\n",
      "Computing for dataset 2\n",
      "Loading data for dataset 2 with window_size of 20, stride of 2 and constRUL of 125. Cros-Validation ratio 0\n",
      "Data loaded for dataset 2\n",
      "Iteration 1\n",
      "259/259 [==============================] - 0s 154us/step\n",
      "Iteration 2\n",
      "259/259 [==============================] - 0s 42us/step\n",
      "Iteration 3\n",
      "259/259 [==============================] - 0s 31us/step\n",
      "Iteration 4\n",
      "259/259 [==============================] - 0s 62us/step\n",
      "Iteration 5\n",
      "259/259 [==============================] - 0s 39us/step\n",
      "Iteration 6\n",
      "259/259 [==============================] - 0s 27us/step\n",
      "Iteration 7\n",
      "259/259 [==============================] - 0s 31us/step\n",
      "Iteration 8\n",
      "259/259 [==============================] - 0s 31us/step\n",
      "Iteration 9\n",
      "259/259 [==============================] - 0s 35us/step\n",
      "Iteration 10\n",
      "259/259 [==============================] - 0s 31us/step\n",
      "DescribeResult(nobs=10, minmax=(29.786110105422548, 33.15856371271752), mean=30.886579879108815, variance=1.3057421415723294, skewness=1.0050599149588326, kurtosis=-0.35667844647183333)\n",
      "DescribeResult(nobs=10, minmax=(15772.678757217382, 29965.83943819689), mean=21146.756660599476, variance=27781931.277655736, skewness=0.7580470906339464, kurtosis=-0.9637707167554312)\n",
      "DescribeResult(nobs=10, minmax=(17.556372831073418, 18.15255190210189), mean=17.761375088746558, variance=0.03576771864577026, skewness=0.8524705815718334, kurtosis=-0.2014981583217086)\n",
      "Computing for dataset 3\n",
      "Loading data for dataset 3 with window_size of 30, stride of 2 and constRUL of 125. Cros-Validation ratio 0\n",
      "Data loaded for dataset 3\n",
      "Iteration 1\n",
      "100/100 [==============================] - 0s 429us/step\n",
      "Iteration 2\n",
      "100/100 [==============================] - 0s 30us/step\n",
      "Iteration 3\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 4\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 5\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 6\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 7\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "Iteration 8\n",
      "100/100 [==============================] - 0s 110us/step\n",
      "Iteration 9\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 10\n",
      "100/100 [==============================] - 0s 30us/step\n",
      "DescribeResult(nobs=10, minmax=(15.23745385554949, 17.570998833304838), mean=15.857769291614073, variance=0.5379478821574074, skewness=1.5228757541952993, kurtosis=1.0279779685871313)\n",
      "DescribeResult(nobs=10, minmax=(398.63052556329393, 559.1594705573816), mean=446.2958640181863, variance=2364.473196781001, skewness=1.283375748253353, kurtosis=0.8866293008797745)\n",
      "DescribeResult(nobs=10, minmax=(8.707653268213562, 9.075762245073065), mean=8.870306331627352, variance=0.01125392256422858, skewness=0.15298101622673346, kurtosis=-0.07353273628272694)\n",
      "Computing for dataset 4\n",
      "Loading data for dataset 4 with window_size of 18, stride of 2 and constRUL of 125. Cros-Validation ratio 0\n",
      "Data loaded for dataset 4\n",
      "Iteration 1\n",
      "248/248 [==============================] - 0s 197us/step\n",
      "Iteration 2\n",
      "248/248 [==============================] - 0s 24us/step\n",
      "Iteration 3\n",
      "248/248 [==============================] - 0s 28us/step\n",
      "Iteration 4\n",
      "248/248 [==============================] - 0s 32us/step\n",
      "Iteration 5\n",
      "248/248 [==============================] - 0s 36us/step\n",
      "Iteration 6\n",
      "248/248 [==============================] - 0s 44us/step\n",
      "Iteration 7\n",
      "248/248 [==============================] - 0s 28us/step\n",
      "Iteration 8\n",
      "248/248 [==============================] - 0s 28us/step\n",
      "Iteration 9\n",
      "248/248 [==============================] - 0s 24us/step\n",
      "Iteration 10\n",
      "248/248 [==============================] - 0s 32us/step\n",
      "DescribeResult(nobs=10, minmax=(33.14198438585502, 37.85461364475337), mean=34.610347996183975, variance=1.9534286406586245, skewness=1.2593064229463768, kurtosis=0.9301475849642129)\n",
      "DescribeResult(nobs=10, minmax=(13355.14543709025, 21817.57927350582), mean=16573.11887177214, variance=5817012.816780189, skewness=0.8267133706885699, kurtosis=0.3532166488429871)\n",
      "DescribeResult(nobs=10, minmax=(19.010949227222227, 19.963691934401595), mean=19.436060209168772, variance=0.09890965583841489, skewness=0.02506525469492928, kurtosis=-1.0336979368144783)\n"
     ]
    }
   ],
   "source": [
    "datasets = [1,2,3,4]\n",
    "iterations = 10\n",
    "tModel.epochs = 100\n",
    "lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "scores ={1:[], 2:[], 3:[], 4:[]}\n",
    "windowSizes = {1:30,2:20,3:30,4:18}\n",
    "strides = {1:2,2:2,3:2,4:2}\n",
    "constRUL = {1:125, 2:125, 3:125, 4:125}\n",
    "#models = {1:RULmodel_SN_1,2:RULmodel_SN_2,3:RULmodel_SN_3,4:RULmodel_SN_4, 5:RULmodel_SN_5, 6:RULmodel_SN_6}\n",
    "models = {5:RULmodel_SN_5}\n",
    "\n",
    "file = open(\"ResultsAllDatasets4.csv\", \"w\")\n",
    "csvfile = csv.writer(file, lineterminator='\\n')\n",
    "\n",
    "for key, model in models.items():\n",
    "    \n",
    "    print(\"For model \"+str(key))\n",
    "    #file.write(\"For model \"+str(key)+'\\n\\n')\n",
    "    \n",
    "    for i in range(1,5):\n",
    "\n",
    "        dataset = i\n",
    "        print(\"Computing for dataset \"+str(i))\n",
    "        #file.write(\"Computing for dataset \"+str(i)+'\\n\\n')\n",
    "\n",
    "        #Create and compile the models\n",
    "        windowSize = windowSizes[i]\n",
    "        nFeatures = len(selected_features)\n",
    "        shapeSN = nFeatures*windowSize\n",
    "        modelRULSN = model(shapeSN)\n",
    "        modelRULSN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "        tModel.changeModel('ModelRUL_SN_Dat'+str(shapeSN), modelRULSN)\n",
    "        tModel.windowSize = windowSize\n",
    "        tModel.windowStride = strides[i]\n",
    "        tModel.constRul = constRUL[i]\n",
    "        tModel.changeDataset(dataset)\n",
    "        tModel.loadData(verbose=1, rectify_labels = False)\n",
    "        tempScoresRMSE = np.zeros((iterations,1))\n",
    "        tempScoresRHS = np.zeros((iterations,1))\n",
    "        tempTime = np.zeros((iterations,1))\n",
    "\n",
    "        for j in range(iterations):\n",
    "\n",
    "            print(\"Iteration \"+str(j+1))\n",
    "            #file.write(\"Iteration \"+str(j+1)+'\\n\\n')\n",
    "            tModel.trainModel(learningRateScheduler=lrate, verbose=0)\n",
    "            tModel.evaluateModel([\"rhs\"], round=2)\n",
    "\n",
    "            cScores = tModel.scores\n",
    "            rmse = math.sqrt(cScores['score_1'])\n",
    "            rmse2 = cScores['rmse']\n",
    "            rhs = cScores['rhs']\n",
    "            time = tModel.trainTime\n",
    "\n",
    "            tempScoresRMSE[j] = rmse2\n",
    "            tempScoresRHS[j] = rhs\n",
    "            tempTime[j] = time\n",
    "\n",
    "        #print(tempScoresRMSE)\n",
    "        tempScoresRMSE = np.reshape(tempScoresRMSE, (iterations,))\n",
    "        tempScoresRHS = np.reshape(tempScoresRHS, (iterations,))\n",
    "        tempTime = np.reshape(tempTime, (iterations,))\n",
    "        csvfile.writerow(tempScoresRMSE)\n",
    "        csvfile.writerow(tempScoresRHS)\n",
    "        csvfile.writerow(tempTime)\n",
    "        #file.write(str(stats.describe(tempScoresRMSE))+'\\n\\n')\n",
    "        #file.write(str(stats.describe(tempScoresRHS))+'\\n\\n')\n",
    "        #file.write(str(stats.describe(tempTime))+'\\n\\n')\n",
    "        print(stats.describe(tempScoresRMSE))\n",
    "        print(stats.describe(tempScoresRHS))\n",
    "        print(stats.describe(tempTime))\n",
    "        \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Best Model\n",
    "\n",
    "Save the model and weights of the best model throughout 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "100/100 [==============================] - 0s 291us/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tempScoresRMSE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1bce8eea1a0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mbestIndex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mtempScoresRMSE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmse2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[0mtempScoresRHS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrhs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mtempTime\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tempScoresRMSE' is not defined"
     ]
    }
   ],
   "source": [
    "#Clear the previous tensorflow graph\n",
    "K.clear_session()\n",
    "\n",
    "def RULmodel_SN_1(input_shape):\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(30, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', name='fc1'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(10, activation='relu', kernel_initializer='glorot_normal', name='fc2'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "#Shared parameters for the models\n",
    "optimizer = Adam(lr=0, beta_1=0.5)\n",
    "lossFunction = \"mean_squared_error\"\n",
    "metrics = [\"mse\"]\n",
    "\n",
    "#Selected as per CNN paper\n",
    "selected_features = ['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'htBleed', 'W31', 'W32']\n",
    "\n",
    "dataFolder = '../CMAPSSData'\n",
    "\n",
    "datasets = [1]\n",
    "iterations = 10\n",
    "lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "scores ={1:[], 2:[], 3:[], 4:[]}\n",
    "#windowSizes = {1:25,2:15,3:25,4:15}\n",
    "windowSizes = 15\n",
    "stride = 2\n",
    "#constRUL = {1:93, 2:94, 3:92, 4:94}\n",
    "constRUL = 95\n",
    "#models = {1:RULmodel_SN_1,2:RULmodel_SN_2,3:RULmodel_SN_3,4:RULmodel_SN_4}\n",
    "models = {1:RULmodel_SN_1}\n",
    "\n",
    "#Create and compile the model\n",
    "windowSize = 15\n",
    "nFeatures = len(selected_features)\n",
    "shapeSN = nFeatures*windowSize\n",
    "modelRULSN = RULmodel_SN_1(shapeSN)\n",
    "modelRULSN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "tModel = TunableModel('ModelRUL_SN_1', modelRULSN, selected_features, dataFolder, window_size=windowSize,\n",
    "                      scaler = min_max_scaler, window_stride=stride, constRul = constRUL)\n",
    "tModel.loadData()\n",
    "tModel.epochs = 200\n",
    "\n",
    "#file = open(\"ResultsBestModelAllDatasetsSingleSet.csv\", \"w\")\n",
    "#csvfile = csv.writer(file, lineterminator='\\n')\n",
    "\n",
    "min_rmse = 1000\n",
    "bestModel = None\n",
    "bestIndex = 0\n",
    "\n",
    "for i in range(iterations):\n",
    "\n",
    "    print(\"Iteration \"+str(i+1))\n",
    "    #file.write(\"Iteration \"+str(j+1)+'\\n\\n')\n",
    "    tModel.trainModel(learningRateScheduler=lrate, verbose=0)\n",
    "    tModel.evaluateModel([\"rhs\"], round=True)\n",
    "\n",
    "    cScores = tModel.scores\n",
    "    rmse = math.sqrt(cScores['score_1'])\n",
    "    rmse2 = cScores['rmse']\n",
    "    rhs = cScores['rhs']\n",
    "    time = tModel.trainTime\n",
    "\n",
    "    if rmse2 < min_rmse:\n",
    "        bestModel = tModel.model\n",
    "        bestIndex = i\n",
    "    \n",
    "    tempScoresRMSE[i] = rmse2\n",
    "    tempScoresRHS[i] = rhs\n",
    "    tempTime[i] = time\n",
    "\n",
    "print(tempScoresRMSE)    \n",
    "    \n",
    "#save best model to file\n",
    "# serialize model to JSON\n",
    "model_json = bestModel.to_json()\n",
    "with open(\"bestRULModel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "bestModel.save_weights(\"bestRULModel.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "        \n",
    "#file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
