{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Test notebook for the C-MAPPS benchmark. Test different MLP architectures. \n",
    "\n",
    "First we import the necessary packages and create the global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import copy\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import custom_scores\n",
    "from data_handler_CMAPS import CMAPSDataHandler\n",
    "from tunable_model import SequenceTunableModelRegression\n",
    "import CMAPSAuxFunctions\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "# print(tf.__version__sess = tf.Session(config=tf.ConfigProto(log_device_placement=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define architectures\n",
    "\n",
    "Define each one of the different architectures to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()  #Clear the previous tensorflow graph\n",
    "\n",
    "l2_lambda_regularization = 0.20\n",
    "l1_lambda_regularization = 0.10\n",
    "\n",
    "def RULmodel_LSTM(input_shape):\n",
    "    \"\"\"Define the RNN model\"\"\"\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    #model.add(Masking(mask_value=0, imput))\n",
    "    #model.add(LSTM(input_shape=input_shape, units=100, return_sequences=True, name='lstm1')))\n",
    "    model.add(LSTM(input_shape=input_shape, units=20, return_sequences=False, name='lstm2'))\n",
    "    model.add(Dense(10, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), name='fc1'))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def RULmodel_SN_4(input_shape):\n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), \n",
    "                    name='fc1'))\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), \n",
    "                    name='fc2'))\n",
    "    model.add(Dense(1, activation='linear', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), name='out'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RULmodel_SN_1(input_shape):\n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(250, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), \n",
    "                    name='fc1'))\n",
    "    model.add(Dense(50, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), \n",
    "                    name='fc2'))\n",
    "    model.add(Dense(1, activation='linear', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def RULmodel_SN_2(input_shape):\n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(100, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), \n",
    "                    name='fc1'))\n",
    "    model.add(Dense(50, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), \n",
    "                    name='fc2'))\n",
    "    model.add(Dense(1, activation='linear', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def RULmodel_SN_3(input_shape):\n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(50, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), \n",
    "                    name='fc1'))\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), \n",
    "                    name='fc2'))\n",
    "    model.add(Dense(1, activation='linear', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def RULmodel_SN_5(input_shape):\n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(50, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), \n",
    "                    name='fc1'))\n",
    "    model.add(Dense(1, activation='linear', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def RULmodel_SN_6(input_shape):\n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(50, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), \n",
    "                    name='fc1'))\n",
    "    model.add(Dense(1, activation='linear', \n",
    "                    kernel_regularizer=regularizers.L1L2(l1_lambda_regularization, l2_lambda_regularization), name='out'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_compiled_model(model_def, shape, model_type='ann'):\n",
    "\n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0, beta_1=0.5)\n",
    "    lossFunction = \"mean_squared_error\"\n",
    "    metrics = [\"mse\"]\n",
    "    model = None\n",
    "\n",
    "    #Create and compile the models\n",
    "\n",
    "    if model_type=='ann':\n",
    "        model = model_def(shape)\n",
    "        model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    elif model_type=='lstm':\n",
    "        model = RULmodel_LSTM(shape)\n",
    "        model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the usable models for this notebook\n",
    "\n",
    "models = {'shallow-20-20':RULmodel_SN_4}\n",
    "\n",
    "#models = {'shallow-250-100':RULmodel_SN_4, 'shallow-100-50':RULmodel_SN_1, 'shallow-50-20':RULmodel_SN_2,\n",
    "#          'shallow-20-20':RULmodel_SN_3, 'shallow-20':RULmodel_SN_5, 'shallow-10':RULmodel_SN_6}\n",
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "selected_features = list(features[i] for i in selected_indices-1)\n",
    "data_folder = '../CMAPSSData'\n",
    "\n",
    "window_size = 30\n",
    "window_stride = 1\n",
    "max_rul = 128\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "dHandler_cmaps = CMAPSDataHandler(data_folder, 1, selected_features, max_rul, \n",
    "                                  window_size, window_stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0, beta_1=0.5)\n",
    "lossFunction = \"mean_squared_error\"\n",
    "metrics = [\"mse\"]\n",
    "\n",
    "\n",
    "#Create and compile the models\n",
    "nFeatures = len(selected_features)\n",
    "shapeSN = nFeatures*window_size\n",
    "shapeLSTM = (window_size,nFeatures)\n",
    "model = get_compiled_model(models['shallow-20-20'], shapeSN, model_type='ann')\n",
    "\n",
    "tModel = SequenceTunableModelRegression('ann20', model, lib_type='keras', data_handler=dHandler_cmaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for dataset 1 with window_size of 30, stride of 1 and maxRUL of 128. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(17731, 420)\n",
      "(17731,)\n",
      "Testing data (X, y)\n",
      "(100, 420)\n",
      "(100,)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.58075601 -0.0455243  -0.27982732 ... -0.81818182  0.43307087\n",
      "   0.4679733 ]\n",
      " [-0.35395189  0.0629156  -0.18014129 ... -0.45454545  0.25984252\n",
      "   0.25294702]\n",
      " [-0.21649485 -0.13299233 -0.13854003 ... -0.45454545  0.38582677\n",
      "   0.72049425]\n",
      " [-0.21649485 -0.39897698 -0.2299843  ... -0.45454545  0.08661417\n",
      "   0.29640676]\n",
      " [-0.20274914 -0.39590793 -0.05926217 ... -0.45454545  0.05511811\n",
      "   0.17880983]]\n",
      "[128. 128. 128. 128. 128.]\n",
      "Testing data (X, y)\n",
      "[[-0.65635739 -0.10946292 -0.48312402 ... -0.27272727  0.05511811\n",
      "   0.30947309]\n",
      " [ 0.03780069 -0.07365729 -0.27629513 ... -0.63636364  0.05511811\n",
      "   0.04416986]\n",
      " [ 0.13402062 -0.08644501  0.038854   ...  0.09090909  0.24409449\n",
      "   0.07882403]\n",
      " [-0.14776632  0.16828645  0.00431711 ...  0.09090909 -0.30708661\n",
      "   0.03365999]\n",
      " [-0.05841924  0.24654731  0.04317111 ... -0.09090909 -0.03937008\n",
      "   0.46996165]]\n",
      "[112.  98.  69.  82.  91.]\n"
     ]
    }
   ],
   "source": [
    "#For LSTM\n",
    "# tModel.data_handler.data_scaler = min_max_scaler\n",
    "# tModel.data_scaler = None\n",
    "\n",
    "#For ANN\n",
    "tModel.data_handler.data_scaler = None\n",
    "tModel.data_scaler = min_max_scaler\n",
    "\n",
    "tModel.data_handler.sequence_length = 30\n",
    "#tModel.data_handler.sequence_length = maxWindowSize[datasetNumber]\n",
    "tModel.data_handler.sequence_stride = 1\n",
    "tModel.data_handler.max_rul = 128\n",
    "\n",
    "tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0)\n",
    "tModel.print_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model shallow-250-100\n",
      "Computing for dataset 1\n",
      "100/100 [==============================] - 0s 489us/step\n",
      "100/100 [==============================] - 0s 568us/step\n",
      "100/100 [==============================] - 0s 668us/step\n",
      "100/100 [==============================] - 0s 768us/step\n",
      "100/100 [==============================] - 0s 878us/step\n",
      "100/100 [==============================] - 0s 957us/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "Results for model shallow-250-100\n",
      "DescribeResult(nobs=10, minmax=(array([15.44312145]), array([16.48544813])), mean=array([15.8214856]), variance=array([0.13954832]), skewness=array([0.70844646]), kurtosis=array([-0.91240078]))\n",
      "DescribeResult(nobs=10, minmax=(array([3.98989722]), array([6.4733304])), mean=array([5.19731842]), variance=array([0.77465176]), skewness=array([0.05257875]), kurtosis=array([-1.28455042]))\n",
      "DescribeResult(nobs=10, minmax=(array([9.37768724]), array([12.04274834])), mean=array([10.29368036]), variance=array([0.76996355]), skewness=array([1.0663643]), kurtosis=array([-0.18259191]))\n",
      "For model shallow-100-50\n",
      "Computing for dataset 1\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "100/100 [==============================] - 0s 3ms/step\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "Results for model shallow-100-50\n",
      "DescribeResult(nobs=10, minmax=(array([15.26138919]), array([17.61703721])), mean=array([15.96005971]), variance=array([0.58388217]), skewness=array([1.0330568]), kurtosis=array([0.12798463]))\n",
      "DescribeResult(nobs=10, minmax=(array([4.23529941]), array([8.36235797])), mean=array([5.50399351]), variance=array([1.69723146]), skewness=array([1.07260249]), kurtosis=array([0.2806006]))\n",
      "DescribeResult(nobs=10, minmax=(array([21.34646719]), array([22.69219563])), mean=array([22.12707653]), variance=array([0.2919281]), skewness=array([-0.41567132]), kurtosis=array([-1.59109017]))\n",
      "For model shallow-50-20\n",
      "Computing for dataset 1\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "100/100 [==============================] - 0s 3ms/step\n",
      "100/100 [==============================] - 0s 3ms/step\n",
      "100/100 [==============================] - 0s 3ms/step\n",
      "100/100 [==============================] - 0s 3ms/step\n",
      "100/100 [==============================] - 0s 3ms/step\n",
      "100/100 [==============================] - 0s 3ms/step\n",
      "100/100 [==============================] - 0s 3ms/step\n",
      "100/100 [==============================] - 0s 3ms/step\n",
      "100/100 [==============================] - 0s 4ms/step\n",
      "Results for model shallow-50-20\n",
      "DescribeResult(nobs=10, minmax=(array([15.2230089]), array([17.31328969])), mean=array([15.94452053]), variance=array([0.35251657]), skewness=array([1.24340027]), kurtosis=array([0.94596541]))\n",
      "DescribeResult(nobs=10, minmax=(array([3.90639534]), array([8.28506047])), mean=array([5.57486729]), variance=array([1.60050763]), skewness=array([0.96350884]), kurtosis=array([0.29689835]))\n",
      "DescribeResult(nobs=10, minmax=(array([15.66122939]), array([18.77310528])), mean=array([17.08979604]), variance=array([0.75843542]), skewness=array([0.29334198]), kurtosis=array([-0.1460667]))\n",
      "For model shallow-20-20\n",
      "Computing for dataset 1\n",
      "100/100 [==============================] - 0s 5ms/step\n",
      "100/100 [==============================] - 0s 5ms/step\n",
      "100/100 [==============================] - 0s 4ms/step\n",
      "100/100 [==============================] - 0s 4ms/step\n",
      "100/100 [==============================] - 0s 4ms/step\n",
      "100/100 [==============================] - 0s 4ms/step\n",
      "100/100 [==============================] - 0s 5ms/step\n",
      "100/100 [==============================] - 0s 4ms/step\n",
      "100/100 [==============================] - 0s 4ms/step\n",
      "100/100 [==============================] - 1s 6ms/step\n",
      "Results for model shallow-20-20\n",
      "DescribeResult(nobs=10, minmax=(array([14.89899325]), array([16.9085777])), mean=array([15.91221323]), variance=array([0.53274444]), skewness=array([0.19652973]), kurtosis=array([-1.35702904]))\n",
      "DescribeResult(nobs=10, minmax=(array([4.13583671]), array([8.03613555])), mean=array([5.54270781]), variance=array([2.0522123]), skewness=array([0.60714293]), kurtosis=array([-1.09730388]))\n",
      "DescribeResult(nobs=10, minmax=(array([15.14353845]), array([17.89941152])), mean=array([16.23987612]), variance=array([0.64526323]), skewness=array([0.42963228]), kurtosis=array([0.12518213]))\n",
      "For model shallow-20\n",
      "Computing for dataset 1\n",
      "100/100 [==============================] - 1s 5ms/step\n",
      "100/100 [==============================] - 1s 6ms/step\n",
      "100/100 [==============================] - 1s 7ms/step\n",
      "100/100 [==============================] - 0s 5ms/step\n",
      "100/100 [==============================] - 1s 5ms/step\n",
      "100/100 [==============================] - 1s 5ms/step\n",
      "100/100 [==============================] - 0s 5ms/step\n",
      "100/100 [==============================] - 1s 6ms/step\n",
      "100/100 [==============================] - 1s 7ms/step\n",
      "100/100 [==============================] - 1s 6ms/step\n",
      "Results for model shallow-20\n",
      "DescribeResult(nobs=10, minmax=(array([16.37345413]), array([17.4854225])), mean=array([16.92200736]), variance=array([0.14740785]), skewness=array([-0.05483688]), kurtosis=array([-1.33817871]))\n",
      "DescribeResult(nobs=10, minmax=(array([4.96626939]), array([7.61632306])), mean=array([6.24572366]), variance=array([0.68700952]), skewness=array([0.018405]), kurtosis=array([-0.92071021]))\n",
      "DescribeResult(nobs=10, minmax=(array([14.62713141]), array([15.77889136])), mean=array([15.44659792]), variance=array([0.11960883]), skewness=array([-1.37178977]), kurtosis=array([1.17152019]))\n",
      "For model shallow-10\n",
      "Computing for dataset 1\n",
      "100/100 [==============================] - 1s 6ms/step\n",
      "100/100 [==============================] - 1s 5ms/step\n",
      "100/100 [==============================] - 1s 6ms/step\n",
      "100/100 [==============================] - 1s 6ms/step\n",
      "100/100 [==============================] - 1s 7ms/step\n",
      "100/100 [==============================] - 1s 6ms/step\n",
      "100/100 [==============================] - 1s 7ms/step\n",
      "100/100 [==============================] - 1s 6ms/step\n",
      "100/100 [==============================] - 1s 7ms/step\n",
      "100/100 [==============================] - 1s 6ms/step\n",
      "Results for model shallow-10\n",
      "DescribeResult(nobs=10, minmax=(array([16.55234122]), array([17.50228557])), mean=array([16.84567378]), variance=array([0.09141648]), skewness=array([1.0352308]), kurtosis=array([0.12167024]))\n",
      "DescribeResult(nobs=10, minmax=(array([5.45183694]), array([7.38609295])), mean=array([6.17718043]), variance=array([0.45419427]), skewness=array([0.62506226]), kurtosis=array([-0.99951047]))\n",
      "DescribeResult(nobs=10, minmax=(array([15.8748855]), array([18.86018306])), mean=array([17.13236627]), variance=array([1.10272156]), skewness=array([0.66559618]), kurtosis=array([-0.82634363]))\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "tModel.epochs = 100\n",
    "lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "num_features = len(selected_features)\n",
    "\n",
    "windowSize = 30\n",
    "windowStride = 1\n",
    "constRul = 140\n",
    "\n",
    "file = open(\"results/MLP/ResultsDataset_1.csv\", \"w\")\n",
    "csvfile = csv.writer(file, lineterminator='\\n')\n",
    "\n",
    "for key, model_def in models.items():\n",
    "  \n",
    "    print(\"For model \"+str(key))\n",
    "    #file.write(\"For model \"+str(key)+'\\n\\n')\n",
    "  \n",
    "    for i in range(1,2):\n",
    "\n",
    "        dataset = i\n",
    "        print(\"Computing for dataset \"+str(i))\n",
    "        #file.write(\"Computing for dataset \"+str(i)+'\\n\\n')\n",
    "      \n",
    "        tempScoresRMSE = np.zeros((iterations,1))\n",
    "        tempScoresRHS = np.zeros((iterations,1))\n",
    "        tempTime = np.zeros((iterations,1))\n",
    "      \n",
    "        input_shape = windowSize*num_features #For simple ANN\n",
    "      \n",
    "        tModel.data_handler.change_dataset(i)\n",
    "        tModel.data_handler.sequence_length = windowSize\n",
    "        tModel.data_handler.sequence_stride = windowStride\n",
    "        tModel.data_handler.max_rul = constRul\n",
    "        tModel.load_data(unroll=True, verbose=0, cross_validation_ratio=0)\n",
    "        #tModel.print_data()\n",
    "\n",
    "        for j in range(iterations):\n",
    "\n",
    "            #Model needs to be recompiled everytime since they are different runs so weights should be reinit\n",
    "            model = get_compiled_model(model_def, input_shape, model_type='ann')\n",
    "\n",
    "            tModel.change_model(key, model, 'keras')\n",
    "            tModel.train_model(learningRate_scheduler=lrate, verbose=0)\n",
    "            tModel.evaluate_model(['rhs', 'rmse'], round=2)\n",
    "            #print(\"scores\")\n",
    "          \n",
    "            #print(j)\n",
    "\n",
    "            cScores = tModel.scores\n",
    "            rmse = math.sqrt(cScores['score_1'])\n",
    "            rmse2 = cScores['rmse']\n",
    "            rhs = cScores['rhs']\n",
    "            time = tModel.train_time\n",
    "          \n",
    "            tempScoresRMSE[j] = rmse2\n",
    "            tempScoresRHS[j] = rhs\n",
    "            tempTime[j] = time\n",
    "\n",
    "        print(\"Results for model \" + key)\n",
    "  \n",
    "        print(stats.describe(tempScoresRMSE))\n",
    "        print(stats.describe(tempScoresRHS))\n",
    "        print(stats.describe(tempTime))\n",
    "          \n",
    "        tempScoresRMSE = np.reshape(tempScoresRMSE, (iterations,))\n",
    "        tempScoresRHS = np.reshape(tempScoresRHS, (iterations,))\n",
    "        tempTime = np.reshape(tempTime, (iterations,))\n",
    "        csvfile.writerow(tempScoresRMSE)\n",
    "        csvfile.writerow(tempScoresRHS)\n",
    "        csvfile.writerow(tempTime)\n",
    "        \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on all Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating statistics for model shallow-20-20\n",
      "Working on dataset 1\n",
      "238\n",
      "100/100 [==============================] - 1s 9ms/step\n",
      "100/100 [==============================] - 1s 9ms/step\n",
      "100/100 [==============================] - 1s 10ms/step\n",
      "100/100 [==============================] - 1s 10ms/step\n",
      "100/100 [==============================] - 1s 10ms/step\n",
      "100/100 [==============================] - 1s 10ms/step\n",
      "100/100 [==============================] - 1s 10ms/step\n",
      "100/100 [==============================] - 1s 10ms/step\n",
      "100/100 [==============================] - 1s 10ms/step\n",
      "100/100 [==============================] - 1s 10ms/step\n",
      "Results for model shallow-20-20\n",
      "DescribeResult(nobs=10, minmax=(array([16.74604431]), array([17.23861943])), mean=array([17.06463444]), variance=array([0.0325017]), skewness=array([-0.88353254]), kurtosis=array([-0.61935145]))\n",
      "DescribeResult(nobs=10, minmax=(array([8.08271055]), array([9.26545247])), mean=array([8.64814575]), variance=array([0.20635946]), skewness=array([-0.04830206]), kurtosis=array([-1.50147762]))\n",
      "DescribeResult(nobs=10, minmax=(array([17.28190351]), array([20.75944268])), mean=array([18.59064881]), variance=array([1.26079365]), skewness=array([0.53965178]), kurtosis=array([-0.70071753]))\n",
      "Working on dataset 2\n",
      "238\n",
      "259/259 [==============================] - 1s 4ms/step\n",
      "259/259 [==============================] - 1s 4ms/step\n",
      "259/259 [==============================] - 1s 4ms/step\n",
      "259/259 [==============================] - 1s 4ms/step\n",
      "259/259 [==============================] - 1s 4ms/step\n",
      "259/259 [==============================] - 1s 4ms/step\n",
      "259/259 [==============================] - 1s 4ms/step\n",
      "259/259 [==============================] - 1s 4ms/step\n",
      "259/259 [==============================] - 1s 4ms/step\n",
      "259/259 [==============================] - 1s 4ms/step\n",
      "Results for model shallow-20-20\n",
      "DescribeResult(nobs=10, minmax=(array([29.77055112]), array([30.12278605])), mean=array([29.9410427]), variance=array([0.01371166]), skewness=array([0.00427771]), kurtosis=array([-1.15611101]))\n",
      "DescribeResult(nobs=10, minmax=(array([54.9013126]), array([63.53765616])), mean=array([58.82387766]), variance=array([5.75062991]), skewness=array([0.46125081]), kurtosis=array([-0.08556425]))\n",
      "DescribeResult(nobs=10, minmax=(array([39.96110995]), array([45.92934572])), mean=array([43.77577243]), variance=array([4.56499441]), skewness=array([-1.02919672]), kurtosis=array([-0.35078346]))\n",
      "Working on dataset 3\n",
      "238\n",
      "100/100 [==============================] - 1s 11ms/step\n",
      "100/100 [==============================] - 1s 12ms/step\n",
      "100/100 [==============================] - 1s 12ms/step\n",
      "100/100 [==============================] - 1s 12ms/step\n",
      "100/100 [==============================] - 1s 12ms/step\n",
      "100/100 [==============================] - 1s 12ms/step\n",
      "100/100 [==============================] - 1s 13ms/step\n",
      "100/100 [==============================] - 1s 13ms/step\n",
      "100/100 [==============================] - 1s 13ms/step\n",
      "100/100 [==============================] - 1s 13ms/step\n",
      "Results for model shallow-20-20\n",
      "DescribeResult(nobs=10, minmax=(array([16.9440255]), array([18.5291662])), mean=array([17.77146405]), variance=array([0.1556282]), skewness=array([-0.24678058]), kurtosis=array([1.09323979]))\n",
      "DescribeResult(nobs=10, minmax=(array([6.02927943]), array([10.18819117])), mean=array([7.64747814]), variance=array([1.88430213]), skewness=array([0.67730309]), kurtosis=array([-0.75931237]))\n",
      "DescribeResult(nobs=10, minmax=(array([25.60197198]), array([29.56520624])), mean=array([28.14127926]), variance=array([2.03920931]), skewness=array([-0.82161631]), kurtosis=array([-1.00131736]))\n",
      "Working on dataset 4\n",
      "238\n",
      "248/248 [==============================] - 1s 5ms/step\n",
      "248/248 [==============================] - 1s 5ms/step\n",
      "248/248 [==============================] - 1s 5ms/step\n",
      "248/248 [==============================] - 1s 5ms/step\n",
      "248/248 [==============================] - 1s 6ms/step\n",
      "248/248 [==============================] - 1s 6ms/step\n",
      "248/248 [==============================] - 1s 6ms/step\n",
      "248/248 [==============================] - 1s 6ms/step\n",
      "248/248 [==============================] - 1s 6ms/step\n",
      "248/248 [==============================] - 1s 6ms/step\n",
      "Results for model shallow-20-20\n",
      "DescribeResult(nobs=10, minmax=(array([33.95668493]), array([35.46329315])), mean=array([35.14841976]), variance=array([0.20013415]), skewness=array([-2.14765661]), kurtosis=array([3.28938939]))\n",
      "DescribeResult(nobs=10, minmax=(array([58.71171799]), array([67.91744227])), mean=array([65.78258587]), variance=array([6.98363345]), skewness=array([-2.12042295]), kurtosis=array([3.41637688]))\n",
      "DescribeResult(nobs=10, minmax=(array([58.69075155]), array([70.03360109])), mean=array([64.19236988]), variance=array([12.78385268]), skewness=array([0.16367492]), kurtosis=array([-1.08353196]))\n"
     ]
    }
   ],
   "source": [
    "datasets = [1,2,3,4]\n",
    "iterations = 10\n",
    "tModel.epochs = 150\n",
    "lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "scores ={1:[], 2:[], 3:[], 4:[]}\n",
    "window_sizes = {1:17,2:17,3:17,4:17}\n",
    "strides = {1:1,2:1,3:1,4:1}\n",
    "max_ruls = {1:129, 2:129, 3:129, 4:129}\n",
    "num_features = len(selected_features)\n",
    "\n",
    "input_shape = None\n",
    "models = {'shallow-20-20':RULmodel_SN_4}\n",
    "\n",
    "#For each model\n",
    "for key, model_def in models.items():\n",
    "    file = open(\"results/MLP/ResultsDatasets_singleSet\"+key+\".csv\", \"w\")\n",
    "    csvfile = csv.writer(file, lineterminator='\\n')\n",
    "    \n",
    "    print(\"Generating statistics for model \" + key)\n",
    "\n",
    "    #For each dataset\n",
    "    for i in range(1,5):\n",
    "        \n",
    "        print(\"Working on dataset \" + str(i))\n",
    "        \n",
    "        tempScoresRMSE = np.zeros((iterations,1))\n",
    "        tempScoresRHS = np.zeros((iterations,1))\n",
    "        tempTime = np.zeros((iterations,1))\n",
    "        \n",
    "        input_shape = window_sizes[i]*num_features #For simple ANN\n",
    "        #input_shape = (window_sizes[i],num_features) #For RNN\n",
    "        \n",
    "        print(input_shape)\n",
    "        \n",
    "        tModel.data_handler.change_dataset(i)\n",
    "        tModel.data_handler.sequence_length = window_sizes[i]\n",
    "        tModel.data_handler.sequence_stride = strides[i]\n",
    "        tModel.data_handler.max_rul = max_ruls[i]\n",
    "        tModel.load_data(unroll=True, verbose=0, cross_validation_ratio=0)\n",
    "        #tModel.print_data()\n",
    "        \n",
    "        #tModel.print_data()\n",
    "        \n",
    "        for j in range(iterations):\n",
    "\n",
    "            #Model needs to be recompiled everytime since they are different runs so weights should be reinit\n",
    "            model = get_compiled_model(model_def, input_shape, model_type='ann')\n",
    "\n",
    "            tModel.change_model(key, model, 'keras')\n",
    "            tModel.train_model(learningRate_scheduler=lrate, verbose=0)\n",
    "            tModel.evaluate_model(['rhs', 'rmse'], round=2)\n",
    "            #print(\"scores\")\n",
    "            \n",
    "            #print(j)\n",
    "\n",
    "            cScores = tModel.scores\n",
    "            rmse = math.sqrt(cScores['score_1'])\n",
    "            rmse2 = cScores['rmse']\n",
    "            rhs = cScores['rhs']\n",
    "            time = tModel.train_time\n",
    "            \n",
    "            tempScoresRMSE[j] = rmse2\n",
    "            tempScoresRHS[j] = rhs\n",
    "            tempTime[j] = time\n",
    "            \n",
    "        print(\"Results for model \" + key)\n",
    "    \n",
    "        print(stats.describe(tempScoresRMSE))\n",
    "        print(stats.describe(tempScoresRHS))\n",
    "        print(stats.describe(tempTime))\n",
    "            \n",
    "        tempScoresRMSE = np.reshape(tempScoresRMSE, (iterations,))\n",
    "        tempScoresRHS = np.reshape(tempScoresRHS, (iterations,))\n",
    "        tempTime = np.reshape(tempTime, (iterations,))\n",
    "        csvfile.writerow(tempScoresRMSE)\n",
    "        csvfile.writerow(tempScoresRHS)\n",
    "        csvfile.writerow(tempTime)\n",
    "    \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
