{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\controlslab\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import copy\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from keras.models import model_from_json, clone_model\n",
    "\n",
    "import custom_scores\n",
    "import CMAPSAuxFunctions\n",
    "from tunableModel import TunableModel\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "100/100 [==============================] - 0s 276us/step\n",
      "Iteration 2\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 3\n",
      "100/100 [==============================] - 0s 70us/step\n",
      "Iteration 4\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 5\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 6\n",
      "100/100 [==============================] - 0s 30us/step\n",
      "Iteration 7\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 8\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 9\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Iteration 10\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "[14.647866738880444, 13.220060514233662, 12.7534309109353, 13.467367968537877, 13.621306838919677, 12.859237924542807, 14.361058456812994, 13.521834195108296, 13.204166009256321, 13.465140177510222]\n",
      "Best Score\n",
      "12.7534309109353\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#Clear the previous tensorflow graph\n",
    "K.clear_session()\n",
    "\n",
    "def RULmodel_SN_1(input_shape):\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(30, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', name='fc1'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(10, activation='relu', kernel_initializer='glorot_normal', name='fc2'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "#Shared parameters for the models\n",
    "optimizer = Adam(lr=0, beta_1=0.5)\n",
    "lossFunction = \"mean_squared_error\"\n",
    "metrics = [\"mse\"]\n",
    "\n",
    "#Selected as per CNN paper\n",
    "selected_features = ['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'htBleed', 'W31', 'W32']\n",
    "\n",
    "dataFolder = '../CMAPSSData'\n",
    "\n",
    "datasets = [1]\n",
    "iterations = 10\n",
    "lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "scores ={1:[], 2:[], 3:[], 4:[]}\n",
    "#windowSizes = {1:25,2:15,3:25,4:15}\n",
    "windowSizes = 15\n",
    "stride = 2\n",
    "#constRUL = {1:93, 2:94, 3:92, 4:94}\n",
    "constRUL = 95\n",
    "#models = {1:RULmodel_SN_1,2:RULmodel_SN_2,3:RULmodel_SN_3,4:RULmodel_SN_4}\n",
    "models = {1:RULmodel_SN_1}\n",
    "\n",
    "#Create and compile the model\n",
    "windowSize = 15\n",
    "nFeatures = len(selected_features)\n",
    "shapeSN = nFeatures*windowSize\n",
    "modelRULSN = RULmodel_SN_1(shapeSN)\n",
    "modelRULSN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "tModel = TunableModel('ModelRUL_SN_1', modelRULSN, selected_features, dataFolder, window_size=windowSize,\n",
    "                      scaler = min_max_scaler, window_stride=stride, constRul = constRUL)\n",
    "tModel.loadData()\n",
    "tModel.epochs = 50\n",
    "\n",
    "#file = open(\"ResultsBestModelAllDatasetsSingleSet.csv\", \"w\")\n",
    "#csvfile = csv.writer(file, lineterminator='\\n')\n",
    "\n",
    "min_rmse = 1000\n",
    "bestModel = None\n",
    "bestIndex = 0\n",
    "\n",
    "tempScoresRMSE = []\n",
    "tempScoresRHS = []\n",
    "tempTime = []\n",
    "\n",
    "bestModel = clone_model(tModel.model)\n",
    "\n",
    "for i in range(iterations):\n",
    "\n",
    "    print(\"Iteration \"+str(i+1))\n",
    "    #file.write(\"Iteration \"+str(j+1)+'\\n\\n')\n",
    "    tModel.trainModel(learningRateScheduler=lrate, verbose=0)\n",
    "    tModel.evaluateModel([\"rhs\"], round=True)\n",
    "\n",
    "    cScores = tModel.scores\n",
    "    rmse = math.sqrt(cScores['score_1'])\n",
    "    rmse2 = cScores['rmse']\n",
    "    rhs = cScores['rhs']\n",
    "    time = tModel.trainTime\n",
    "\n",
    "    if rmse2 < min_rmse:\n",
    "        bestModel.set_weights(tModel.model.get_weights())\n",
    "        bestIndex = i\n",
    "        min_rmse = rmse2\n",
    "    \n",
    "    tempScoresRMSE.append(rmse2)\n",
    "    tempScoresRHS.append(rhs)\n",
    "    tempTime.append(time)\n",
    "\n",
    "print(tempScoresRMSE)\n",
    "print('Best Score')\n",
    "print(min_rmse)\n",
    "    \n",
    "#save best model to file\n",
    "# serialize model to JSON\n",
    "model_json = bestModel.to_json()\n",
    "with open(\"bestRULModel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "bestModel.save_weights(\"bestRULModel.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "        \n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Loading data for dataset 1 with window_size of 15, stride of 2 and constRUL of 95. Cros-Validation ratio 0\n",
      "Data loaded for dataset 1\n",
      "Description for model: Loaded_Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1 (Dense)                  (None, 30)                6330      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 6,651\n",
      "Trainable params: 6,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('bestRULModel.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"bestRULModel.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "#Shared parameters for the models\n",
    "optimizer = Adam(lr=0, beta_1=0.5)\n",
    "lossFunction = \"mean_squared_error\"\n",
    "metrics = [\"mse\"]\n",
    "\n",
    "#Selected as per CNN paper\n",
    "selected_features = ['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'htBleed', 'W31', 'W32']\n",
    "\n",
    "windowSize = 15\n",
    "stride = 2\n",
    "constRUL = 95\n",
    "\n",
    "\n",
    "dataFolder = '../CMAPSSData'\n",
    "\n",
    "#Create and compile the models\n",
    "#nFeatures = len(selected_features)\n",
    "#shapeSN = nFeatures*windowSize\n",
    "#modelRULSN = RULmodel_SN_1(shapeSN)\n",
    "loaded_model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "tModel = TunableModel('Loaded_Model', loaded_model, selected_features, dataFolder, window_size=windowSize,\n",
    "                      scaler = min_max_scaler, window_stride=stride, constRul = constRUL)\n",
    "tModel.loadData(verbose=1)\n",
    "tModel.getModelDescription()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 531us/step\n",
      "scores\n",
      "{'rmse': 12.7534309109353, 'rhs': 258.3132150863941, 'score_1': 163.44337829589844, 'loss': 163.44337829589844}\n",
      "RMSE: 12.784497576983558\n",
      "RMSE2: 12.7534309109353\n",
      "RHS: 258.3132150863941\n",
      "Time : None seconds\n"
     ]
    }
   ],
   "source": [
    "# evaluate loaded model on test data\n",
    "tModel.evaluateModel([\"rhs\"], round=True)\n",
    "print(\"scores\")\n",
    "\n",
    "#print(tModel.y_pred)\n",
    "\n",
    "cScores = tModel.scores\n",
    "rmse = math.sqrt(cScores['score_1'])\n",
    "rmse2 = cScores['rmse']\n",
    "rhs = cScores['rhs']\n",
    "time = tModel.trainTime\n",
    "\n",
    "print(cScores)\n",
    "print(\"RMSE: {}\".format(rmse))\n",
    "print(\"RMSE2: {}\".format(rmse2))\n",
    "print(\"RHS: {}\".format(rhs))\n",
    "print(\"Time : {} seconds\".format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
