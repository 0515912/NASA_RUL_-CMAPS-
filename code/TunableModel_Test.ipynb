{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Test notebook for the DataHandlers. Test the CMAPSS DataHandler\n",
    "\n",
    "First we import the necessary packages and create the global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlaredorazo/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_handler_CMAPS import CMAPSDataHandler\n",
    "from tunable_model import SequenceTunableModelRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D, LSTM\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "import CMAPSAuxFunctions\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define different types of Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2_lambda_regularization = 0\n",
    "#l1_lambda_regularization = 0.2\n",
    "\n",
    "def RULmodel_LSTM(input_shape):\n",
    "    \"\"\"Define the RNN model\"\"\"\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    #model.add(Masking(mask_value=0, imput))\n",
    "    #model.add(LSTM(input_shape=input_shape, units=100, return_sequences=True, name='lstm1')))\n",
    "    model.add(LSTM(input_shape=input_shape, units=20, return_sequences=False, name='lstm2'))\n",
    "    model.add(Dense(10, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), name='fc1'))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "def RULmodel_SN_5(input_shape):\n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), \n",
    "                    name='fc1'))\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), \n",
    "                    name='fc2'))\n",
    "    model.add(Dense(1, activation='linear', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def test_model(input_shape):\n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', \n",
    "                    kernel_initializer=keras.initializers.glorot_normal(seed=0), \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), name='fc1'))\n",
    "    model.add(Dense(1, activation='linear', \n",
    "                    kernel_initializer=keras.initializers.glorot_normal(seed=0), \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), name='out'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(input_shape, output_shape):\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=(None,input_shape), name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=None, name=\"y\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def tf_model(X):\n",
    "    \n",
    "    l2_lambda_regularization = 0.2\n",
    "    \n",
    "    A1 = tf.layers.dense(X, 20, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False), kernel_regularizer=regularizers.l2(l2_lambda_regularization), name=\"fc1\")\n",
    "    A2 = tf.layers.dense(A1, 20, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False), kernel_regularizer=regularizers.l2(l2_lambda_regularization), name=\"fc2\")\n",
    "    y = tf.layers.dense(A2, 1, activation=None, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False), kernel_regularizer=regularizers.l2(l2_lambda_regularization), name=\"out\")\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_model_weights(model):\n",
    "\n",
    "    for layer in model.layers:\n",
    "        weights = layer.get_weights() # list of numpy arrays\n",
    "        \n",
    "        for weight in weights:\n",
    "        \n",
    "            print(weight.shape)\n",
    "            print(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Data Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Selected as per CNN paper\n",
    "features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "selected_features = list(features[i] for i in selected_indices-1)\n",
    "data_folder = '../CMAPSSData'\n",
    "\n",
    "window_size = 30\n",
    "window_stride = 1\n",
    "max_rul = 125\n",
    "\n",
    "dHandler_cmaps = CMAPSDataHandler(data_folder, 1, selected_features, max_rul, window_size, window_stride)\n",
    "#dHandler_cmaps.load_data(verbose=1, cross_validation_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tunable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "#min_max_scaler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_compiled_model(shape, model_type='ann'):\n",
    "    \n",
    "    K.clear_session()  #Clear the previous tensorflow graph\n",
    "    \n",
    "    #To test the model without randomness\n",
    "    seed(0)\n",
    "    set_random_seed(0)\n",
    "    \n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0.001)\n",
    "    \n",
    "    #optimizer = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    \n",
    "    lossFunction = \"mean_squared_error\"\n",
    "    metrics = [\"mse\"]\n",
    "    model = None\n",
    "\n",
    "    #Create and compile the models\n",
    "\n",
    "    if model_type=='ann':\n",
    "        model = test_model(shape)\n",
    "        model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    elif model_type=='lstm':\n",
    "        model = RULmodel_LSTM(shape)\n",
    "        model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def tf_compiled_model(input_shape, output_shape):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    X, y = create_placeholders(input_shape, output_shape)\n",
    "    \n",
    "    y_pred = tf_model(X)\n",
    "    cost = tf.losses.mean_squared_error(y, y_pred)\n",
    "    reg_cost = tf.losses.get_regularization_loss()\n",
    "    total_cost = cost + reg_cost\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(total_cost)\n",
    "    \n",
    "    return {'X_placeholder':X, 'y_placeholder':y, 'y_pred':y_pred, 'cost':cost, 'total_cost':total_cost, 'optimizer':optimizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = len(selected_features)\n",
    "\n",
    "shape = len(selected_features)*window_size\n",
    "model = get_compiled_model(shape, model_type='ann')\n",
    "tModel = SequenceTunableModelRegression('ModelRUL_SN_1', model, lib_type='keras', data_handler=dHandler_cmaps)\n",
    "\n",
    "#shape = (window_size, num_features)\n",
    "#model = get_compiled_model(shape, model_type='lstm')\n",
    "#tModel = SequenceTunableModelRegression('ModelRUL_LSTM_1', model, lib_type='keras', data_handler=dHandler_cmaps)\n",
    "#tModel.data_handler.data_scaler = min_max_scaler\n",
    "#tModel.data_scaler = min_max_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tModel.data_handler.sequence_length = 24\n",
    "#tModel.data_handler.sequence_length = maxWindowSize[datasetNumber]\n",
    "tModel.data_handler.sequence_stride = 1\n",
    "tModel.data_handler.max_rul = 129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.59060403 -0.0455243  -0.27982732 ... -0.45454545  0.33333333\n",
      "   0.33501825]\n",
      " [-0.36912752  0.0629156  -0.18014129 ... -0.27272727  0.25581395\n",
      "   0.50126369]\n",
      " [-0.23489933 -0.13299233 -0.13854003 ... -0.09090909  0.11627907\n",
      "   0.46222971]\n",
      " [-0.23489933 -0.39897698 -0.2299843  ... -0.27272727  0.31782946\n",
      "   0.55293457]\n",
      " [-0.22147651 -0.39590793 -0.05926217 ... -0.81818182  0.34883721\n",
      "   0.09491716]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.10738255 -0.49616368 -0.26844584 ... -0.27272727  0.03875969\n",
      "   0.29458017]\n",
      " [-0.12751678 -0.18158568  0.02197802 ... -0.63636364  0.03875969\n",
      "   0.0322943 ]\n",
      " [ 0.06711409 -0.05473146  0.13814757 ...  0.09090909  0.2248062\n",
      "   0.06655434]\n",
      " [-0.1409396   0.15294118  0.00353218 ...  0.09090909 -0.31782946\n",
      "   0.02190396]\n",
      " [-0.01342282  0.03273657  0.2032967  ... -0.09090909 -0.05426357\n",
      "   0.45324347]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n"
     ]
    }
   ],
   "source": [
    "#Load Non sequenced data (unroll sequence into a single feature vector)\n",
    "\n",
    "tModel.data_handler.data_scaler = None\n",
    "tModel.data_scaler = min_max_scaler\n",
    "\n",
    "tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0)\n",
    "#tModel.data_handler.print_data()\n",
    "tModel.print_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load sequenced data (do not unroll sequence into a single feature vector)\n",
    "\n",
    "tModel.data_handler.data_scaler = min_max_scaler\n",
    "tModel.data_scaler = None\n",
    "\n",
    "tModel.load_data(unroll=False, verbose=1, cross_validation_ratio=0)\n",
    "#tModel.data_handler.print_data()\n",
    "tModel.print_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tModel.data_handler.data_scaler = min_max_scaler\n",
    "#tModel.data_scaler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model and test some Tunable Model functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n",
      "[[-0.59060403 -0.0455243  -0.27982732 ... -0.45454545  0.33333333\n",
      "   0.33501825]\n",
      " [-0.36912752  0.0629156  -0.18014129 ... -0.27272727  0.25581395\n",
      "   0.50126369]\n",
      " [-0.23489933 -0.13299233 -0.13854003 ... -0.09090909  0.11627907\n",
      "   0.46222971]\n",
      " ...\n",
      " [ 0.10067114  0.58516624  0.33398744 ...  0.63636364 -0.53488372\n",
      "  -0.89019938]\n",
      " [ 0.42281879  0.55498721  0.53649922 ...  0.09090909 -0.76744186\n",
      "  -0.52316765]\n",
      " [ 0.4295302   0.13452685  0.43877551 ...  0.27272727 -0.64341085\n",
      "  -0.55630441]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " ...\n",
      " [  2.]\n",
      " [  1.]\n",
      " [  0.]]\n",
      "Epoch: 0001 cost_reg= 8377.573011610 cost= 8365.186469184\n",
      "Epoch: 0002 cost_reg= 6529.002075195 cost= 6515.298814562\n",
      "Epoch: 0003 cost_reg= 3256.191728380 cost= 3237.800598145\n",
      "Epoch: 0004 cost_reg= 1183.044752333 cost= 1159.935431586\n",
      "Epoch: 0005 cost_reg= 736.296556261 cost= 712.926103380\n",
      "Epoch: 0006 cost_reg= 553.083836873 cost= 528.970405579\n",
      "Epoch: 0007 cost_reg= 463.801349216 cost= 437.980370416\n",
      "Epoch: 0008 cost_reg= 421.051527235 cost= 393.535922580\n",
      "Epoch: 0009 cost_reg= 393.442044576 cost= 364.359730191\n",
      "Epoch: 0010 cost_reg= 374.066841125 cost= 343.457927280\n",
      "Epoch: 0011 cost_reg= 362.400623745 cost= 330.739395142\n",
      "Epoch: 0012 cost_reg= 353.192303975 cost= 320.812146505\n",
      "Epoch: 0013 cost_reg= 342.510169983 cost= 309.563122220\n",
      "Epoch: 0014 cost_reg= 329.945806715 cost= 296.430122375\n",
      "Epoch: 0015 cost_reg= 319.080788506 cost= 284.947008769\n",
      "Epoch: 0016 cost_reg= 308.527673509 cost= 273.756154802\n",
      "Epoch: 0017 cost_reg= 300.739195930 cost= 265.280050066\n",
      "Epoch: 0018 cost_reg= 295.001255459 cost= 259.004959954\n",
      "Epoch: 0019 cost_reg= 290.570732117 cost= 254.216400570\n",
      "Epoch: 0020 cost_reg= 287.234354655 cost= 250.653081258\n",
      "Epoch: 0021 cost_reg= 283.567162408 cost= 246.800184038\n",
      "Epoch: 0022 cost_reg= 280.724309285 cost= 243.772215101\n",
      "Epoch: 0023 cost_reg= 278.094504462 cost= 241.081997342\n",
      "Epoch: 0024 cost_reg= 275.335282220 cost= 238.290083567\n",
      "Epoch: 0025 cost_reg= 274.078855726 cost= 237.062488132\n",
      "Epoch: 0026 cost_reg= 271.792023977 cost= 234.803397285\n",
      "Epoch: 0027 cost_reg= 270.252713097 cost= 233.379475911\n",
      "Epoch: 0028 cost_reg= 268.905289968 cost= 232.195987278\n",
      "Epoch: 0029 cost_reg= 267.876296997 cost= 231.307681190\n",
      "Epoch: 0030 cost_reg= 265.827895270 cost= 229.434582180\n",
      "Epoch: 0031 cost_reg= 265.230806139 cost= 229.084584978\n",
      "Epoch: 0032 cost_reg= 263.739429474 cost= 227.788032956\n",
      "Epoch: 0033 cost_reg= 262.220802307 cost= 226.483171251\n",
      "Epoch: 0034 cost_reg= 261.667727576 cost= 226.129803975\n",
      "Epoch: 0035 cost_reg= 260.367476993 cost= 225.091624366\n",
      "Epoch: 0036 cost_reg= 259.461862776 cost= 224.394156138\n",
      "Epoch: 0037 cost_reg= 258.864362081 cost= 224.014426337\n",
      "Epoch: 0038 cost_reg= 257.825808631 cost= 223.164604611\n",
      "Epoch: 0039 cost_reg= 256.800817702 cost= 222.361742655\n",
      "Epoch: 0040 cost_reg= 255.659387377 cost= 221.425395118\n",
      "Epoch: 0041 cost_reg= 255.562687768 cost= 221.534968906\n",
      "Epoch: 0042 cost_reg= 254.094170888 cost= 220.242473178\n",
      "Epoch: 0043 cost_reg= 253.455980937 cost= 219.783583323\n",
      "Epoch: 0044 cost_reg= 252.117109087 cost= 218.615332286\n",
      "Epoch: 0045 cost_reg= 251.768287659 cost= 218.404421912\n",
      "Epoch: 0046 cost_reg= 250.784279717 cost= 217.565651364\n",
      "Epoch: 0047 cost_reg= 250.802981483 cost= 217.705088298\n",
      "Epoch: 0048 cost_reg= 249.868117862 cost= 216.892707401\n",
      "Epoch: 0049 cost_reg= 248.630381690 cost= 215.780661265\n",
      "Epoch: 0050 cost_reg= 247.894743178 cost= 215.170684814\n",
      "Epoch: 0051 cost_reg= 247.740306430 cost= 215.102721320\n",
      "Epoch: 0052 cost_reg= 246.407145182 cost= 213.871362050\n",
      "Epoch: 0053 cost_reg= 246.496952905 cost= 214.015135447\n",
      "Epoch: 0054 cost_reg= 245.559230804 cost= 213.166959975\n",
      "Epoch: 0055 cost_reg= 244.980995178 cost= 212.689170837\n",
      "Epoch: 0056 cost_reg= 244.172843933 cost= 211.932674832\n",
      "Epoch: 0057 cost_reg= 243.430098640 cost= 211.281954871\n",
      "Epoch: 0058 cost_reg= 242.985543993 cost= 210.871253967\n",
      "Epoch: 0059 cost_reg= 242.405932532 cost= 210.384703318\n",
      "Epoch: 0060 cost_reg= 241.908659617 cost= 209.950377570\n",
      "Epoch: 0061 cost_reg= 241.019692739 cost= 209.134184519\n",
      "Epoch: 0062 cost_reg= 240.501507229 cost= 208.652269575\n",
      "Epoch: 0063 cost_reg= 240.067516751 cost= 208.306151920\n",
      "Epoch: 0064 cost_reg= 240.187781016 cost= 208.457400852\n",
      "Epoch: 0065 cost_reg= 239.382366604 cost= 207.732215881\n",
      "Epoch: 0066 cost_reg= 238.625429789 cost= 207.030264113\n",
      "Epoch: 0067 cost_reg= 238.108729892 cost= 206.544783698\n",
      "Epoch: 0068 cost_reg= 237.433018578 cost= 205.897981856\n",
      "Epoch: 0069 cost_reg= 237.115292443 cost= 205.611929152\n",
      "Epoch: 0070 cost_reg= 236.774364471 cost= 205.327938928\n",
      "Epoch: 0071 cost_reg= 237.399183485 cost= 205.951846229\n",
      "Epoch: 0072 cost_reg= 235.987174988 cost= 204.572145674\n",
      "Epoch: 0073 cost_reg= 236.217269474 cost= 204.838606940\n",
      "Epoch: 0074 cost_reg= 234.878697289 cost= 203.531478458\n",
      "Epoch: 0075 cost_reg= 234.884683397 cost= 203.555996789\n",
      "Epoch: 0076 cost_reg= 234.707254622 cost= 203.393465678\n",
      "Epoch: 0077 cost_reg= 234.001721700 cost= 202.720584869\n",
      "Epoch: 0078 cost_reg= 234.677232954 cost= 203.398730384\n",
      "Epoch: 0079 cost_reg= 233.291178809 cost= 202.036849128\n",
      "Epoch: 0080 cost_reg= 232.524208493 cost= 201.265585158\n",
      "Epoch: 0081 cost_reg= 232.254465739 cost= 201.009053972\n",
      "Epoch: 0082 cost_reg= 231.873957740 cost= 200.647337172\n",
      "Epoch: 0083 cost_reg= 231.879681481 cost= 200.677454207\n",
      "Epoch: 0084 cost_reg= 231.363855998 cost= 200.162867228\n",
      "Epoch: 0085 cost_reg= 231.041121589 cost= 199.845192379\n",
      "Epoch: 0086 cost_reg= 230.716927422 cost= 199.535189735\n",
      "Epoch: 0087 cost_reg= 230.140908983 cost= 198.971888224\n",
      "Epoch: 0088 cost_reg= 230.212677850 cost= 199.058937073\n",
      "Epoch: 0089 cost_reg= 229.549229940 cost= 198.415819380\n",
      "Epoch: 0090 cost_reg= 229.341008504 cost= 198.214472029\n",
      "Epoch: 0091 cost_reg= 228.901716020 cost= 197.759385427\n",
      "Epoch: 0092 cost_reg= 228.673863305 cost= 197.561781989\n",
      "Epoch: 0093 cost_reg= 228.274083455 cost= 197.150570763\n",
      "Epoch: 0094 cost_reg= 228.093608008 cost= 196.984828101\n",
      "Epoch: 0095 cost_reg= 228.195638021 cost= 197.069839478\n",
      "Epoch: 0096 cost_reg= 227.673752679 cost= 196.575068580\n",
      "Epoch: 0097 cost_reg= 227.857271406 cost= 196.745094723\n",
      "Epoch: 0098 cost_reg= 227.247853597 cost= 196.137282477\n",
      "Epoch: 0099 cost_reg= 227.338498010 cost= 196.231424967\n",
      "Epoch: 0100 cost_reg= 228.891397264 cost= 197.797379388\n",
      "Epoch: 0101 cost_reg= 226.063791063 cost= 194.980601417\n",
      "Epoch: 0102 cost_reg= 227.565141466 cost= 196.435745239\n",
      "Epoch: 0103 cost_reg= 226.769299825 cost= 195.632525126\n",
      "Epoch: 0104 cost_reg= 226.871946971 cost= 195.718775431\n",
      "Epoch: 0105 cost_reg= 225.266524421 cost= 194.113200294\n",
      "Epoch: 0106 cost_reg= 224.985472361 cost= 193.829986148\n",
      "Epoch: 0107 cost_reg= 225.149684906 cost= 193.954185486\n",
      "Epoch: 0108 cost_reg= 225.119198269 cost= 193.919695960\n",
      "Epoch: 0109 cost_reg= 224.805678474 cost= 193.598918915\n",
      "Epoch: 0110 cost_reg= 224.581522624 cost= 193.367631276\n",
      "Epoch: 0111 cost_reg= 224.560285780 cost= 193.322493659\n",
      "Epoch: 0112 cost_reg= 223.809999678 cost= 192.548620860\n",
      "Epoch: 0113 cost_reg= 224.637758043 cost= 193.374593099\n",
      "Epoch: 0114 cost_reg= 223.966788398 cost= 192.675075955\n",
      "Epoch: 0115 cost_reg= 223.385248820 cost= 192.064915127\n",
      "Epoch: 0116 cost_reg= 223.402783288 cost= 192.055046929\n",
      "Epoch: 0117 cost_reg= 223.236754523 cost= 191.866600037\n",
      "Epoch: 0118 cost_reg= 222.313126034 cost= 190.904925876\n",
      "Epoch: 0119 cost_reg= 222.787340800 cost= 191.347766876\n",
      "Epoch: 0120 cost_reg= 222.688691881 cost= 191.227865431\n",
      "Epoch: 0121 cost_reg= 222.463628981 cost= 190.989251455\n",
      "Epoch: 0122 cost_reg= 222.804308573 cost= 191.297573090\n",
      "Epoch: 0123 cost_reg= 221.572599199 cost= 190.019676208\n",
      "Epoch: 0124 cost_reg= 221.369219462 cost= 189.771879832\n",
      "Epoch: 0125 cost_reg= 221.195320129 cost= 189.567599403\n",
      "Epoch: 0126 cost_reg= 221.257609049 cost= 189.593397776\n",
      "Epoch: 0127 cost_reg= 220.596718682 cost= 188.904165904\n",
      "Epoch: 0128 cost_reg= 221.399532318 cost= 189.673883226\n",
      "Epoch: 0129 cost_reg= 220.801525116 cost= 189.033832974\n",
      "Epoch: 0130 cost_reg= 220.287768470 cost= 188.474467807\n",
      "Epoch: 0131 cost_reg= 220.185744815 cost= 188.357487996\n",
      "Epoch: 0132 cost_reg= 220.143913269 cost= 188.267759111\n",
      "Epoch: 0133 cost_reg= 219.863495721 cost= 187.950577630\n",
      "Epoch: 0134 cost_reg= 219.644615173 cost= 187.700176239\n",
      "Epoch: 0135 cost_reg= 219.974926419 cost= 187.970166524\n",
      "Epoch: 0136 cost_reg= 219.530892690 cost= 187.490068224\n",
      "Epoch: 0137 cost_reg= 219.233911726 cost= 187.191802979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0138 cost_reg= 220.457909054 cost= 188.370627085\n",
      "Epoch: 0139 cost_reg= 218.730031755 cost= 186.597028520\n",
      "Epoch: 0140 cost_reg= 219.286266327 cost= 187.118611230\n",
      "Epoch: 0141 cost_reg= 218.527625190 cost= 186.319642385\n",
      "Epoch: 0142 cost_reg= 218.491434733 cost= 186.232306586\n",
      "Epoch: 0143 cost_reg= 218.143500010 cost= 185.847084045\n",
      "Epoch: 0144 cost_reg= 218.611676110 cost= 186.236434937\n",
      "Epoch: 0145 cost_reg= 218.241404215 cost= 185.862783220\n",
      "Epoch: 0146 cost_reg= 218.372593774 cost= 185.938151889\n",
      "Epoch: 0147 cost_reg= 217.631909264 cost= 185.181059943\n",
      "Epoch: 0148 cost_reg= 217.472109901 cost= 184.992567274\n",
      "Epoch: 0149 cost_reg= 217.375561184 cost= 184.858635373\n",
      "Epoch: 0150 cost_reg= 217.363023122 cost= 184.786864811\n",
      "Epoch: 0151 cost_reg= 216.989672767 cost= 184.388654921\n",
      "Epoch: 0152 cost_reg= 216.783836365 cost= 184.133578406\n",
      "Epoch: 0153 cost_reg= 216.559694926 cost= 183.856592390\n",
      "Epoch: 0154 cost_reg= 217.021157159 cost= 184.292811500\n",
      "Epoch: 0155 cost_reg= 216.271771325 cost= 183.508759393\n",
      "Epoch: 0156 cost_reg= 216.676847246 cost= 183.879391988\n",
      "Epoch: 0157 cost_reg= 216.308551788 cost= 183.472879622\n",
      "Epoch: 0158 cost_reg= 215.782346937 cost= 182.881768121\n",
      "Epoch: 0159 cost_reg= 216.091787974 cost= 183.155342526\n",
      "Epoch: 0160 cost_reg= 215.818329705 cost= 182.866656409\n",
      "Epoch: 0161 cost_reg= 215.216953701 cost= 182.206789653\n",
      "Epoch: 0162 cost_reg= 215.450174967 cost= 182.414616055\n",
      "Epoch: 0163 cost_reg= 215.670505524 cost= 182.581509484\n",
      "Epoch: 0164 cost_reg= 216.122316572 cost= 183.002795325\n",
      "Epoch: 0165 cost_reg= 215.092974769 cost= 181.921308306\n",
      "Epoch: 0166 cost_reg= 215.377188789 cost= 182.173684014\n",
      "Epoch: 0167 cost_reg= 214.485738542 cost= 181.235283746\n",
      "Epoch: 0168 cost_reg= 214.299409654 cost= 181.009110345\n",
      "Epoch: 0169 cost_reg= 214.312828912 cost= 180.977510240\n",
      "Epoch: 0170 cost_reg= 214.009173923 cost= 180.639559004\n",
      "Epoch: 0171 cost_reg= 214.764897664 cost= 181.336169773\n",
      "Epoch: 0172 cost_reg= 213.921987745 cost= 180.481380463\n",
      "Epoch: 0173 cost_reg= 214.075182597 cost= 180.593644036\n",
      "Epoch: 0174 cost_reg= 214.195093367 cost= 180.665797340\n",
      "Epoch: 0175 cost_reg= 214.240643819 cost= 180.680489434\n",
      "Epoch: 0176 cost_reg= 213.790793525 cost= 180.205204010\n",
      "Epoch: 0177 cost_reg= 213.513626946 cost= 179.864926232\n",
      "Epoch: 0178 cost_reg= 213.586297353 cost= 179.928504520\n",
      "Epoch: 0179 cost_reg= 214.464629703 cost= 180.771197425\n",
      "Epoch: 0180 cost_reg= 214.454955207 cost= 180.718191359\n",
      "Epoch: 0181 cost_reg= 213.486907535 cost= 179.711927202\n",
      "Epoch: 0182 cost_reg= 212.812163459 cost= 178.974807315\n",
      "Epoch: 0183 cost_reg= 214.010544247 cost= 180.139467451\n",
      "Epoch: 0184 cost_reg= 213.248984443 cost= 179.366080390\n",
      "Epoch: 0185 cost_reg= 212.821762085 cost= 178.881605360\n",
      "Epoch: 0186 cost_reg= 211.856243557 cost= 177.869258033\n",
      "Epoch: 0187 cost_reg= 212.520173815 cost= 178.520446777\n",
      "Epoch: 0188 cost_reg= 212.042025672 cost= 177.973862542\n",
      "Epoch: 0189 cost_reg= 212.009360419 cost= 177.901067946\n",
      "Epoch: 0190 cost_reg= 211.813076443 cost= 177.680107541\n",
      "Epoch: 0191 cost_reg= 212.260725233 cost= 178.084490882\n",
      "Epoch: 0192 cost_reg= 212.789087084 cost= 178.591130151\n",
      "Epoch: 0193 cost_reg= 212.417675018 cost= 178.146563212\n",
      "Epoch: 0194 cost_reg= 211.706417931 cost= 177.424045987\n",
      "Epoch: 0195 cost_reg= 211.176409403 cost= 176.857572767\n",
      "Epoch: 0196 cost_reg= 211.062251197 cost= 176.694023980\n",
      "Epoch: 0197 cost_reg= 211.966755761 cost= 177.558316549\n",
      "Epoch: 0198 cost_reg= 211.401427375 cost= 176.947667864\n",
      "Epoch: 0199 cost_reg= 211.701908535 cost= 177.232532077\n",
      "Epoch: 0200 cost_reg= 211.110290527 cost= 176.614743551\n",
      "Epoch:Final cost_reg= 211.110290527 cost= 176.614743551\n"
     ]
    }
   ],
   "source": [
    "nFeatures = len(selected_features)\n",
    "\n",
    "#lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "\n",
    "shape = len(selected_features)*tModel.data_handler.sequence_length\n",
    "print(shape)\n",
    "\n",
    "#modelRULSN = RULmodel_SN_5(shape)\n",
    "#modelRULSN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "#model = get_compiled_model(shape, model_type='ann')\n",
    "#tModel.change_model('ModelRUL_SN_1', model, 'keras')\n",
    "\n",
    "model = tf_compiled_model(shape, 1)\n",
    "tModel.change_model('ModelRUL_SN_1', model, 'tensorflow')\n",
    "\n",
    "#tModel.print_data()\n",
    "\n",
    "#shape = (window_size, num_features)\n",
    "#model = get_compiled_model(shape, model_type='lstm')\n",
    "#tModel.change_model('ModelRUL_RNN_1', model, 'keras')\n",
    "\n",
    "#tModel.data_handler.data_scaler = min_max_scaler\n",
    "#tModel.data_scaler = min_max_scaler\n",
    "\n",
    "#print(\"Printing model weights\")\n",
    "#print_model_weights(tModel.model)\n",
    "\n",
    "tModel.epochs = 200\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "tModel.train_model(tf_session=sess, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow test\n",
      "scores\n",
      "Engine 1, Predicted RUL [[112.48052  ]\n",
      " [132.92393  ]\n",
      " [ 49.67283  ]\n",
      " [ 82.155266 ]\n",
      " [ 92.56063  ]\n",
      " [115.54735  ]\n",
      " [109.295944 ]\n",
      " [ 95.9404   ]\n",
      " [123.75031  ]\n",
      " [ 95.77486  ]\n",
      " [ 74.449356 ]\n",
      " [ 98.29668  ]\n",
      " [ 93.28192  ]\n",
      " [ 95.80575  ]\n",
      " [108.04846  ]\n",
      " [109.4397   ]\n",
      " [ 46.431183 ]\n",
      " [ 31.84631  ]\n",
      " [ 86.993    ]\n",
      " [ 15.904498 ]\n",
      " [ 78.170135 ]\n",
      " [125.11542  ]\n",
      " [124.1586   ]\n",
      " [ 22.168282 ]\n",
      " [111.29738  ]\n",
      " [115.5059   ]\n",
      " [107.76465  ]\n",
      " [114.15495  ]\n",
      " [ 97.67837  ]\n",
      " [107.93029  ]\n",
      " [ 13.163554 ]\n",
      " [ 47.43408  ]\n",
      " [108.43592  ]\n",
      " [  5.739829 ]\n",
      " [ 10.967816 ]\n",
      " [ 26.103645 ]\n",
      " [ 17.499498 ]\n",
      " [ 54.14962  ]\n",
      " [122.49233  ]\n",
      " [ 27.977829 ]\n",
      " [ 24.529604 ]\n",
      " [  7.853009 ]\n",
      " [ 62.833534 ]\n",
      " [118.56399  ]\n",
      " [ 83.86805  ]\n",
      " [ 49.874676 ]\n",
      " [114.51108  ]\n",
      " [103.391525 ]\n",
      " [ 16.187824 ]\n",
      " [ 74.874    ]\n",
      " [127.23999  ]\n",
      " [ 26.798056 ]\n",
      " [ 29.70998  ]\n",
      " [118.849976 ]\n",
      " [111.02827  ]\n",
      " [ 20.971508 ]\n",
      " [104.56493  ]\n",
      " [ 37.684307 ]\n",
      " [100.70172  ]\n",
      " [124.79871  ]\n",
      " [ 17.600594 ]\n",
      " [ 42.116985 ]\n",
      " [ 81.59564  ]\n",
      " [ 23.87476  ]\n",
      " [121.89214  ]\n",
      " [ 17.114765 ]\n",
      " [111.58425  ]\n",
      " [  8.410134 ]\n",
      " [108.35232  ]\n",
      " [103.8702   ]\n",
      " [107.5927   ]\n",
      " [ 54.931763 ]\n",
      " [112.47137  ]\n",
      " [108.6006   ]\n",
      " [107.34847  ]\n",
      " [  7.5651636]\n",
      " [ 30.722439 ]\n",
      " [128.9503   ]\n",
      " [ 94.10201  ]\n",
      " [ 98.40347  ]\n",
      " [  8.573304 ]\n",
      " [  9.152696 ]\n",
      " [123.46786  ]\n",
      " [ 72.57395  ]\n",
      " [127.96744  ]\n",
      " [100.809074 ]\n",
      " [110.3898   ]\n",
      " [114.026146 ]\n",
      " [117.958084 ]\n",
      " [ 31.695076 ]\n",
      " [ 28.182566 ]\n",
      " [ 26.845547 ]\n",
      " [ 51.434036 ]\n",
      " [ 61.617077 ]\n",
      " [106.966866 ]\n",
      " [112.3605   ]\n",
      " [ 91.30217  ]\n",
      " [ 87.07623  ]\n",
      " [118.68275  ]\n",
      " [ 23.860294 ]], Rounded RUL 112.0, Real RUL [112.]\n",
      "{'rhs': 3.636461880205316, 'rmse': 14.791889669680478}\n",
      "RMSE2: 14.791889669680478\n",
      "RHS: 3.636461880205316\n",
      "Time : 33.022057999999994 seconds\n"
     ]
    }
   ],
   "source": [
    "tModel.evaluate_model(['rhs', 'rmse'], round=2, tf_session=sess)\n",
    "print(\"scores\")\n",
    "\n",
    "cScores = tModel.scores\n",
    "#rmse = math.sqrt(cScores['score_1'])\n",
    "rmse2 = cScores['rmse']\n",
    "rhs = cScores['rhs']\n",
    "time = tModel.train_time\n",
    "\n",
    "i = range(1,len(tModel.y_test)+1)\n",
    "\n",
    "\n",
    "for i, rul_prediction, rul_prediction_rounded, true_rul in zip(i, tModel.y_predicted, tModel.y_predicted_rounded, tModel.y_test):\n",
    "    print('Engine {}, Predicted RUL {}, Rounded RUL {}, Real RUL {}'.format(i, rul_prediction, \n",
    "                                                                    rul_prediction_rounded, \n",
    "                                                                    true_rul))\n",
    "\n",
    "print(cScores)\n",
    "#print(\"RMSE: {}\".format(rmse))\n",
    "print(\"RMSE2: {}\".format(rmse2))\n",
    "print(\"RHS: {}\".format(rhs))\n",
    "print(\"Time : {} seconds\".format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
