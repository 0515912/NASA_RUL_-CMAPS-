{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Test notebook for the DataHandlers. Test the CMAPSS DataHandler\n",
    "\n",
    "First we import the necessary packages and create the global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlaredorazo/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_handler_CMAPS import CMAPSDataHandler\n",
    "from tunable_model import SequenceTunableModelRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D, LSTM\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "import CMAPSAuxFunctions\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define different types of Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2_lambda_regularization = 0\n",
    "#l1_lambda_regularization = 0.2\n",
    "\n",
    "def RULmodel_LSTM(input_shape):\n",
    "    \"\"\"Define the RNN model\"\"\"\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    #model.add(Masking(mask_value=0, imput))\n",
    "    #model.add(LSTM(input_shape=input_shape, units=100, return_sequences=True, name='lstm1')))\n",
    "    model.add(LSTM(input_shape=input_shape, units=20, return_sequences=False, name='lstm2'))\n",
    "    model.add(Dense(10, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), name='fc1'))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "def RULmodel_SN_5(input_shape):\n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), \n",
    "                    name='fc1'))\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), \n",
    "                    name='fc2'))\n",
    "    model.add(Dense(1, activation='linear', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def test_model(input_shape):\n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', \n",
    "                    kernel_initializer=keras.initializers.glorot_normal(seed=0), \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), name='fc1'))\n",
    "    model.add(Dense(1, activation='linear', \n",
    "                    kernel_initializer=keras.initializers.glorot_normal(seed=0), \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), name='out'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(input_shape, output_shape):\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=(None,input_shape), name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=None, name=\"y\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "#regularizers.l2(l2_lambda_regularization)\n",
    "def tf_model(X):\n",
    "    \n",
    "    l2_lambda_regularization = 0.20\n",
    "    l1_lambda_regularization = 0.10\n",
    "    \n",
    "    A1 = tf.layers.dense(X, 20, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False), \n",
    "                         kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(l1_lambda_regularization,l2_lambda_regularization), name=\"fc1\")\n",
    "    A2 = tf.layers.dense(A1, 20, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False),\n",
    "                         kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(l1_lambda_regularization,l2_lambda_regularization), name=\"fc2\")\n",
    "    y = tf.layers.dense(A2, 1, activation=None, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False),\n",
    "                        kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(l1_lambda_regularization,l2_lambda_regularization), name=\"out\")\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_model_weights(model):\n",
    "\n",
    "    for layer in model.layers:\n",
    "        weights = layer.get_weights() # list of numpy arrays\n",
    "        \n",
    "        for weight in weights:\n",
    "        \n",
    "            print(weight.shape)\n",
    "            print(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Data Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Selected as per CNN paper\n",
    "features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "selected_features = list(features[i] for i in selected_indices-1)\n",
    "data_folder = '../CMAPSSData'\n",
    "\n",
    "window_size = 30\n",
    "window_stride = 1\n",
    "max_rul = 125\n",
    "\n",
    "dHandler_cmaps = CMAPSDataHandler(data_folder, 1, selected_features, max_rul, window_size, window_stride)\n",
    "#dHandler_cmaps.load_data(verbose=1, cross_validation_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tunable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "#min_max_scaler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_compiled_model(shape, model_type='ann'):\n",
    "    \n",
    "    K.clear_session()  #Clear the previous tensorflow graph\n",
    "    \n",
    "    #To test the model without randomness\n",
    "\n",
    "    \n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0.001,beta_1=0.5)\n",
    "    \n",
    "    #optimizer = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    \n",
    "    lossFunction = \"mean_squared_error\"\n",
    "    metrics = [\"mse\"]\n",
    "    model = None\n",
    "\n",
    "    #Create and compile the models\n",
    "\n",
    "    if model_type=='ann':\n",
    "        model = test_model(shape)\n",
    "        model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    elif model_type=='lstm':\n",
    "        model = RULmodel_LSTM(shape)\n",
    "        model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def tf_compiled_model(input_shape, output_shape):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    X, y = create_placeholders(input_shape, output_shape)\n",
    "    \n",
    "    y_pred = tf_model(X)\n",
    "    cost = tf.losses.mean_squared_error(y, y_pred)\n",
    "    reg_cost = tf.losses.get_regularization_loss()\n",
    "    total_cost = cost + reg_cost\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001,beta1=0.5).minimize(total_cost)\n",
    "    \n",
    "    return {'X_placeholder':X, 'y_placeholder':y, 'y_pred':y_pred, 'cost':cost, 'total_cost':total_cost, 'optimizer':optimizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = len(selected_features)\n",
    "\n",
    "shape = len(selected_features)*window_size\n",
    "model = get_compiled_model(shape, model_type='ann')\n",
    "tModel = SequenceTunableModelRegression('ModelRUL_SN_1', model, lib_type='keras', data_handler=dHandler_cmaps)\n",
    "\n",
    "#shape = (window_size, num_features)\n",
    "#model = get_compiled_model(shape, model_type='lstm')\n",
    "#tModel = SequenceTunableModelRegression('ModelRUL_LSTM_1', model, lib_type='keras', data_handler=dHandler_cmaps)\n",
    "#tModel.data_handler.data_scaler = min_max_scaler\n",
    "#tModel.data_scaler = min_max_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tModel.data_handler.sequence_length = 24\n",
    "#tModel.data_handler.sequence_length = maxWindowSize[datasetNumber]\n",
    "tModel.data_handler.sequence_stride = 1\n",
    "tModel.data_handler.max_rul = 129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for dataset 1 with window_size of 24, stride of 1 and maxRUL of 129. Cros-Validation ratio 0\n",
      "Loading data from file and computing dataframes\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(18331, 336)\n",
      "(18331, 1)\n",
      "Testing data (X, y)\n",
      "(100, 336)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.59060403 -0.0455243  -0.27982732 ... -0.45454545  0.33333333\n",
      "   0.33501825]\n",
      " [-0.36912752  0.0629156  -0.18014129 ... -0.27272727  0.25581395\n",
      "   0.50126369]\n",
      " [-0.23489933 -0.13299233 -0.13854003 ... -0.09090909  0.11627907\n",
      "   0.46222971]\n",
      " [-0.23489933 -0.39897698 -0.2299843  ... -0.27272727  0.31782946\n",
      "   0.55293457]\n",
      " [-0.22147651 -0.39590793 -0.05926217 ... -0.81818182  0.34883721\n",
      "   0.09491716]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]\n",
      " [129.]]\n",
      "Testing data (X, y)\n",
      "[[-0.10738255 -0.49616368 -0.26844584 ... -0.27272727  0.03875969\n",
      "   0.29458017]\n",
      " [-0.12751678 -0.18158568  0.02197802 ... -0.63636364  0.03875969\n",
      "   0.0322943 ]\n",
      " [ 0.06711409 -0.05473146  0.13814757 ...  0.09090909  0.2248062\n",
      "   0.06655434]\n",
      " [-0.1409396   0.15294118  0.00353218 ...  0.09090909 -0.31782946\n",
      "   0.02190396]\n",
      " [-0.01342282  0.03273657  0.2032967  ... -0.09090909 -0.05426357\n",
      "   0.45324347]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n"
     ]
    }
   ],
   "source": [
    "#Load Non sequenced data (unroll sequence into a single feature vector)\n",
    "\n",
    "tModel.data_handler.data_scaler = None\n",
    "tModel.data_scaler = min_max_scaler\n",
    "\n",
    "tModel.load_data(unroll=True, verbose=1, cross_validation_ratio=0)\n",
    "#tModel.data_handler.print_data()\n",
    "tModel.print_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Load sequenced data (do not unroll sequence into a single feature vector)\n",
    "\n",
    "# tModel.data_handler.data_scaler = min_max_scaler\n",
    "# tModel.data_scaler = None\n",
    "\n",
    "# tModel.load_data(unroll=False, verbose=1, cross_validation_ratio=0)\n",
    "# #tModel.data_handler.print_data()\n",
    "# tModel.print_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tModel.data_handler.data_scaler = min_max_scaler\n",
    "#tModel.data_scaler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model and test some Tunable Model functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n",
      "[[-0.59060403 -0.0455243  -0.27982732 ... -0.45454545  0.33333333\n",
      "   0.33501825]\n",
      " [-0.36912752  0.0629156  -0.18014129 ... -0.27272727  0.25581395\n",
      "   0.50126369]\n",
      " [-0.23489933 -0.13299233 -0.13854003 ... -0.09090909  0.11627907\n",
      "   0.46222971]\n",
      " ...\n",
      " [ 0.10067114  0.58516624  0.33398744 ...  0.63636364 -0.53488372\n",
      "  -0.89019938]\n",
      " [ 0.42281879  0.55498721  0.53649922 ...  0.09090909 -0.76744186\n",
      "  -0.52316765]\n",
      " [ 0.4295302   0.13452685  0.43877551 ...  0.27272727 -0.64341085\n",
      "  -0.55630441]]\n",
      "[[129.]\n",
      " [129.]\n",
      " [129.]\n",
      " ...\n",
      " [  2.]\n",
      " [  1.]\n",
      " [  0.]]\n",
      "Epoch: 0001 cost_reg= 8173.348280165 cost= 8118.137274848\n",
      "Epoch: 0002 cost_reg= 5025.889743381 cost= 4963.187947591\n",
      "Epoch: 0003 cost_reg= 1612.153347439 cost= 1536.116780599\n",
      "Epoch: 0004 cost_reg= 884.120159573 cost= 804.171902127\n",
      "Epoch: 0005 cost_reg= 637.512629191 cost= 555.148045010\n",
      "Epoch: 0006 cost_reg= 551.522994995 cost= 467.033223470\n",
      "Epoch: 0007 cost_reg= 510.708658854 cost= 424.287512037\n",
      "Epoch: 0008 cost_reg= 486.963276333 cost= 399.303111606\n",
      "Epoch: 0009 cost_reg= 468.162301805 cost= 379.508725484\n",
      "Epoch: 0010 cost_reg= 451.899219089 cost= 362.108894348\n",
      "Epoch: 0011 cost_reg= 436.674560547 cost= 345.724819607\n",
      "Epoch: 0012 cost_reg= 422.286310832 cost= 330.172032674\n",
      "Epoch: 0013 cost_reg= 407.164164225 cost= 313.836571587\n",
      "Epoch: 0014 cost_reg= 393.335911221 cost= 298.946088155\n",
      "Epoch: 0015 cost_reg= 381.958029853 cost= 287.120683034\n",
      "Epoch: 0016 cost_reg= 374.974610223 cost= 280.279094696\n",
      "Epoch: 0017 cost_reg= 370.741594950 cost= 276.589187198\n",
      "Epoch: 0018 cost_reg= 367.119717068 cost= 273.694486830\n",
      "Epoch: 0019 cost_reg= 363.807903714 cost= 271.353056166\n",
      "Epoch: 0020 cost_reg= 361.426433139 cost= 269.965218438\n",
      "Epoch: 0021 cost_reg= 358.683058845 cost= 268.294098324\n",
      "Epoch: 0022 cost_reg= 356.462920295 cost= 267.116003672\n",
      "Epoch: 0023 cost_reg= 354.145720588 cost= 265.885721419\n",
      "Epoch: 0024 cost_reg= 352.336960687 cost= 265.101733738\n",
      "Epoch: 0025 cost_reg= 349.957656013 cost= 263.776805030\n",
      "Epoch: 0026 cost_reg= 347.936514960 cost= 262.833840264\n",
      "Epoch: 0027 cost_reg= 346.049447801 cost= 261.962851630\n",
      "Epoch: 0028 cost_reg= 344.732604133 cost= 261.700015598\n",
      "Epoch: 0029 cost_reg= 342.490869310 cost= 260.406055874\n",
      "Epoch: 0030 cost_reg= 340.554335700 cost= 259.458134121\n",
      "Epoch: 0031 cost_reg= 338.628308614 cost= 258.412319183\n",
      "Epoch: 0032 cost_reg= 337.082422892 cost= 257.777727339\n",
      "Epoch: 0033 cost_reg= 335.277197944 cost= 256.794860840\n",
      "Epoch: 0034 cost_reg= 333.491631402 cost= 255.856697506\n",
      "Epoch: 0035 cost_reg= 331.662964715 cost= 254.828078376\n",
      "Epoch: 0036 cost_reg= 330.175131056 cost= 254.162520515\n",
      "Epoch: 0037 cost_reg= 328.716514587 cost= 253.407303280\n",
      "Epoch: 0038 cost_reg= 327.362345378 cost= 252.863894992\n",
      "Epoch: 0039 cost_reg= 325.683354696 cost= 251.878858778\n",
      "Epoch: 0040 cost_reg= 324.397262573 cost= 251.262786865\n",
      "Epoch: 0041 cost_reg= 322.757116530 cost= 250.349788242\n",
      "Epoch: 0042 cost_reg= 321.241762797 cost= 249.485012478\n",
      "Epoch: 0043 cost_reg= 320.409205967 cost= 249.281037649\n",
      "Epoch: 0044 cost_reg= 318.614315457 cost= 248.069686466\n",
      "Epoch: 0045 cost_reg= 317.538585239 cost= 247.639001634\n",
      "Epoch: 0046 cost_reg= 315.809638977 cost= 246.537034776\n",
      "Epoch: 0047 cost_reg= 314.417617798 cost= 245.765689426\n",
      "Epoch: 0048 cost_reg= 313.124738057 cost= 245.014678107\n",
      "Epoch: 0049 cost_reg= 311.899754842 cost= 244.445741442\n",
      "Epoch: 0050 cost_reg= 311.042978075 cost= 244.049268511\n",
      "Epoch: 0051 cost_reg= 309.583558824 cost= 243.229654524\n",
      "Epoch: 0052 cost_reg= 308.730583191 cost= 242.812025706\n",
      "Epoch: 0053 cost_reg= 307.512664795 cost= 242.209214105\n",
      "Epoch: 0054 cost_reg= 306.607599046 cost= 241.731556363\n",
      "Epoch: 0055 cost_reg= 305.404188368 cost= 241.010867649\n",
      "Epoch: 0056 cost_reg= 304.234270732 cost= 240.385716332\n",
      "Epoch: 0057 cost_reg= 303.098849826 cost= 239.676418304\n",
      "Epoch: 0058 cost_reg= 302.872975667 cost= 239.930903541\n",
      "Epoch: 0059 cost_reg= 302.109301249 cost= 239.644657135\n",
      "Epoch: 0060 cost_reg= 300.598691305 cost= 238.529046800\n",
      "Epoch: 0061 cost_reg= 299.531278822 cost= 237.925416734\n",
      "Epoch: 0062 cost_reg= 298.439699809 cost= 237.253052606\n",
      "Epoch: 0063 cost_reg= 297.959747314 cost= 237.179172516\n",
      "Epoch: 0064 cost_reg= 296.859405518 cost= 236.469979604\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f8f2f9845f09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/University of California/Research/Projects/NASA_RUL_(CMAPS)/code/tunable_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, verbose, learningRate_scheduler, tf_session)\u001b[0m\n\u001b[1;32m     80\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A valid tensorflow session is needed to perform the training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_tf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University of California/Research/Projects/NASA_RUL_(CMAPS)/code/tunable_model.py\u001b[0m in \u001b[0;36mtrain_tf\u001b[0;34m(self, tf_session, verbose)\u001b[0m\n\u001b[1;32m    150\u001b[0m                         \u001b[0mcost_reg_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                         \u001b[0mX_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCMAPSAuxFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                         \u001b[0;31m#Train with the minibatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University of California/Research/Projects/NASA_RUL_(CMAPS)/code/CMAPSAuxFunctions.py\u001b[0m in \u001b[0;36mget_minibatches\u001b[0;34m(X_full, y_full, batch_size)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mremainder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtotal_batches\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mX_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mX_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \"\"\"\n\u001b[1;32m    342\u001b[0m     \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;31m# convert sparse matrices to CSR for row-based indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0mresampled_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msafe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresampled_arrays\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;31m# syntactic sugar for the unit argument case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;31m# convert sparse matrices to CSR for row-based indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0mresampled_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msafe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresampled_arrays\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;31m# syntactic sugar for the unit argument case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36msafe_indexing\u001b[0;34m(X, indices)\u001b[0m\n\u001b[1;32m    158\u001b[0m                                    indices.dtype.kind == 'i'):\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# This is often substantially faster than X[indices]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nFeatures = len(selected_features)\n",
    "\n",
    "#lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "\n",
    "shape = len(selected_features)*tModel.data_handler.sequence_length\n",
    "print(shape)\n",
    "\n",
    "#modelRULSN = RULmodel_SN_5(shape)\n",
    "#modelRULSN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "#model = get_compiled_model(shape, model_type='ann')\n",
    "#tModel.change_model('ModelRUL_SN_1', model, 'keras')\n",
    "\n",
    "model = tf_compiled_model(shape, 1)\n",
    "tModel.change_model('ModelRUL_SN_1', model, 'tensorflow')\n",
    "\n",
    "#tModel.print_data()\n",
    "\n",
    "#shape = (window_size, num_features)\n",
    "#model = get_compiled_model(shape, model_type='lstm')\n",
    "#tModel.change_model('ModelRUL_RNN_1', model, 'keras')\n",
    "\n",
    "#tModel.data_handler.data_scaler = min_max_scaler\n",
    "#tModel.data_scaler = min_max_scaler\n",
    "\n",
    "#print(\"Printing model weights\")\n",
    "#print_model_weights(tModel.model)\n",
    "\n",
    "tModel.epochs = 200\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "tModel.train_model(tf_session=sess, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow test\n",
      "scores\n",
      "Engine 1, Predicted RUL 106.85459899902344, Rounded RUL 106.0, Real RUL 112.0\n",
      "Engine 2, Predicted RUL 131.2633819580078, Rounded RUL 131.0, Real RUL 98.0\n",
      "Engine 3, Predicted RUL 46.94147491455078, Rounded RUL 46.0, Real RUL 69.0\n",
      "Engine 4, Predicted RUL 79.00276184082031, Rounded RUL 79.0, Real RUL 82.0\n",
      "Engine 5, Predicted RUL 87.82756805419922, Rounded RUL 87.0, Real RUL 91.0\n",
      "Engine 6, Predicted RUL 112.91165161132812, Rounded RUL 112.0, Real RUL 93.0\n",
      "Engine 7, Predicted RUL 107.88333129882812, Rounded RUL 107.0, Real RUL 91.0\n",
      "Engine 8, Predicted RUL 93.47246551513672, Rounded RUL 93.0, Real RUL 95.0\n",
      "Engine 9, Predicted RUL 121.0886459350586, Rounded RUL 121.0, Real RUL 111.0\n",
      "Engine 10, Predicted RUL 93.68683624267578, Rounded RUL 93.0, Real RUL 96.0\n",
      "Engine 11, Predicted RUL 79.62642669677734, Rounded RUL 79.0, Real RUL 97.0\n",
      "Engine 12, Predicted RUL 95.20885467529297, Rounded RUL 95.0, Real RUL 124.0\n",
      "Engine 13, Predicted RUL 90.19422149658203, Rounded RUL 90.0, Real RUL 95.0\n",
      "Engine 14, Predicted RUL 95.69951629638672, Rounded RUL 95.0, Real RUL 107.0\n",
      "Engine 15, Predicted RUL 104.85379028320312, Rounded RUL 104.0, Real RUL 83.0\n",
      "Engine 16, Predicted RUL 109.35690307617188, Rounded RUL 109.0, Real RUL 84.0\n",
      "Engine 17, Predicted RUL 43.012855529785156, Rounded RUL 43.0, Real RUL 50.0\n",
      "Engine 18, Predicted RUL 29.43654441833496, Rounded RUL 29.0, Real RUL 28.0\n",
      "Engine 19, Predicted RUL 88.36365509033203, Rounded RUL 88.0, Real RUL 87.0\n",
      "Engine 20, Predicted RUL 15.153580665588379, Rounded RUL 15.0, Real RUL 16.0\n",
      "Engine 21, Predicted RUL 82.76395416259766, Rounded RUL 82.0, Real RUL 57.0\n",
      "Engine 22, Predicted RUL 123.6407241821289, Rounded RUL 123.0, Real RUL 111.0\n",
      "Engine 23, Predicted RUL 122.55130004882812, Rounded RUL 122.0, Real RUL 113.0\n",
      "Engine 24, Predicted RUL 14.187458992004395, Rounded RUL 14.0, Real RUL 20.0\n",
      "Engine 25, Predicted RUL 108.14207458496094, Rounded RUL 108.0, Real RUL 145.0\n",
      "Engine 26, Predicted RUL 114.88095092773438, Rounded RUL 114.0, Real RUL 119.0\n",
      "Engine 27, Predicted RUL 106.47738647460938, Rounded RUL 106.0, Real RUL 66.0\n",
      "Engine 28, Predicted RUL 113.09087371826172, Rounded RUL 113.0, Real RUL 97.0\n",
      "Engine 29, Predicted RUL 100.47163391113281, Rounded RUL 100.0, Real RUL 90.0\n",
      "Engine 30, Predicted RUL 101.8004379272461, Rounded RUL 101.0, Real RUL 115.0\n",
      "Engine 31, Predicted RUL 13.326611518859863, Rounded RUL 13.0, Real RUL 8.0\n",
      "Engine 32, Predicted RUL 43.51869201660156, Rounded RUL 43.0, Real RUL 48.0\n",
      "Engine 33, Predicted RUL 105.81517028808594, Rounded RUL 105.0, Real RUL 106.0\n",
      "Engine 34, Predicted RUL 5.181253910064697, Rounded RUL 5.0, Real RUL 7.0\n",
      "Engine 35, Predicted RUL 13.664227485656738, Rounded RUL 13.0, Real RUL 11.0\n",
      "Engine 36, Predicted RUL 29.614133834838867, Rounded RUL 29.0, Real RUL 19.0\n",
      "Engine 37, Predicted RUL 24.129627227783203, Rounded RUL 24.0, Real RUL 21.0\n",
      "Engine 38, Predicted RUL 53.338340759277344, Rounded RUL 53.0, Real RUL 50.0\n",
      "Engine 39, Predicted RUL 121.13459014892578, Rounded RUL 121.0, Real RUL 142.0\n",
      "Engine 40, Predicted RUL 28.10570526123047, Rounded RUL 28.0, Real RUL 28.0\n",
      "Engine 41, Predicted RUL 23.60094451904297, Rounded RUL 23.0, Real RUL 18.0\n",
      "Engine 42, Predicted RUL 5.542255878448486, Rounded RUL 5.0, Real RUL 10.0\n",
      "Engine 43, Predicted RUL 60.7703742980957, Rounded RUL 60.0, Real RUL 59.0\n",
      "Engine 44, Predicted RUL 114.83051300048828, Rounded RUL 114.0, Real RUL 109.0\n",
      "Engine 45, Predicted RUL 87.20222473144531, Rounded RUL 87.0, Real RUL 114.0\n",
      "Engine 46, Predicted RUL 49.54157257080078, Rounded RUL 49.0, Real RUL 47.0\n",
      "Engine 47, Predicted RUL 118.14871215820312, Rounded RUL 118.0, Real RUL 135.0\n",
      "Engine 48, Predicted RUL 97.45267486572266, Rounded RUL 97.0, Real RUL 92.0\n",
      "Engine 49, Predicted RUL 14.39700698852539, Rounded RUL 14.0, Real RUL 21.0\n",
      "Engine 50, Predicted RUL 69.1630859375, Rounded RUL 69.0, Real RUL 79.0\n",
      "Engine 51, Predicted RUL 125.30191040039062, Rounded RUL 125.0, Real RUL 114.0\n",
      "Engine 52, Predicted RUL 23.847000122070312, Rounded RUL 23.0, Real RUL 29.0\n",
      "Engine 53, Predicted RUL 30.468677520751953, Rounded RUL 30.0, Real RUL 26.0\n",
      "Engine 54, Predicted RUL 117.219482421875, Rounded RUL 117.0, Real RUL 97.0\n",
      "Engine 55, Predicted RUL 109.19404602050781, Rounded RUL 109.0, Real RUL 137.0\n",
      "Engine 56, Predicted RUL 18.177692413330078, Rounded RUL 18.0, Real RUL 15.0\n",
      "Engine 57, Predicted RUL 99.87581634521484, Rounded RUL 99.0, Real RUL 103.0\n",
      "Engine 58, Predicted RUL 37.87717819213867, Rounded RUL 37.0, Real RUL 37.0\n",
      "Engine 59, Predicted RUL 100.38878631591797, Rounded RUL 100.0, Real RUL 114.0\n",
      "Engine 60, Predicted RUL 122.06981658935547, Rounded RUL 122.0, Real RUL 100.0\n",
      "Engine 61, Predicted RUL 19.715042114257812, Rounded RUL 19.0, Real RUL 21.0\n",
      "Engine 62, Predicted RUL 40.56403732299805, Rounded RUL 40.0, Real RUL 54.0\n",
      "Engine 63, Predicted RUL 79.84778594970703, Rounded RUL 79.0, Real RUL 72.0\n",
      "Engine 64, Predicted RUL 23.417118072509766, Rounded RUL 23.0, Real RUL 28.0\n",
      "Engine 65, Predicted RUL 120.09810638427734, Rounded RUL 120.0, Real RUL 128.0\n",
      "Engine 66, Predicted RUL 12.892512321472168, Rounded RUL 12.0, Real RUL 14.0\n",
      "Engine 67, Predicted RUL 111.55892944335938, Rounded RUL 111.0, Real RUL 77.0\n",
      "Engine 68, Predicted RUL 8.180233001708984, Rounded RUL 8.0, Real RUL 8.0\n",
      "Engine 69, Predicted RUL 96.66205596923828, Rounded RUL 96.0, Real RUL 121.0\n",
      "Engine 70, Predicted RUL 99.94843292236328, Rounded RUL 99.0, Real RUL 94.0\n",
      "Engine 71, Predicted RUL 107.6190185546875, Rounded RUL 107.0, Real RUL 118.0\n",
      "Engine 72, Predicted RUL 49.55564498901367, Rounded RUL 49.0, Real RUL 50.0\n",
      "Engine 73, Predicted RUL 110.46394348144531, Rounded RUL 110.0, Real RUL 131.0\n",
      "Engine 74, Predicted RUL 104.67194366455078, Rounded RUL 104.0, Real RUL 126.0\n",
      "Engine 75, Predicted RUL 107.18620300292969, Rounded RUL 107.0, Real RUL 113.0\n",
      "Engine 76, Predicted RUL 11.280654907226562, Rounded RUL 11.0, Real RUL 10.0\n",
      "Engine 77, Predicted RUL 26.310819625854492, Rounded RUL 26.0, Real RUL 34.0\n",
      "Engine 78, Predicted RUL 124.36153411865234, Rounded RUL 124.0, Real RUL 107.0\n",
      "Engine 79, Predicted RUL 87.98456573486328, Rounded RUL 87.0, Real RUL 63.0\n",
      "Engine 80, Predicted RUL 96.73636627197266, Rounded RUL 96.0, Real RUL 90.0\n",
      "Engine 81, Predicted RUL 9.282401084899902, Rounded RUL 9.0, Real RUL 8.0\n",
      "Engine 82, Predicted RUL 7.501002311706543, Rounded RUL 7.0, Real RUL 9.0\n",
      "Engine 83, Predicted RUL 116.01570129394531, Rounded RUL 116.0, Real RUL 137.0\n",
      "Engine 84, Predicted RUL 66.51954650878906, Rounded RUL 66.0, Real RUL 58.0\n",
      "Engine 85, Predicted RUL 129.11386108398438, Rounded RUL 129.0, Real RUL 118.0\n",
      "Engine 86, Predicted RUL 105.31786346435547, Rounded RUL 105.0, Real RUL 89.0\n",
      "Engine 87, Predicted RUL 104.59969329833984, Rounded RUL 104.0, Real RUL 116.0\n",
      "Engine 88, Predicted RUL 112.44657135009766, Rounded RUL 112.0, Real RUL 115.0\n",
      "Engine 89, Predicted RUL 112.27588653564453, Rounded RUL 112.0, Real RUL 136.0\n",
      "Engine 90, Predicted RUL 33.97881317138672, Rounded RUL 33.0, Real RUL 28.0\n",
      "Engine 91, Predicted RUL 25.864349365234375, Rounded RUL 25.0, Real RUL 38.0\n",
      "Engine 92, Predicted RUL 24.1507511138916, Rounded RUL 24.0, Real RUL 20.0\n",
      "Engine 93, Predicted RUL 52.35270690917969, Rounded RUL 52.0, Real RUL 85.0\n",
      "Engine 94, Predicted RUL 56.36191177368164, Rounded RUL 56.0, Real RUL 55.0\n",
      "Engine 95, Predicted RUL 102.06832885742188, Rounded RUL 102.0, Real RUL 128.0\n",
      "Engine 96, Predicted RUL 110.13729095458984, Rounded RUL 110.0, Real RUL 137.0\n",
      "Engine 97, Predicted RUL 89.52613067626953, Rounded RUL 89.0, Real RUL 82.0\n",
      "Engine 98, Predicted RUL 84.6590347290039, Rounded RUL 84.0, Real RUL 59.0\n",
      "Engine 99, Predicted RUL 110.04949188232422, Rounded RUL 110.0, Real RUL 117.0\n",
      "Engine 100, Predicted RUL 14.221673011779785, Rounded RUL 14.0, Real RUL 20.0\n",
      "{'rhs': 3.47011012039595, 'rmse': 15.007331541616583}\n",
      "RMSE2: 15.007331541616583\n",
      "RHS: 3.47011012039595\n",
      "Time : 39.781829000000016 seconds\n"
     ]
    }
   ],
   "source": [
    "tModel.evaluate_model(['rhs', 'rmse'], round=2, tf_session=sess)\n",
    "print(\"scores\")\n",
    "\n",
    "cScores = tModel.scores\n",
    "#rmse = math.sqrt(cScores['score_1'])\n",
    "rmse2 = cScores['rmse']\n",
    "rhs = cScores['rhs']\n",
    "time = tModel.train_time\n",
    "\n",
    "i = range(1,len(tModel.y_test)+1)\n",
    "\n",
    "\n",
    "for i, rul_prediction, rul_prediction_rounded, true_rul in zip(i, np.ravel(tModel.y_predicted), tModel.y_predicted_rounded, np.ravel(tModel.y_test)):\n",
    "    print('Engine {}, Predicted RUL {}, Rounded RUL {}, Real RUL {}'.format(i, rul_prediction, \n",
    "                                                                    rul_prediction_rounded, \n",
    "                                                                    true_rul))\n",
    "\n",
    "print(cScores)\n",
    "#print(\"RMSE: {}\".format(rmse))\n",
    "print(\"RMSE2: {}\".format(rmse2))\n",
    "print(\"RHS: {}\".format(rhs))\n",
    "print(\"Time : {} seconds\".format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
