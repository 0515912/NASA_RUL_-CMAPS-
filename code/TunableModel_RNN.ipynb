{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Test notebook for the DataHandlers. Test the CMAPSS DataHandler\n",
    "\n",
    "First we import the necessary packages and create the global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_handler_CMAPS import CMAPSDataHandler\n",
    "from tunable_model import SequenceTunableModelRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D, LSTM, CuDNNLSTM\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "import CMAPSAuxFunctions\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define different types of Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2_lambda_regularization = 0.2\n",
    "#l1_lambda_regularization = 0.2\n",
    "\n",
    "def RULmodel_LSTM(input_shape):\n",
    "    \"\"\"Define the RNN model\"\"\"\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    #model.add(Masking(mask_value=0, imput))\n",
    "    #model.add(LSTM(input_shape=input_shape, units=20, return_sequences=False, dropout=0.2, name='lstm1'))\n",
    "    model.add(CuDNNLSTM(input_shape=input_shape, units=20, return_sequences=False, name='lstm1'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), \n",
    "                    name='fc1'))\n",
    "    model.add(Dense(1, activation='linear', kernel_initializer='glorot_normal', \n",
    "                    kernel_regularizer=regularizers.l2(l2_lambda_regularization), name='out'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Data Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Selected as per CNN paper\n",
    "features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "#selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "\n",
    "selected_indices = np.array(list(range(1,22)))\n",
    "\n",
    "selected_features = list(features[i] for i in selected_indices-1)\n",
    "data_folder = '../CMAPSSData'\n",
    "\n",
    "window_size = 30\n",
    "window_stride = 1\n",
    "max_rul = 0\n",
    "\n",
    "dHandler_cmaps = CMAPSDataHandler(data_folder, 1, selected_features, max_rul, window_size, window_stride)\n",
    "#dHandler_cmaps.load_data(verbose=1, cross_validation_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tunable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "#scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_compiled_model(shape, model_type='ann'):\n",
    "    \n",
    "    K.clear_session()  #Clear the previous tensorflow graph\n",
    "    \n",
    "    #To test the model without randomness\n",
    "\n",
    "    \n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0.001,beta_1=0.5)\n",
    "    \n",
    "    lossFunction = \"mean_squared_error\"\n",
    "    metrics = [\"mse\"]\n",
    "    model = None\n",
    "\n",
    "    #Create and compile the models\n",
    "\n",
    "    model = RULmodel_LSTM(shape)\n",
    "    model.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = len(selected_features)\n",
    "\n",
    "shape = (window_size, num_features)\n",
    "model = get_compiled_model(shape, model_type='lstm')\n",
    "tModel = SequenceTunableModelRegression('ModelRUL_LSTM_1', model, lib_type='keras', data_handler=dHandler_cmaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tModel.data_handler.sequence_length = 30\n",
    "#tModel.data_handler.sequence_length = maxWindowSize[datasetNumber]\n",
    "tModel.data_handler.sequence_stride = 1\n",
    "tModel.data_handler.max_rul = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for dataset 1 with window_size of 30, stride of 1 and maxRUL of 125. Cros-Validation ratio 0.01\n",
      "Loading data from file and computing dataframes\n",
      "cv number\n",
      "[55]\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(17567, 30, 14)\n",
      "(17567, 1)\n",
      "Cross-Validation data (X, y)\n",
      "(1, 30, 14)\n",
      "(1, 1)\n",
      "Testing data (X, y)\n",
      "(100, 30, 21)\n",
      "(100, 1)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[[0.         0.18373494 0.40680183 ... 0.         0.71317829 0.7246617 ]\n",
      "  [0.         0.28313253 0.4530194  ... 0.         0.66666667 0.73101353]\n",
      "  [0.         0.34337349 0.36952256 ... 0.         0.62790698 0.62137531]\n",
      "  ...\n",
      "  [0.         0.34337349 0.25724875 ... 0.         0.6744186  0.53838719]\n",
      "  [0.         0.21084337 0.30063222 ... 0.         0.6124031  0.64277824]\n",
      "  [0.         0.29819277 0.49008066 ... 0.         0.70542636 0.71361502]]\n",
      "\n",
      " [[0.         0.28313253 0.4530194  ... 0.         0.66666667 0.73101353]\n",
      "  [0.         0.34337349 0.36952256 ... 0.         0.62790698 0.62137531]\n",
      "  [0.         0.34337349 0.25615871 ... 0.         0.57364341 0.66238608]\n",
      "  ...\n",
      "  [0.         0.21084337 0.30063222 ... 0.         0.6124031  0.64277824]\n",
      "  [0.         0.29819277 0.49008066 ... 0.         0.70542636 0.71361502]\n",
      "  [0.         0.2439759  0.28646174 ... 0.         0.62015504 0.60908589]]\n",
      "\n",
      " [[0.         0.34337349 0.36952256 ... 0.         0.62790698 0.62137531]\n",
      "  [0.         0.34337349 0.25615871 ... 0.         0.57364341 0.66238608]\n",
      "  [0.         0.34939759 0.25746675 ... 0.         0.58914729 0.70450152]\n",
      "  ...\n",
      "  [0.         0.29819277 0.49008066 ... 0.         0.70542636 0.71361502]\n",
      "  [0.         0.2439759  0.28646174 ... 0.         0.62015504 0.60908589]\n",
      "  [0.         0.3373494  0.44342708 ... 0.         0.68217054 0.83637117]]\n",
      "\n",
      " [[0.         0.34337349 0.25615871 ... 0.         0.57364341 0.66238608]\n",
      "  [0.         0.34939759 0.25746675 ... 0.         0.58914729 0.70450152]\n",
      "  [0.         0.26807229 0.29278395 ... 0.         0.65116279 0.65272024]\n",
      "  ...\n",
      "  [0.         0.2439759  0.28646174 ... 0.         0.62015504 0.60908589]\n",
      "  [0.         0.3373494  0.44342708 ... 0.         0.68217054 0.83637117]\n",
      "  [0.         0.45180723 0.37846087 ... 0.         0.53488372 0.63021265]]\n",
      "\n",
      " [[0.         0.34939759 0.25746675 ... 0.         0.58914729 0.70450152]\n",
      "  [0.         0.26807229 0.29278395 ... 0.         0.65116279 0.65272024]\n",
      "  [0.         0.38253012 0.46391977 ... 0.         0.74418605 0.667219  ]\n",
      "  ...\n",
      "  [-0.70180933  0.13976207 -0.95260149 ... -0.78170979  1.12718287\n",
      "    1.94178323]\n",
      "  [ 0.05812812 -0.34629233 -0.72261137 ... -0.78170979  0.07596096\n",
      "    0.56254617]\n",
      "  [-0.2818439  -1.47661348 -0.93926872 ... -0.78170979 -0.03469398\n",
      "    0.18009195]]]\n",
      "[[125.]\n",
      " [125.]\n",
      " [125.]\n",
      " [125.]\n",
      " [125.]]\n",
      "Cross-Validation data (X, y)\n",
      "[[[ 0.13812154  0.54915689 -0.65705863  0.37543752 -0.6572157\n",
      "   -0.69435294 -0.34135027 -0.0860569  -0.0855483  -0.65018391\n",
      "    0.20142897 -0.78170979 -0.14534892 -0.07857273]\n",
      "  [-0.66181262 -0.0461782   0.10846404 -0.12169785 -0.6572157\n",
      "   -0.48830598 -0.3787921   0.59187655  0.05350055 -0.39121588\n",
      "    0.86002312  0.50967466 -0.20067638  0.62628854]\n",
      "  [ 0.4180985  -0.29409857 -0.69150159  0.74828904 -0.37546111\n",
      "   -0.84152934 -0.49111761 -0.12673291 -0.22459715 -0.61768185\n",
      "    0.4760654  -0.78170979  0.40792577  0.43783284]\n",
      "  [-0.88179452 -0.00866394 -1.18370267 -0.5058479   0.04717078\n",
      "   -0.4624935  -0.71576862 -0.00470489 -0.50269485 -0.30209733\n",
      "   -0.61448119  0.50967466  0.57390818 -0.05547767]\n",
      "  [-0.22184883  0.11203414 -0.00486442  1.52788769 -0.23458381\n",
      "   -0.48332462 -0.34135027  0.4834072   0.19254939 -0.07091332\n",
      "    0.07610944 -1.42740201  0.29727084  0.43506143]\n",
      "  [-0.38183567  0.28329492  0.0095794   0.1494669  -0.09370652\n",
      "   -0.6042357   0.10795176  0.34782051  0.05350055 -0.77023184\n",
      "   -0.19052787 -0.78170979  0.90587299  0.54868913]\n",
      "  [ 0.51809027 -0.79972563 -0.82816239  0.27375074 -0.37546111\n",
      "   -0.67397467 -0.30390843  0.22579249 -0.363646   -0.56158959\n",
      "   -0.33184565  0.50967466  0.90587299  0.07015946]\n",
      "  [ 0.1981166  -1.13735403  0.37956351  0.34154193 -0.6572157\n",
      "   -0.48830598  0.03306809  0.97151929  0.33159824 -0.33040557\n",
      "    0.39074146 -0.13601757  0.46325324  0.39349032]\n",
      "  [-0.04186365  0.06310248  0.46844858 -0.42675819 -0.37546111\n",
      "   -0.60106574 -0.2664666  -0.04538089 -0.50269485 -0.38440093\n",
      "   -0.56648648 -0.78170979  1.0718554   0.20133941]\n",
      "  [-0.7618044  -1.86806669 -0.12819246 -0.31377287 -0.37546111\n",
      "   -0.56483771 -1.12762881  0.04952979  1.02684248 -0.2722164\n",
      "   -0.58781746 -0.13601757  0.07596096  0.5754794 ]\n",
      "  [-0.12185706 -0.61704747 -0.87260492 -0.12169785  0.04717078\n",
      "   -0.46656915 -0.07925742  0.21223382 -0.64174369 -0.3172999\n",
      "    0.31341664 -0.78170979  0.46325324 -0.34278023]\n",
      "  [-0.12185706 -1.22053784 -0.92704703  0.6240052   0.18804808\n",
      "   -0.47290906 -0.64088495  0.03597112 -0.22459715 -0.35714114\n",
      "   -0.49982715 -0.78170979  0.02063349  0.87017239]\n",
      "  [-0.16185377  0.36321661 -1.00259934  0.8047817  -0.09370652\n",
      "   -0.71925972 -0.56600128  0.74102191 -0.22459715 -0.74349628\n",
      "   -0.0785402  -0.78170979 -0.31133132  0.79626819]\n",
      "  [-1.04178135 -0.73448343 -0.61706034  0.45452724 -0.37546111\n",
      "   -0.38822602 -0.15414109  0.79525659  0.60969594 -0.37811021\n",
      "    0.04144659 -0.13601757  0.85054552  0.95885742]\n",
      "  [-0.08186036 -0.82908463  0.16401721 -0.73181852 -0.37546111\n",
      "   -0.418567   -0.15414109  0.34782051  0.19254939 -0.55058082\n",
      "   -0.9104486   1.15536688  0.3525983   0.63737417]\n",
      "  [ 0.61808204  0.26046015 -1.08370696  0.83867729 -0.23458381\n",
      "   -0.63457668 -0.19158293  0.99863662 -0.22459715 -0.51860299\n",
      "    0.05477845 -0.13601757  1.01652793  0.19487279]\n",
      "  [ 0.09812483 -0.26473958  0.73065953 -0.52844496  0.32892537\n",
      "   -0.49192878  0.22027726  0.51052454  0.60969594 -0.51545763\n",
      "    0.44140255 -0.13601757 -0.64329614  0.71866878]\n",
      "  [ 0.15811989 -1.13409192 -0.58039525  0.34154193  0.04717078\n",
      "   -0.71744831 -0.11669925  0.4834072   0.05350055 -0.59776123\n",
      "    0.03611384 -0.13601757  0.24194337  0.24660573]\n",
      "  [-1.08177806 -0.30062279 -0.57706206  0.27375074 -0.23458381\n",
      "   -0.64544509 -0.60344311  0.41561385 -0.22459715  0.07115214\n",
      "   -0.46249793 -0.13601757  0.51858071 -0.2531714 ]\n",
      "  [-0.92179123  0.73672822 -0.65816969 -0.48325084  0.04717078\n",
      "   -0.31576995 -0.22902476 -0.01826356  0.05350055 -0.91334576\n",
      "   -0.62514668  1.15536688 -1.47320817  0.39903314]\n",
      "  [ 1.37801949  0.50674946  0.09624234  0.11557131 -0.23458381\n",
      "   -0.09794887 -0.49111761 -0.04538089 -0.22459715 -0.40694268\n",
      "    0.31874939 -0.78170979  0.40792577 -0.19220043]\n",
      "  [ 0.4180985  -0.75894926 -0.48262168 -0.25728022 -0.09370652\n",
      "   -0.40860429 -0.90297779  0.37493785 -0.64174369 -0.50549732\n",
      "    0.30008477 -0.13601757  0.29727084  0.37224286]\n",
      "  [ 0.51809027 -0.62520274  0.03735599  0.34154193 -0.37546111\n",
      "   -0.47155051 -0.49111761  0.51052454 -0.0855483  -0.61977876\n",
      "   -0.37184124 -0.78170979 -0.80927854  0.97825727]\n",
      "  [ 0.05812812 -0.63498908 -0.89371513  0.6240052   0.32892537\n",
      "   -0.44211523 -1.0153033   0.21223382  0.47064709 -0.43787206\n",
      "   -0.92911322 -0.13601757 -0.14534892  0.44060425]\n",
      "  [-1.14177312 -1.0949466  -0.15485798  1.20023029 -0.23458381\n",
      "   -0.2668621  -0.49111761  0.55120055 -0.22459715 -0.37234372\n",
      "    1.2786437  -0.78170979  0.90587299  0.65123121]\n",
      "  [-1.18176983  0.20337322 -0.7670539  -0.25728022 -0.37546111\n",
      "   -0.24693668  0.48237011  0.52408321 -0.22459715 -0.5500566\n",
      "   -0.20119336 -0.13601757 -0.14534892  0.75562088]\n",
      "  [ 0.9380557   0.43661409 -1.18703586  0.36413899  0.46980267\n",
      "   -0.23063406 -0.49111761  0.7003459   0.19254939 -0.43734784\n",
      "   -0.74513347 -0.13601757  0.96120046  0.0479882 ]\n",
      "  [-1.08177806 -1.57284573 -0.78594198 -0.27987728 -0.9389703\n",
      "   -0.30354299  0.14539359 -0.0860569  -1.05889024 -0.42109681\n",
      "    0.35341224 -0.78170979  0.85054552  0.59303165]\n",
      "  [-0.58181921  0.47412836  0.48844772  0.01388453 -0.37546111\n",
      "   -0.0721364  -0.15414109 -0.31655427  0.05350055 -0.07563136\n",
      "    0.03344747 -0.78170979  0.13128843  0.27986262]\n",
      "  [ 0.39810014 -0.23701164 -0.42595744 -0.24598169 -0.51633841\n",
      "   -0.80484846  0.33260277 -0.31655427  0.05350055 -0.14220816\n",
      "   -0.01188088 -0.13601757  0.68456312  0.12835902]]]\n",
      "[[109.]]\n",
      "Testing data (X, y)\n",
      "[[[0.         0.15060241 0.3795509  ... 0.         0.68217054 0.68682684]\n",
      "  [0.         0.37650602 0.34663179 ... 0.         0.72868217 0.72134769]\n",
      "  [0.         0.37048193 0.2851537  ... 0.         0.66666667 0.66210991]\n",
      "  ...\n",
      "  [0.         0.22289157 0.35120994 ... 0.         0.68217054 0.64609224]\n",
      "  [0.         0.47590361 0.32003488 ... 0.         0.73643411 0.7079536 ]\n",
      "  [0.         0.4126506  0.22193155 ... 0.         0.51937984 0.63656448]]\n",
      "\n",
      " [[0.         0.45481928 0.39481142 ... 0.         0.48837209 0.49061033]\n",
      "  [0.         0.33433735 0.42903859 ... 0.         0.58139535 0.67578017]\n",
      "  [0.         0.37048193 0.3148027  ... 0.         0.57364341 0.48784866]\n",
      "  ...\n",
      "  [0.         0.4939759  0.36058426 ... 0.         0.57364341 0.55550953]\n",
      "  [0.         0.43072289 0.36341836 ... 0.         0.65891473 0.54901961]\n",
      "  [0.         0.40361446 0.33900153 ... 0.         0.51937984 0.50759459]]\n",
      "\n",
      " [[0.         0.49698795 0.38936124 ... 0.         0.52713178 0.48536316]\n",
      "  [0.         0.37650602 0.55068672 ... 0.         0.65891473 0.491715  ]\n",
      "  [0.         0.45180723 0.52125572 ... 0.         0.62015504 0.45346589]\n",
      "  ...\n",
      "  [0.         0.55722892 0.42402442 ... 0.         0.41860465 0.47100249]\n",
      "  [0.         0.61144578 0.38369305 ... 0.         0.3255814  0.45954156]\n",
      "  [0.         0.50301205 0.40789187 ... 0.         0.6124031  0.52444076]]\n",
      "\n",
      " [[0.         0.37349398 0.49792893 ... 0.         0.54263566 0.60535764]\n",
      "  [0.         0.59638554 0.26139089 ... 0.         0.60465116 0.60411489]\n",
      "  [0.         0.50301205 0.4647918  ... 0.         0.52713178 0.65009666]\n",
      "  ...\n",
      "  [0.         0.4939759  0.38979725 ... 0.         0.56589147 0.49461475]\n",
      "  [0.         0.44277108 0.47896228 ... 0.         0.41085271 0.52236951]\n",
      "  [0.         0.47289157 0.51209941 ... 0.         0.34108527 0.5024855 ]]\n",
      "\n",
      " [[0.         0.4126506  0.53128406 ... 0.         0.46511628 0.54750069]\n",
      "  [0.         0.36144578 0.28755178 ... 0.         0.46511628 0.55785695]\n",
      "  [0.         0.57228916 0.35666013 ... 0.         0.43410853 0.44794256]\n",
      "  ...\n",
      "  [0.         0.45180723 0.46653586 ... 0.         0.5503876  0.4584369 ]\n",
      "  [0.         0.45481928 0.48048834 ... 0.         0.41860465 0.56255178]\n",
      "  [0.         0.31927711 0.41203401 ... 0.         0.47286822 0.71458161]]]\n",
      "[[112.]\n",
      " [ 98.]\n",
      " [ 69.]\n",
      " [ 82.]\n",
      " [ 91.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/controlslab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/media/controlslab/DATA/Projects/NASA_RUL_-CMAPS-/code/data_handler_CMAPS.py:133: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  norm_test_df = pd.DataFrame(self._data_scaler.transform(self._df_test[cols_normalize]), columns=cols_normalize, index=self._df_test.index)\n"
     ]
    }
   ],
   "source": [
    "# #Load sequenced data (do not unroll sequence into a single feature vector)\n",
    "\n",
    "tModel.data_handler.data_scaler = scaler\n",
    "tModel.data_scaler = None\n",
    "\n",
    "tModel.load_data(unroll=False, verbose=1, cross_validation_ratio=0.01)\n",
    "tModel.print_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model and test some Tunable Model functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17731/17731 [==============================] - 3s 159us/step - loss: 8124.7990 - mean_squared_error: 8120.3017\n",
      "Epoch 2/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 7349.1129 - mean_squared_error: 7344.1392\n",
      "Epoch 3/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 6273.7442 - mean_squared_error: 6267.9084\n",
      "Epoch 4/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 5267.1569 - mean_squared_error: 5260.1987\n",
      "Epoch 5/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 4307.9284 - mean_squared_error: 4299.6841\n",
      "Epoch 6/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 3421.1964 - mean_squared_error: 3411.5036\n",
      "Epoch 7/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 2634.1178 - mean_squared_error: 2622.8905\n",
      "Epoch 8/100\n",
      "17731/17731 [==============================] - 0s 11us/step - loss: 1996.1576 - mean_squared_error: 1983.3752\n",
      "Epoch 9/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 1503.8797 - mean_squared_error: 1489.6082\n",
      "Epoch 10/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 1137.3455 - mean_squared_error: 1121.6964\n",
      "Epoch 11/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 894.3259 - mean_squared_error: 877.4613\n",
      "Epoch 12/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 716.7695 - mean_squared_error: 698.8485\n",
      "Epoch 13/100\n",
      "17731/17731 [==============================] - 0s 13us/step - loss: 610.9626 - mean_squared_error: 592.1667\n",
      "Epoch 14/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 543.6025 - mean_squared_error: 524.1088\n",
      "Epoch 15/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 504.9727 - mean_squared_error: 484.9283\n",
      "Epoch 16/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 476.0897 - mean_squared_error: 455.6092\n",
      "Epoch 17/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 456.2636 - mean_squared_error: 435.4215\n",
      "Epoch 18/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 427.2541 - mean_squared_error: 406.1012\n",
      "Epoch 19/100\n",
      "17731/17731 [==============================] - 0s 11us/step - loss: 396.0625 - mean_squared_error: 374.6368\n",
      "Epoch 20/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 366.7247 - mean_squared_error: 345.0441\n",
      "Epoch 21/100\n",
      "17731/17731 [==============================] - 0s 11us/step - loss: 339.2025 - mean_squared_error: 317.3011\n",
      "Epoch 22/100\n",
      "17731/17731 [==============================] - 0s 11us/step - loss: 325.4450 - mean_squared_error: 303.3591\n",
      "Epoch 23/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 317.6623 - mean_squared_error: 295.4273\n",
      "Epoch 24/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 301.1245 - mean_squared_error: 278.7785\n",
      "Epoch 25/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 298.3553 - mean_squared_error: 275.9230\n",
      "Epoch 26/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 296.5971 - mean_squared_error: 274.0994\n",
      "Epoch 27/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 286.6203 - mean_squared_error: 264.0590\n",
      "Epoch 28/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 282.8544 - mean_squared_error: 260.2455\n",
      "Epoch 29/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 280.4644 - mean_squared_error: 257.8231\n",
      "Epoch 30/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 276.0648 - mean_squared_error: 253.4160\n",
      "Epoch 31/100\n",
      "17731/17731 [==============================] - 0s 13us/step - loss: 276.1473 - mean_squared_error: 253.4984\n",
      "Epoch 32/100\n",
      "17731/17731 [==============================] - 0s 11us/step - loss: 275.3912 - mean_squared_error: 252.7356\n",
      "Epoch 33/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 269.7273 - mean_squared_error: 247.0881\n",
      "Epoch 34/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 266.2979 - mean_squared_error: 243.6374\n",
      "Epoch 35/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 262.6065 - mean_squared_error: 239.9600\n",
      "Epoch 36/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 268.1682 - mean_squared_error: 245.5478\n",
      "Epoch 37/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 260.1387 - mean_squared_error: 237.5245\n",
      "Epoch 38/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 262.2583 - mean_squared_error: 239.6513\n",
      "Epoch 39/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 259.7080 - mean_squared_error: 237.1387\n",
      "Epoch 40/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 259.5588 - mean_squared_error: 237.0166\n",
      "Epoch 41/100\n",
      "17731/17731 [==============================] - 0s 11us/step - loss: 253.1848 - mean_squared_error: 230.6698\n",
      "Epoch 42/100\n",
      "17731/17731 [==============================] - 0s 11us/step - loss: 256.2549 - mean_squared_error: 233.7652\n",
      "Epoch 43/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 252.1875 - mean_squared_error: 229.7386\n",
      "Epoch 44/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 251.4290 - mean_squared_error: 229.0258\n",
      "Epoch 45/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 252.1743 - mean_squared_error: 229.8076\n",
      "Epoch 46/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 256.0697 - mean_squared_error: 233.7265\n",
      "Epoch 47/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 243.8837 - mean_squared_error: 221.5829\n",
      "Epoch 48/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 246.7246 - mean_squared_error: 224.4732\n",
      "Epoch 49/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 244.6302 - mean_squared_error: 222.4008\n",
      "Epoch 50/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 245.3569 - mean_squared_error: 223.1838\n",
      "Epoch 51/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 242.7728 - mean_squared_error: 220.6362\n",
      "Epoch 52/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 240.4533 - mean_squared_error: 218.3144\n",
      "Epoch 53/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 242.2272 - mean_squared_error: 220.0917\n",
      "Epoch 54/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 239.7808 - mean_squared_error: 217.6510\n",
      "Epoch 55/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 237.5036 - mean_squared_error: 215.3748\n",
      "Epoch 56/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 236.2208 - mean_squared_error: 214.0904\n",
      "Epoch 57/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 238.0302 - mean_squared_error: 215.9026\n",
      "Epoch 58/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 239.8955 - mean_squared_error: 217.7693\n",
      "Epoch 59/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 238.4437 - mean_squared_error: 216.3193\n",
      "Epoch 60/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 236.4635 - mean_squared_error: 214.3419\n",
      "Epoch 61/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 231.2910 - mean_squared_error: 209.1748\n",
      "Epoch 62/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 241.0969 - mean_squared_error: 218.9855\n",
      "Epoch 63/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 239.5095 - mean_squared_error: 217.4020\n",
      "Epoch 64/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 236.9010 - mean_squared_error: 214.7994\n",
      "Epoch 65/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 233.6574 - mean_squared_error: 211.5597\n",
      "Epoch 66/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 235.9406 - mean_squared_error: 213.8504\n",
      "Epoch 67/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 235.1898 - mean_squared_error: 213.1027\n",
      "Epoch 68/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 238.0044 - mean_squared_error: 215.9240\n",
      "Epoch 69/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 235.0965 - mean_squared_error: 213.0250\n",
      "Epoch 70/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 236.5366 - mean_squared_error: 214.4736\n",
      "Epoch 71/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 236.2461 - mean_squared_error: 214.1879\n",
      "Epoch 72/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 234.7740 - mean_squared_error: 212.7216\n",
      "Epoch 73/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 236.6503 - mean_squared_error: 214.6067\n",
      "Epoch 74/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 239.8113 - mean_squared_error: 217.7718\n",
      "Epoch 75/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 238.4205 - mean_squared_error: 216.3893\n",
      "Epoch 76/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 238.7634 - mean_squared_error: 216.7341\n",
      "Epoch 77/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 236.6628 - mean_squared_error: 214.6378\n",
      "Epoch 78/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 237.2361 - mean_squared_error: 215.2189\n",
      "Epoch 79/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 232.7444 - mean_squared_error: 210.7339\n",
      "Epoch 80/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 234.3098 - mean_squared_error: 212.3079\n",
      "Epoch 81/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 233.9130 - mean_squared_error: 211.9227\n",
      "Epoch 82/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 239.4950 - mean_squared_error: 217.5147\n",
      "Epoch 83/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 231.9233 - mean_squared_error: 209.9513\n",
      "Epoch 84/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 237.0665 - mean_squared_error: 215.1042\n",
      "Epoch 85/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 237.3220 - mean_squared_error: 215.3680\n",
      "Epoch 86/100\n",
      "17731/17731 [==============================] - 0s 11us/step - loss: 230.9901 - mean_squared_error: 209.0418\n",
      "Epoch 87/100\n",
      "17731/17731 [==============================] - 0s 11us/step - loss: 233.9738 - mean_squared_error: 212.0340\n",
      "Epoch 88/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 235.4307 - mean_squared_error: 213.5019\n",
      "Epoch 89/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 234.0835 - mean_squared_error: 212.1674\n",
      "Epoch 90/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 233.3397 - mean_squared_error: 211.4307\n",
      "Epoch 91/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 235.7990 - mean_squared_error: 213.8980\n",
      "Epoch 92/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 233.9922 - mean_squared_error: 212.0996\n",
      "Epoch 93/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 233.7144 - mean_squared_error: 211.8353\n",
      "Epoch 94/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 234.5737 - mean_squared_error: 212.7055\n",
      "Epoch 95/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 232.9813 - mean_squared_error: 211.1259\n",
      "Epoch 96/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 230.9072 - mean_squared_error: 209.0597\n",
      "Epoch 97/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 236.7594 - mean_squared_error: 214.9242\n",
      "Epoch 98/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 230.2582 - mean_squared_error: 208.4359\n",
      "Epoch 99/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 237.1009 - mean_squared_error: 215.2883\n",
      "Epoch 100/100\n",
      "17731/17731 [==============================] - 0s 12us/step - loss: 232.6953 - mean_squared_error: 210.8879\n"
     ]
    }
   ],
   "source": [
    "nFeatures = len(selected_features)\n",
    "\n",
    "lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "\n",
    "shape = (tModel.data_handler.sequence_length, nFeatures)\n",
    "model = get_compiled_model(shape, model_type='lstm')\n",
    "tModel.change_model('ModelRUL_RNN_1', model, 'keras')\n",
    "\n",
    "tModel.epochs = 100\n",
    "\n",
    "tModel.train_model(learningRate_scheduler=lrate, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tModel.evaluate_model(['rhs', 'rmse'], round=2)\n",
    "print(\"scores\")\n",
    "\n",
    "cScores = tModel.scores\n",
    "#rmse = math.sqrt(cScores['score_1'])\n",
    "rmse2 = cScores['rmse']\n",
    "rhs = cScores['rhs']\n",
    "time = tModel.train_time\n",
    "\n",
    "i = range(1,len(tModel.y_test)+1)\n",
    "\n",
    "#print(tModel.y_predicted)\n",
    "#print(tModel.y_predicted_rounded)\n",
    "#print(tModel.y_test)\n",
    "\n",
    "for i, rul_prediction, rul_prediction_rounded, true_rul in zip(i, np.ravel(tModel.y_predicted), tModel.y_predicted_rounded, np.ravel(tModel.y_test)):\n",
    "    print('Engine {}, Predicted RUL {}, Rounded RUL {}, Real RUL {}'.format(i, rul_prediction, \n",
    "                                                                    rul_prediction_rounded, \n",
    "                                                                    true_rul))\n",
    "\n",
    "print(cScores)\n",
    "#print(\"RMSE: {}\".format(rmse))\n",
    "print(\"RMSE2: {}\".format(rmse2))\n",
    "print(\"RHS: {}\".format(rhs))\n",
    "print(\"Time : {} seconds\".format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 50\n",
      "1 51\n",
      "2 52\n",
      "3 53\n",
      "4 54\n",
      "5 55\n",
      "6 56\n",
      "7 57\n",
      "8 58\n",
      "9 59\n",
      "10 60\n",
      "11 61\n",
      "12 62\n",
      "13 63\n",
      "14 64\n",
      "15 65\n",
      "16 66\n",
      "17 67\n",
      "18 68\n",
      "19 69\n",
      "20 70\n",
      "21 71\n",
      "22 72\n",
      "23 73\n",
      "24 74\n",
      "25 75\n",
      "26 76\n",
      "27 77\n",
      "28 78\n",
      "29 79\n",
      "30 80\n",
      "31 81\n",
      "32 82\n",
      "33 83\n",
      "34 84\n",
      "35 85\n",
      "36 86\n",
      "37 87\n",
      "38 88\n",
      "39 89\n",
      "40 90\n",
      "41 91\n",
      "42 92\n",
      "43 93\n",
      "44 94\n",
      "45 95\n",
      "46 96\n",
      "47 97\n",
      "48 98\n",
      "49 99\n",
      "50 100\n",
      "51 101\n",
      "52 102\n",
      "53 103\n",
      "54 104\n",
      "55 105\n",
      "56 106\n",
      "57 107\n",
      "58 108\n",
      "59 109\n",
      "60 110\n",
      "61 111\n",
      "62 112\n",
      "63 113\n",
      "64 114\n",
      "65 115\n",
      "66 116\n",
      "67 117\n",
      "68 118\n",
      "69 119\n",
      "70 120\n",
      "71 121\n",
      "72 122\n",
      "73 123\n",
      "74 124\n",
      "75 125\n",
      "76 126\n",
      "77 127\n",
      "78 128\n",
      "79 129\n",
      "80 130\n",
      "81 131\n",
      "82 132\n",
      "83 133\n",
      "84 134\n",
      "85 135\n",
      "86 136\n",
      "87 137\n",
      "88 138\n",
      "89 139\n",
      "90 140\n",
      "91 141\n",
      "92 142\n",
      "93 143\n",
      "94 144\n",
      "95 145\n",
      "96 146\n",
      "97 147\n",
      "98 148\n",
      "99 149\n",
      "100 150\n",
      "101 151\n",
      "102 152\n",
      "103 153\n",
      "104 154\n",
      "105 155\n",
      "106 156\n",
      "107 157\n",
      "108 158\n",
      "109 159\n",
      "110 160\n",
      "111 161\n"
     ]
    }
   ],
   "source": [
    "for start, stop in zip(range(0, 112), range(50, 192)):\n",
    "    print(start, stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
