{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import custom_scores\n",
    "import CMAPSAuxFunctions\n",
    "from tunableModel import TunableModel\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "\n",
    "from scipy.optimize import differential_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clear the previous tensorflow graph\n",
    "K.clear_session()\n",
    "\n",
    "FilterN = 10\n",
    "FilterL = 10\n",
    "\n",
    "def RULmodel_SN_1(input_shape):\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(250, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', name='fc1'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(50, activation='relu', kernel_initializer='glorot_normal', name='fc2'))\n",
    "    #model.add(Dense(5, activation='relu', kernel_initializer='glorot_normal', name='fc3'))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(Dense(10, activation='relu', name='fc3'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(10, activation='tanh', name='fc4'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    #create a placeholder for the input\n",
    "    #X_input = Input(shape=(input_shape))\n",
    "    \n",
    "    #Create the layers\n",
    "    #X = Dense(100, activation='relu', name='fc1')(X_input)\n",
    "    #X = Dense(100, activation='relu', name='fc2')(X)\n",
    "    #X = Dense(1, activation='linear', name='out')(X)\n",
    "    \n",
    "    # Create model. This creates the Keras model instance, you'll use this instance to train/test the model.\n",
    "    #model = Sequential(inputs = X_input, outputs = X, name='RUL')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def RULModel_CNN_1(input_shape):\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    print(input_shape)\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Conv2D(1, (FilterN, FilterL), input_shape=input_shape, padding='same', kernel_initializer='glorot_normal', activation='relu', name='cl1'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(MaxPooling2D(pool_size=5, name='pl1'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(20, activation='relu', kernel_initializer='glorot_normal', name='fc1'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def RULCNNModel(TW, FeatureN):\n",
    "    \n",
    "    input_layer = Input(shape=(TW, FeatureN))\n",
    "    y = Reshape((TW, FeatureN, 1), input_shape=(TW, FeatureN, ),name = 'Reshape')(input_layer)\n",
    "\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C1')(y)\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C2')(y)\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C3')(y)\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C4')(y)\n",
    "    #y = Convolution2D(FilterN, FilterL, 1, border_mode='same', init='glorot_normal', activation='tanh', name='C5')(y)\n",
    "    #y = Convolution2D(FilterN, FilterL, 1, border_mode='same', init='glorot_normal', activation='tanh', name='C6')(y)\n",
    "    \n",
    "    y = Conv2D(1, 3, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='Clast')(y)  \n",
    "    \n",
    "    y = Reshape((TW,14))(y)\n",
    "    y = Flatten()(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "    \n",
    "    #y = Dense(100, activation='tanh', init='glorot_normal', activity_regularizer=keras.regularizers.l2(0.01),)(y)\n",
    "    y = Dense(100,activation='tanh', kernel_initializer='glorot_normal', name='fc')(y)\n",
    "    y = Dense(1)(y)\n",
    "    \n",
    "    model = Model(inputs = input_layer, outputs = y, name='RUL_CNN_Model')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selected_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1a5ac75cb5a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Create and compile the models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mshapeSN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnFeatures\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindowSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mshapeCNN1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindowSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'selected_features' is not defined"
     ]
    }
   ],
   "source": [
    "#Shared parameters for the models\n",
    "optimizer = Adam(lr=0, beta_1=0.5)\n",
    "lossFunction = \"mean_squared_error\"\n",
    "metrics = [\"mse\"]\n",
    "\n",
    "#Create and compile the models\n",
    "nFeatures = len(selected_features)\n",
    "shapeSN = nFeatures*tModel.windowSize\n",
    "shapeCNN1 = (tModel.windowSize, nFeatures, 1)\n",
    "shapeDCNN1 = (tModel.windowSize, nFeatures)\n",
    "\n",
    "modelRULSN = RULmodel_SN_1(shapeSN)\n",
    "modelRULCNN = RULModel_CNN_1(shapeCNN1)\n",
    "DCNN = RULCNNModel(shapeDCNN1[0], shapeDCNN1[1])\n",
    "\n",
    "modelRULSN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "modelRULCNN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "DCNN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "#Add the models to the tunableModel object\n",
    "#tModel.addModel('RULmodel_SN_1', modelRULSN)\n",
    "#tModel.addModel('RULModel_CNN_1', modelRULCNN)\n",
    "#tModel.addModel('RULCNNModel', DCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for dataset 1 with window_size of 30, stride of 1 and constRUL of 125. Cros-Validation ratio 0\n",
      "Data loaded for dataset 1\n"
     ]
    }
   ],
   "source": [
    "#Shared parameters for the models\n",
    "optimizer = Adam(lr=0, beta_1=0.5)\n",
    "lossFunction = \"mean_squared_error\"\n",
    "metrics = [\"mse\"]\n",
    "\n",
    "#Selected as per CNN paper\n",
    "selected_features = ['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'htBleed', 'W31', 'W32']\n",
    "\n",
    "windowSize = 30\n",
    "dataFolder = '../CMAPSSData'\n",
    "\n",
    "#Create and compile the models\n",
    "nFeatures = len(selected_features)\n",
    "shapeSN = nFeatures*windowSize\n",
    "modelRULSN = RULmodel_SN_1(shapeSN)\n",
    "modelRULSN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "tModel = TunableModel('ModelRUL_SN_1', modelRULSN, selected_features, dataFolder, \n",
    "                      scaler = min_max_scaler, window_stride=1)\n",
    "tModel.loadData(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(17731, 420)\n",
      "(17731, 1)\n",
      "Testing data (X, y)\n",
      "(100, 420)\n",
      "(100, 1)\n",
      "Printing last 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[ 0.62199313  0.32071611  0.36067504 ...,  0.45454545 -0.4488189\n",
      "  -0.77474791]\n",
      " [ 0.20962199  0.14475703  0.60204082 ...,  0.09090909 -0.7480315\n",
      "  -0.24669791]\n",
      " [ 0.12714777  0.14475703  0.71428571 ...,  0.63636364 -0.52755906\n",
      "  -0.88893623]\n",
      " [ 0.03092784  0.14475703  0.78296703 ...,  0.09090909 -0.76377953\n",
      "  -0.51768215]\n",
      " [ 0.26460481  0.15191816  0.50039246 ...,  0.27272727 -0.63779528\n",
      "  -0.55120011]]\n",
      "[[ 4.]\n",
      " [ 3.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [ 0.]]\n",
      "Testing data (X, y)\n",
      "[[-0.49140893 -0.54373402 -0.47959184 ..., -0.63636364  0.29133858\n",
      "   0.60886238]\n",
      " [ 0.11340206 -0.19028133 -0.21350078 ...,  0.09090909 -0.25984252\n",
      "   0.1393268 ]\n",
      " [-0.03780069  0.10537084 -0.18210361 ..., -0.09090909 -0.02362205\n",
      "   0.32537992]\n",
      " [-0.32646048 -0.05012788 -0.49568289 ..., -0.63636364  0.27559055\n",
      "   0.32168726]\n",
      " [-0.20962199  0.03375959  0.02943485 ...,  0.27272727 -0.11811024\n",
      "  -0.17256072]]\n",
      "[[ 125.]\n",
      " [  82.]\n",
      " [  59.]\n",
      " [ 117.]\n",
      " [  20.]]\n",
      "Loading data for dataset 1 with window_size of 30, stride of 1 and constRUL of 125. Cros-Validation ratio 0.1\n",
      "Data loaded for dataset 1\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(15978, 420)\n",
      "(15978, 1)\n",
      "Cross-Validation data (X, y)\n",
      "(10, 420)\n",
      "(10, 1)\n",
      "Testing data (X, y)\n",
      "(100, 420)\n",
      "(100, 1)\n",
      "Printing last 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[ 0.2233677   0.29462916  0.22645212 ...,  0.4        -0.456      -0.57875302]\n",
      " [ 0.69072165  0.12736573  0.23783359 ..., -0.2        -0.632      -0.79207499]\n",
      " [ 0.46391753  0.25882353 -0.05455259 ...,  0.2        -0.344      -0.2904417 ]\n",
      " [ 0.08591065  0.06342711  0.11459969 ...,  0.2        -0.536      -0.56369834]\n",
      " [ 0.02405498  0.26086957  0.43288854 ...,  0.6        -0.472      -0.15097287]]\n",
      "[[ 4.]\n",
      " [ 3.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [ 0.]]\n",
      "Cross-Validation data (X, y)\n",
      "[[-0.16151203  0.0511509  -0.03061224 ...,  0.          0.184       0.28305638]\n",
      " [-0.13402062  0.04245524 -0.1310832  ...,  0.         -0.168      -0.18392274]\n",
      " [ 0.04467354 -0.52276215 -0.30023548 ..., -0.6         0.28        0.52591961]\n",
      " [-0.2233677  -0.16419437 -0.02864992 ..., -0.4         0.104       0.22851868]\n",
      " [-0.31271478 -0.20613811 -0.09497645 ..., -0.2        -0.056      -0.26487715]]\n",
      "[[ 176.]\n",
      " [  25.]\n",
      " [ 140.]\n",
      " [  46.]\n",
      " [  53.]]\n",
      "Testing data (X, y)\n",
      "[[-0.49140893 -0.54373402 -0.47959184 ..., -0.6         0.28        0.60886238]\n",
      " [ 0.11340206 -0.19028133 -0.21350078 ...,  0.2        -0.28        0.1393268 ]\n",
      " [-0.03780069  0.10537084 -0.18210361 ...,  0.         -0.04        0.32537992]\n",
      " [-0.32646048 -0.05012788 -0.49568289 ..., -0.6         0.264       0.32168726]\n",
      " [-0.20962199  0.03375959  0.02943485 ...,  0.4        -0.136      -0.17256072]]\n",
      "[[ 125.]\n",
      " [  82.]\n",
      " [  59.]\n",
      " [ 117.]\n",
      " [  20.]]\n"
     ]
    }
   ],
   "source": [
    "#tModel.printData(printTop=False)\n",
    "#tModel.windowSize = 20\n",
    "#tModel.changeDataset(2)\n",
    "#tModel.loadData(verbose=1, crossValRatio=0.1)\n",
    "#tModel.printData(printTop=False)\n",
    "tModel.getModelDescription()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14184/14184 [==============================] - 1s 76us/step - loss: 4679.1091 - mean_squared_error: 4679.1091\n",
      "Epoch 2/20\n",
      "14184/14184 [==============================] - 0s 34us/step - loss: 757.7337 - mean_squared_error: 757.7337\n",
      "Epoch 3/20\n",
      "14184/14184 [==============================] - ETA: 0s - loss: 540.2549 - mean_squared_error: 540.25 - 0s 31us/step - loss: 538.2157 - mean_squared_error: 538.2157\n",
      "Epoch 4/20\n",
      "14184/14184 [==============================] - 0s 32us/step - loss: 468.1235 - mean_squared_error: 468.1235\n",
      "Epoch 5/20\n",
      "14184/14184 [==============================] - 1s 48us/step - loss: 422.6891 - mean_squared_error: 422.6891\n",
      "Epoch 6/20\n",
      "14184/14184 [==============================] - 0s 31us/step - loss: 395.6182 - mean_squared_error: 395.6182\n",
      "Epoch 7/20\n",
      "14184/14184 [==============================] - 1s 36us/step - loss: 383.0616 - mean_squared_error: 383.0616\n",
      "Epoch 8/20\n",
      "14184/14184 [==============================] - 0s 30us/step - loss: 370.9658 - mean_squared_error: 370.9658\n",
      "Epoch 9/20\n",
      "14184/14184 [==============================] - 0s 30us/step - loss: 363.0837 - mean_squared_error: 363.0837\n",
      "Epoch 10/20\n",
      "14184/14184 [==============================] - 1s 49us/step - loss: 359.9244 - mean_squared_error: 359.9244\n",
      "Epoch 11/20\n",
      "14184/14184 [==============================] - 1s 50us/step - loss: 350.3550 - mean_squared_error: 350.3550\n",
      "Epoch 12/20\n",
      "14184/14184 [==============================] - 0s 32us/step - loss: 345.2511 - mean_squared_error: 345.2511\n",
      "Epoch 13/20\n",
      "14184/14184 [==============================] - 1s 40us/step - loss: 350.4478 - mean_squared_error: 350.4478\n",
      "Epoch 14/20\n",
      "14184/14184 [==============================] - 0s 33us/step - loss: 338.8827 - mean_squared_error: 338.8827\n",
      "Epoch 15/20\n",
      "14184/14184 [==============================] - 0s 33us/step - loss: 338.9818 - mean_squared_error: 338.9818\n",
      "Epoch 16/20\n",
      "14184/14184 [==============================] - 0s 34us/step - loss: 336.4400 - mean_squared_error: 336.4400\n",
      "Epoch 17/20\n",
      "14184/14184 [==============================] - 1s 42us/step - loss: 339.6565 - mean_squared_error: 339.6565\n",
      "Epoch 18/20\n",
      "14184/14184 [==============================] - 0s 32us/step - loss: 339.1250 - mean_squared_error: 339.1250\n",
      "Epoch 19/20\n",
      "14184/14184 [==============================] - 1s 59us/step - loss: 330.5450 - mean_squared_error: 330.5450\n",
      "Epoch 20/20\n",
      "14184/14184 [==============================] - 1s 41us/step - loss: 339.4278 - mean_squared_error: 339.4278\n"
     ]
    }
   ],
   "source": [
    "lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "\n",
    "#print(tModel.currentModelName)\n",
    "#tModel.getAllModelsDescription()\n",
    "#tModel.getModelDescription('RULModel_CNN_1')\n",
    "#tModel.getModelDescription(tModel.currentModelName)\n",
    "#tModel.getModelDescription()\n",
    "#tModel.setCurrentModel('RULmodel_SN_1')\n",
    "#tModel.getModelDescription()\n",
    "tModel.epochs = 20\n",
    "tModel.trainModel(learningRateScheduler=lrate, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3547/3547 [==============================] - 0s 56us/step\n",
      "scores\n",
      "{'loss': 199.46597253042844, 'score_1': 199.46597253042844, 'rhs': 11209.523105929726}\n",
      "RMSE: 14.12324228109213\n",
      "RHS: 11209.523105929726\n",
      "Time : 23.014435 seconds\n"
     ]
    }
   ],
   "source": [
    "tModel.evaluateModel([\"rhs\"], crossValidation=True)\n",
    "print(\"scores\")\n",
    "\n",
    "cScores = tModel.scores\n",
    "rmse = math.sqrt(cScores['score_1'])\n",
    "rhs = cScores['rhs']\n",
    "time = tModel.trainTime\n",
    "\n",
    "print(cScores)\n",
    "print(\"RMSE: {}\".format(rmse))\n",
    "print(\"RHS: {}\".format(rhs))\n",
    "print(\"Time : {} seconds\".format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_optmize_fun(x, selected_features=['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'htBleed', 'W31', 'W32'], datasetNumber = '1', scaler = None, verbose=0, epochs=250, \n",
    "                  saveToFile = None, iterations = 0):\n",
    "    \n",
    "    #Clear the previous tensorflow graph\n",
    "    K.clear_session()\n",
    "    \n",
    "    #Extract the tunning variables from the input vector\n",
    "    #Round the values to the nearest integer since this implementation is for real numbers\n",
    "    x = x.astype(int)\n",
    "    windows_size = x[0]\n",
    "    window_stride = x[1]\n",
    "    constantRUL = x[2]\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Creating model\")\n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0, beta_1=0.5)\n",
    "    lossFunction = \"mean_squared_error\"\n",
    "    metrics = [\"mse\"]\n",
    "    \n",
    "    #Define the model\n",
    "    nFeatures = len(selected_features)\n",
    "    shapeSN = nFeatures*windows_size\n",
    "    modelRULSN = RULmodel_SN_1(shapeSN)\n",
    "    modelRULSN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "    #load the data using the selected parameters\n",
    "    tModel = TunableModel(selected_features, scaler = min_max_scaler, window_stride = window_stride, \n",
    "                          window_size = windows_size, constRul = constantRUL, datasetNumber = datasetNumber, \n",
    "                         epochs=epochs)\n",
    "    \n",
    "    tModel.loadData()\n",
    "    \n",
    "    #Add the models to the tunableModel object\n",
    "    tModel.addModel(\"RUL_SN_1_optmizable\", modelRULSN)\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Training model\")\n",
    "    #Train the model\n",
    "    lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "    tModel.trainCurrentModel(learningRateScheduler=lrate, verbose=verbose)\n",
    "    time = tModel.getModelTimes(tModel.currentModelName)\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Training time {}\".format(time))\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Assesing model performance\")\n",
    "    #Assess the model performance\n",
    "    tModel.evaluateCurrentModel([\"rhs\"], crossValidation=True)\n",
    "    cScores = tModel.getModelScores(tModel.currentModelName)\n",
    "    rmse = math.sqrt(cScores['score_1'])\n",
    "    rhs = cScores['rhs']\n",
    "    #print(\"The score for this model is: {}\".format(rmse))\n",
    "    \n",
    "    msgStr = \"The model variables are \" + str(x) + \"\\tThe scores are: [RMSE:{:.4f}, RHS:{:.4f}]\\n\".format(rmse, rhs)\n",
    "    \n",
    "    if saveToFile is not None:\n",
    "        #print(msgStr)\n",
    "        saveToFile.write(msgStr)\n",
    "    else:\n",
    "        print(msgStr)\n",
    "    \n",
    "    #Return RMSE as the performance metric to steer the search\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
