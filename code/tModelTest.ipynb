{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Test notebook for the C-MAPPS benchmark. Test the Tunable Model class architecture\n",
    "\n",
    "First we import the necessary packages and create the global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import custom_scores\n",
    "import CMAPSAuxFunctions\n",
    "from tunableModel import TunableModel\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Reshape, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "from scipy.optimize import differential_evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create models\n",
    "\n",
    "Create different types of models to be tested with the Tunable Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clear the previous tensorflow graph\n",
    "K.clear_session()\n",
    "\n",
    "FilterN = 10\n",
    "FilterL = 10\n",
    "\n",
    "def RULmodel_SN_1(input_shape):\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(30, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', name='fc1'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(10, activation='relu', kernel_initializer='glorot_normal', name='fc2'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def RULmodel_SN_2(input_shape):\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Dense(20, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', name='fc1'))\n",
    "    #model.add(Dense(30, input_dim=input_shape, activation='relu', kernel_initializer='glorot_normal', \n",
    "    #                kernel_regularizer=regularizers.l2(0.1), name='fc1'))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def RULModel_CNN_1(input_shape):\n",
    "    \n",
    "    #Create a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    print(input_shape)\n",
    "    \n",
    "    #Add the layers for the model\n",
    "    model.add(Conv2D(1, (FilterN, FilterL), input_shape=input_shape, padding='same', kernel_initializer='glorot_normal', activation='relu', name='cl1'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(MaxPooling2D(pool_size=5, name='pl1'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(20, activation='relu', kernel_initializer='glorot_normal', name='fc1'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear', name='out'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def RULCNNModel(TW, FeatureN):\n",
    "    \n",
    "    input_layer = Input(shape=(TW, FeatureN))\n",
    "    y = Reshape((TW, FeatureN, 1), input_shape=(TW, FeatureN, ),name = 'Reshape')(input_layer)\n",
    "\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C1')(y)\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C2')(y)\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C3')(y)\n",
    "    y = Conv2D(FilterN, FilterL, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='C4')(y)\n",
    "    #y = Convolution2D(FilterN, FilterL, 1, border_mode='same', init='glorot_normal', activation='tanh', name='C5')(y)\n",
    "    #y = Convolution2D(FilterN, FilterL, 1, border_mode='same', init='glorot_normal', activation='tanh', name='C6')(y)\n",
    "    \n",
    "    y = Conv2D(1, 3, 1, border_mode='same', kernel_initializer='glorot_normal', activation='tanh', name='Clast')(y)  \n",
    "    \n",
    "    y = Reshape((TW,14))(y)\n",
    "    y = Flatten()(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "    \n",
    "    #y = Dense(100, activation='tanh', init='glorot_normal', activity_regularizer=keras.regularizers.l2(0.01),)(y)\n",
    "    y = Dense(100,activation='tanh', kernel_initializer='glorot_normal', name='fc')(y)\n",
    "    y = Dense(1)(y)\n",
    "    \n",
    "    model = Model(inputs = input_layer, outputs = y, name='RUL_CNN_Model')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', 'BPR', 'htBleed', 'W31', 'W32']\n",
      "Loading data for dataset 1 with window_size of 30, stride of 2 and constRUL of 125. Cros-Validation ratio 0\n",
      "Data loaded for dataset 1\n",
      "Printing shapes\n",
      "\n",
      "Training data (X, y)\n",
      "(8890, 420)\n",
      "(8890,)\n",
      "Testing data (X, y)\n",
      "(100, 420)\n",
      "(100,)\n",
      "Printing first 5 elements\n",
      "\n",
      "Training data (X, y)\n",
      "[[-0.61403509 -0.00691857 -0.39391206 ..., -0.8         0.41463415\n",
      "   0.4921528 ]\n",
      " [-0.24210526 -0.09792443 -0.23156708 ..., -0.4         0.36585366\n",
      "   0.7554042 ]\n",
      " [-0.22807018 -0.37147419 -0.14047351 ..., -0.4         0.02439024\n",
      "   0.19070181]\n",
      " [-0.15087719  0.1325173  -0.52153326 ..., -0.4         0.10569106\n",
      "   0.55078472]\n",
      " [-0.40350877  0.06120277 -0.65546787 ..., -0.4         0.43089431\n",
      "   0.6870003 ]]\n",
      "[ 125.  125.  125.  125.  125.]\n",
      "Testing data (X, y)\n",
      "[[-0.69122807 -0.07344332 -0.62750846 ..., -0.2         0.02439024\n",
      "   0.32691738]\n",
      " [ 0.01754386 -0.03618946 -0.38985344 ..., -0.6         0.02439024\n",
      "   0.05034054]\n",
      " [ 0.11578947 -0.04949441 -0.02773393 ...,  0.2         0.2195122\n",
      "   0.08646728]\n",
      " [-0.17192982  0.21554018 -0.06741826 ...,  0.2        -0.3495935\n",
      "   0.03938407]\n",
      " [-0.08070175  0.29696647 -0.02277339 ...,  0.         -0.07317073\n",
      "   0.49422564]]\n",
      "[ 112.   98.   69.   82.   91.]\n"
     ]
    }
   ],
   "source": [
    "#Shared parameters for the models\n",
    "optimizer = Adam(lr=0, beta_1=0.5)\n",
    "lossFunction = \"mean_squared_error\"\n",
    "metrics = [\"mse\"]\n",
    "\n",
    "#Selected as per CNN paper\n",
    "features = ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30', 'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']\n",
    "\n",
    "selected_indices = np.array([2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21])\n",
    "#selected_indices = np.array([7, 8, 9, 12, 16, 17, 20])\n",
    "#selected_indices = np.array(list(range(1,22)))\n",
    "\n",
    "selected_features = list(features[i] for i in selected_indices-1)\n",
    "\n",
    "print(selected_features)\n",
    "\n",
    "windowSize = 30\n",
    "stride = 2\n",
    "constRUL = 125\n",
    "\n",
    "\n",
    "dataFolder = '../CMAPSSData'\n",
    "\n",
    "#Create and compile the models\n",
    "nFeatures = len(selected_features)\n",
    "shapeSN = nFeatures*windowSize\n",
    "modelRULSN = RULmodel_SN_2(shapeSN)\n",
    "modelRULSN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "tModel = TunableModel('ModelRUL_SN_1', modelRULSN, selected_features, dataFolder, 'keras', window_size=windowSize,\n",
    "                      scaler = min_max_scaler, window_stride=stride, constRul = constRUL)\n",
    "tModel.changeDataset(1)\n",
    "tModel.loadData(verbose=1, rectify_labels = False)\n",
    "tModel.printData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description for model: ModelRUL_SN_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1 (Dense)                  (None, 20)                8420      \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 8,441\n",
      "Trainable params: 8,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#tModel.printData(printTop=False)\n",
    "#tModel.windowSize = 20\n",
    "#tModel.changeDataset(2)\n",
    "#tModel.loadData(verbose=1, crossValRatio=0.1)\n",
    "#tModel.printData(printTop=False)\n",
    "tModel.getModelDescription()\n",
    "#ruldcnn = RULCNNModel(tModel.windowSize, len(selected_features))\n",
    "#ruldcnn.summary()\n",
    "#tModel.trimmedRUL_train\n",
    "#display(tModel.df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model and test some Tunable Model functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8890/8890 [==============================] - 1s 74us/step - loss: 7909.9379 - mean_squared_error: 7909.9379\n",
      "Epoch 2/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 6961.4261 - mean_squared_error: 6961.4261\n",
      "Epoch 3/100\n",
      "8890/8890 [==============================] - 0s 14us/step - loss: 5996.7597 - mean_squared_error: 5996.7597\n",
      "Epoch 4/100\n",
      "8890/8890 [==============================] - 0s 14us/step - loss: 5001.0505 - mean_squared_error: 5001.0505\n",
      "Epoch 5/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 4097.5826 - mean_squared_error: 4097.5826\n",
      "Epoch 6/100\n",
      "8890/8890 [==============================] - 0s 12us/step - loss: 3333.6800 - mean_squared_error: 3333.6800\n",
      "Epoch 7/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 2731.9943 - mean_squared_error: 2731.9943\n",
      "Epoch 8/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 2286.9668 - mean_squared_error: 2286.9668\n",
      "Epoch 9/100\n",
      "8890/8890 [==============================] - 0s 12us/step - loss: 1971.6552 - mean_squared_error: 1971.6552\n",
      "Epoch 10/100\n",
      "8890/8890 [==============================] - 0s 11us/step - loss: 1748.4446 - mean_squared_error: 1748.4446\n",
      "Epoch 11/100\n",
      "8890/8890 [==============================] - 0s 12us/step - loss: 1581.4061 - mean_squared_error: 1581.4061\n",
      "Epoch 12/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 1444.5452 - mean_squared_error: 1444.5452\n",
      "Epoch 13/100\n",
      "8890/8890 [==============================] - 0s 12us/step - loss: 1313.6393 - mean_squared_error: 1313.6393\n",
      "Epoch 14/100\n",
      "8890/8890 [==============================] - 0s 12us/step - loss: 1186.3971 - mean_squared_error: 1186.3971\n",
      "Epoch 15/100\n",
      "8890/8890 [==============================] - 0s 12us/step - loss: 1067.1687 - mean_squared_error: 1067.1687\n",
      "Epoch 16/100\n",
      "8890/8890 [==============================] - 0s 12us/step - loss: 957.3792 - mean_squared_error: 957.3792\n",
      "Epoch 17/100\n",
      "8890/8890 [==============================] - 0s 11us/step - loss: 859.6084 - mean_squared_error: 859.6084\n",
      "Epoch 18/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 773.2953 - mean_squared_error: 773.2953\n",
      "Epoch 19/100\n",
      "8890/8890 [==============================] - 0s 14us/step - loss: 697.8889 - mean_squared_error: 697.8889\n",
      "Epoch 20/100\n",
      "8890/8890 [==============================] - 0s 16us/step - loss: 634.5473 - mean_squared_error: 634.5473\n",
      "Epoch 21/100\n",
      "8890/8890 [==============================] - 0s 14us/step - loss: 581.4441 - mean_squared_error: 581.4441\n",
      "Epoch 22/100\n",
      "8890/8890 [==============================] - 0s 14us/step - loss: 537.8586 - mean_squared_error: 537.8586\n",
      "Epoch 23/100\n",
      "8890/8890 [==============================] - 0s 28us/step - loss: 501.8651 - mean_squared_error: 501.8651\n",
      "Epoch 24/100\n",
      "8890/8890 [==============================] - 0s 19us/step - loss: 472.0082 - mean_squared_error: 472.0082\n",
      "Epoch 25/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 446.3198 - mean_squared_error: 446.3198\n",
      "Epoch 26/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 423.6592 - mean_squared_error: 423.6592\n",
      "Epoch 27/100\n",
      "8890/8890 [==============================] - 0s 28us/step - loss: 403.5634 - mean_squared_error: 403.5634\n",
      "Epoch 28/100\n",
      "8890/8890 [==============================] - 0s 19us/step - loss: 385.2586 - mean_squared_error: 385.2586\n",
      "Epoch 29/100\n",
      "8890/8890 [==============================] - 0s 28us/step - loss: 368.4372 - mean_squared_error: 368.4372\n",
      "Epoch 30/100\n",
      "8890/8890 [==============================] - 0s 18us/step - loss: 351.9216 - mean_squared_error: 351.9216\n",
      "Epoch 31/100\n",
      "8890/8890 [==============================] - 0s 12us/step - loss: 336.5273 - mean_squared_error: 336.5273\n",
      "Epoch 32/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 322.8409 - mean_squared_error: 322.8409\n",
      "Epoch 33/100\n",
      "8890/8890 [==============================] - 0s 15us/step - loss: 310.9757 - mean_squared_error: 310.9757\n",
      "Epoch 34/100\n",
      "8890/8890 [==============================] - 0s 21us/step - loss: 300.3281 - mean_squared_error: 300.3281\n",
      "Epoch 35/100\n",
      "8890/8890 [==============================] - 0s 16us/step - loss: 291.1846 - mean_squared_error: 291.1846\n",
      "Epoch 36/100\n",
      "8890/8890 [==============================] - 0s 12us/step - loss: 283.2205 - mean_squared_error: 283.2205\n",
      "Epoch 37/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 276.8364 - mean_squared_error: 276.8364\n",
      "Epoch 38/100\n",
      "8890/8890 [==============================] - 0s 15us/step - loss: 270.9723 - mean_squared_error: 270.9723\n",
      "Epoch 39/100\n",
      "8890/8890 [==============================] - 0s 16us/step - loss: 266.2619 - mean_squared_error: 266.2619\n",
      "Epoch 40/100\n",
      "8890/8890 [==============================] - 0s 16us/step - loss: 262.6066 - mean_squared_error: 262.6066\n",
      "Epoch 41/100\n",
      "8890/8890 [==============================] - 0s 17us/step - loss: 258.8475 - mean_squared_error: 258.8475\n",
      "Epoch 42/100\n",
      "8890/8890 [==============================] - 0s 15us/step - loss: 255.6879 - mean_squared_error: 255.6879\n",
      "Epoch 43/100\n",
      "8890/8890 [==============================] - 0s 17us/step - loss: 253.0832 - mean_squared_error: 253.0832\n",
      "Epoch 44/100\n",
      "8890/8890 [==============================] - 0s 12us/step - loss: 250.8612 - mean_squared_error: 250.8612\n",
      "Epoch 45/100\n",
      "8890/8890 [==============================] - 0s 27us/step - loss: 248.8709 - mean_squared_error: 248.8709\n",
      "Epoch 46/100\n",
      "8890/8890 [==============================] - 0s 14us/step - loss: 246.7939 - mean_squared_error: 246.7939\n",
      "Epoch 47/100\n",
      "8890/8890 [==============================] - 0s 12us/step - loss: 244.8674 - mean_squared_error: 244.8674\n",
      "Epoch 48/100\n",
      "8890/8890 [==============================] - 0s 18us/step - loss: 243.5170 - mean_squared_error: 243.5170\n",
      "Epoch 49/100\n",
      "8890/8890 [==============================] - 0s 22us/step - loss: 242.1497 - mean_squared_error: 242.1497\n",
      "Epoch 50/100\n",
      "8890/8890 [==============================] - ETA: 0s - loss: 240.7089 - mean_squared_error: 240.70 - 0s 14us/step - loss: 240.8786 - mean_squared_error: 240.8786\n",
      "Epoch 51/100\n",
      "8890/8890 [==============================] - 0s 16us/step - loss: 239.4730 - mean_squared_error: 239.4730\n",
      "Epoch 52/100\n",
      "8890/8890 [==============================] - 0s 30us/step - loss: 238.2799 - mean_squared_error: 238.2799\n",
      "Epoch 53/100\n",
      "8890/8890 [==============================] - 0s 15us/step - loss: 237.0605 - mean_squared_error: 237.0605\n",
      "Epoch 54/100\n",
      "8890/8890 [==============================] - 0s 11us/step - loss: 236.4708 - mean_squared_error: 236.4708\n",
      "Epoch 55/100\n",
      "8890/8890 [==============================] - 0s 19us/step - loss: 235.1519 - mean_squared_error: 235.1519\n",
      "Epoch 56/100\n",
      "8890/8890 [==============================] - 0s 25us/step - loss: 234.3957 - mean_squared_error: 234.3957\n",
      "Epoch 57/100\n",
      "8890/8890 [==============================] - 0s 22us/step - loss: 233.6190 - mean_squared_error: 233.6190\n",
      "Epoch 58/100\n",
      "8890/8890 [==============================] - 0s 15us/step - loss: 232.4268 - mean_squared_error: 232.4268\n",
      "Epoch 59/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 231.8329 - mean_squared_error: 231.8329\n",
      "Epoch 60/100\n",
      "8890/8890 [==============================] - 0s 26us/step - loss: 230.9722 - mean_squared_error: 230.9722\n",
      "Epoch 61/100\n",
      "8890/8890 [==============================] - 0s 26us/step - loss: 230.6616 - mean_squared_error: 230.6616\n",
      "Epoch 62/100\n",
      "8890/8890 [==============================] - 0s 27us/step - loss: 229.6393 - mean_squared_error: 229.6393\n",
      "Epoch 63/100\n",
      "8890/8890 [==============================] - 0s 24us/step - loss: 228.9219 - mean_squared_error: 228.9219\n",
      "Epoch 64/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 228.1280 - mean_squared_error: 228.1280\n",
      "Epoch 65/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 227.4068 - mean_squared_error: 227.4068\n",
      "Epoch 66/100\n",
      "8890/8890 [==============================] - 0s 15us/step - loss: 226.7269 - mean_squared_error: 226.7269\n",
      "Epoch 67/100\n",
      "8890/8890 [==============================] - 0s 33us/step - loss: 226.1006 - mean_squared_error: 226.1006\n",
      "Epoch 68/100\n",
      "8890/8890 [==============================] - 0s 28us/step - loss: 225.5597 - mean_squared_error: 225.5597\n",
      "Epoch 69/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 225.1463 - mean_squared_error: 225.1463\n",
      "Epoch 70/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 224.2382 - mean_squared_error: 224.2382\n",
      "Epoch 71/100\n",
      "8890/8890 [==============================] - 0s 10us/step - loss: 223.8308 - mean_squared_error: 223.8308\n",
      "Epoch 72/100\n",
      "8890/8890 [==============================] - 0s 36us/step - loss: 222.8160 - mean_squared_error: 222.8160\n",
      "Epoch 73/100\n",
      "8890/8890 [==============================] - 0s 27us/step - loss: 222.7555 - mean_squared_error: 222.7555\n",
      "Epoch 74/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 222.2122 - mean_squared_error: 222.2122\n",
      "Epoch 75/100\n",
      "8890/8890 [==============================] - 0s 11us/step - loss: 221.4950 - mean_squared_error: 221.4950\n",
      "Epoch 76/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 220.6527 - mean_squared_error: 220.6527\n",
      "Epoch 77/100\n",
      "8890/8890 [==============================] - 0s 12us/step - loss: 220.0833 - mean_squared_error: 220.0833\n",
      "Epoch 78/100\n",
      "8890/8890 [==============================] - 0s 47us/step - loss: 219.6308 - mean_squared_error: 219.6308\n",
      "Epoch 79/100\n",
      "8890/8890 [==============================] - 0s 25us/step - loss: 219.1254 - mean_squared_error: 219.1254\n",
      "Epoch 80/100\n",
      "8890/8890 [==============================] - 0s 14us/step - loss: 218.6041 - mean_squared_error: 218.6041\n",
      "Epoch 81/100\n",
      "8890/8890 [==============================] - 0s 15us/step - loss: 218.1391 - mean_squared_error: 218.1391\n",
      "Epoch 82/100\n",
      "8890/8890 [==============================] - 0s 18us/step - loss: 217.5552 - mean_squared_error: 217.5552\n",
      "Epoch 83/100\n",
      "8890/8890 [==============================] - 0s 23us/step - loss: 217.2812 - mean_squared_error: 217.2812\n",
      "Epoch 84/100\n",
      "8890/8890 [==============================] - 0s 17us/step - loss: 216.4517 - mean_squared_error: 216.4517\n",
      "Epoch 85/100\n",
      "8890/8890 [==============================] - 0s 14us/step - loss: 215.9916 - mean_squared_error: 215.9916\n",
      "Epoch 86/100\n",
      "8890/8890 [==============================] - 0s 14us/step - loss: 215.4592 - mean_squared_error: 215.4592\n",
      "Epoch 87/100\n",
      "8890/8890 [==============================] - 0s 31us/step - loss: 215.2636 - mean_squared_error: 215.2636\n",
      "Epoch 88/100\n",
      "8890/8890 [==============================] - 0s 16us/step - loss: 214.2928 - mean_squared_error: 214.2928\n",
      "Epoch 89/100\n",
      "8890/8890 [==============================] - 0s 27us/step - loss: 213.7521 - mean_squared_error: 213.7521\n",
      "Epoch 90/100\n",
      "8890/8890 [==============================] - 0s 36us/step - loss: 213.1103 - mean_squared_error: 213.1103\n",
      "Epoch 91/100\n",
      "8890/8890 [==============================] - 0s 38us/step - loss: 212.4034 - mean_squared_error: 212.4034\n",
      "Epoch 92/100\n",
      "8890/8890 [==============================] - 0s 26us/step - loss: 212.5339 - mean_squared_error: 212.5339\n",
      "Epoch 93/100\n",
      "8890/8890 [==============================] - 0s 16us/step - loss: 211.6669 - mean_squared_error: 211.6669\n",
      "Epoch 94/100\n",
      "8890/8890 [==============================] - 0s 22us/step - loss: 210.9988 - mean_squared_error: 210.9988\n",
      "Epoch 95/100\n",
      "8890/8890 [==============================] - 0s 14us/step - loss: 210.5094 - mean_squared_error: 210.5094\n",
      "Epoch 96/100\n",
      "8890/8890 [==============================] - 0s 27us/step - loss: 210.2083 - mean_squared_error: 210.2083\n",
      "Epoch 97/100\n",
      "8890/8890 [==============================] - 0s 15us/step - loss: 210.1251 - mean_squared_error: 210.1251\n",
      "Epoch 98/100\n",
      "8890/8890 [==============================] - 0s 13us/step - loss: 209.5061 - mean_squared_error: 209.5061\n",
      "Epoch 99/100\n",
      "8890/8890 [==============================] - 0s 12us/step - loss: 209.0789 - mean_squared_error: 209.0789\n",
      "Epoch 100/100\n",
      "8890/8890 [==============================] - 0s 12us/step - loss: 208.7246 - mean_squared_error: 208.7246\n"
     ]
    }
   ],
   "source": [
    "lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "#lrate = None\n",
    "\n",
    "#print(tModel.currentModelName)\n",
    "#tModel.getAllModelsDescription()\n",
    "#tModel.getModelDescription('RULModel_CNN_1')\n",
    "#tModel.getModelDescription(tModel.currentModelName)\n",
    "#tModel.getModelDescription()\n",
    "#tModel.setCurrentModel('RULmodel_SN_1')\n",
    "#tModel.getModelDescription()\n",
    "#Create and compile the models\n",
    "nFeatures = len(selected_features)\n",
    "shapeSN = nFeatures*windowSize\n",
    "modelRULSN = RULmodel_SN_2(shapeSN)\n",
    "modelRULSN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "tModel.changeModel('ModelRUL_SN_1', modelRULSN, 'keras')\n",
    "tModel.epochs = 100\n",
    "tModel.trainModel(learningRateScheduler=lrate, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 255us/step\n",
      "limits\n",
      "[  0.  16.  -8.   7.  11.  12.  15.  -5.   5. -10.  -5. -23. -10.   3.  26.\n",
      "  20.   9.  -4.   9.  -9.  33.  13.   8. -13. -29.  -8.  38.  10.  14. -13.\n",
      "  -1.   5.  -4.   0.   9.   4.   9.  11. -17.   3.  -4.  -3.  15.  -8. -34.\n",
      "  -2. -26.  11. -11.  22. -11.  -7.   4.  16. -25.  10.  -4.  22. -12.   5.\n",
      " -14.  -7.   9.  -6.  -9.  -1.  48.  -1.  -5.  -6. -10.  23. -27. -23.  -5.\n",
      "  -3.   8.  36.  35.   4.   1.  -2.  -9.  22.  15.  21.  -5.  -1. -27.  -3.\n",
      "  -7.   7. -41.  16. -17. -43.   2.   8.  -6. -13.]\n",
      "scores\n",
      "Engine 1, RUL [ 112.09597015], Rounded RUL 112.0, Real RUL 112.0\n",
      "Engine 2, RUL [ 114.98062897], Rounded RUL 114.0, Real RUL 98.0\n",
      "Engine 3, RUL [ 61.13838577], Rounded RUL 61.0, Real RUL 69.0\n",
      "Engine 4, RUL [ 89.6437912], Rounded RUL 89.0, Real RUL 82.0\n",
      "Engine 5, RUL [ 102.12400055], Rounded RUL 102.0, Real RUL 91.0\n",
      "Engine 6, RUL [ 105.61565399], Rounded RUL 105.0, Real RUL 93.0\n",
      "Engine 7, RUL [ 106.07927704], Rounded RUL 106.0, Real RUL 91.0\n",
      "Engine 8, RUL [ 90.37837982], Rounded RUL 90.0, Real RUL 95.0\n",
      "Engine 9, RUL [ 116.5294342], Rounded RUL 116.0, Real RUL 111.0\n",
      "Engine 10, RUL [ 86.42476654], Rounded RUL 86.0, Real RUL 96.0\n",
      "Engine 11, RUL [ 92.6919632], Rounded RUL 92.0, Real RUL 97.0\n",
      "Engine 12, RUL [ 101.47112274], Rounded RUL 101.0, Real RUL 124.0\n",
      "Engine 13, RUL [ 85.14214325], Rounded RUL 85.0, Real RUL 95.0\n",
      "Engine 14, RUL [ 110.70761871], Rounded RUL 110.0, Real RUL 107.0\n",
      "Engine 15, RUL [ 109.06583405], Rounded RUL 109.0, Real RUL 83.0\n",
      "Engine 16, RUL [ 104.75893402], Rounded RUL 104.0, Real RUL 84.0\n",
      "Engine 17, RUL [ 59.88967514], Rounded RUL 59.0, Real RUL 50.0\n",
      "Engine 18, RUL [ 24.96191788], Rounded RUL 24.0, Real RUL 28.0\n",
      "Engine 19, RUL [ 96.50554657], Rounded RUL 96.0, Real RUL 87.0\n",
      "Engine 20, RUL [ 6.05144691], Rounded RUL 7.0, Real RUL 16.0\n",
      "Engine 21, RUL [ 90.40208435], Rounded RUL 90.0, Real RUL 57.0\n",
      "Engine 22, RUL [ 124.10237885], Rounded RUL 124.0, Real RUL 111.0\n",
      "Engine 23, RUL [ 121.5351944], Rounded RUL 121.0, Real RUL 113.0\n",
      "Engine 24, RUL [-0.05641058], Rounded RUL 7.0, Real RUL 20.0\n",
      "Engine 25, RUL [ 116.35678864], Rounded RUL 116.0, Real RUL 145.0\n",
      "Engine 26, RUL [ 111.03781891], Rounded RUL 111.0, Real RUL 119.0\n",
      "Engine 27, RUL [ 104.25057983], Rounded RUL 104.0, Real RUL 66.0\n",
      "Engine 28, RUL [ 107.27584076], Rounded RUL 107.0, Real RUL 97.0\n",
      "Engine 29, RUL [ 104.16306305], Rounded RUL 104.0, Real RUL 90.0\n",
      "Engine 30, RUL [ 102.65923309], Rounded RUL 102.0, Real RUL 115.0\n",
      "Engine 31, RUL [ 7.75985479], Rounded RUL 7.0, Real RUL 8.0\n",
      "Engine 32, RUL [ 53.07660675], Rounded RUL 53.0, Real RUL 48.0\n",
      "Engine 33, RUL [ 102.79889679], Rounded RUL 102.0, Real RUL 106.0\n",
      "Engine 34, RUL [-17.98397255], Rounded RUL 7.0, Real RUL 7.0\n",
      "Engine 35, RUL [ 20.45234871], Rounded RUL 20.0, Real RUL 11.0\n",
      "Engine 36, RUL [ 23.1600914], Rounded RUL 23.0, Real RUL 19.0\n",
      "Engine 37, RUL [ 30.03309059], Rounded RUL 30.0, Real RUL 21.0\n",
      "Engine 38, RUL [ 61.53653717], Rounded RUL 61.0, Real RUL 50.0\n",
      "Engine 39, RUL [ 125.70179749], Rounded RUL 125.0, Real RUL 142.0\n",
      "Engine 40, RUL [ 31.23425865], Rounded RUL 31.0, Real RUL 28.0\n",
      "Engine 41, RUL [ 14.58670044], Rounded RUL 14.0, Real RUL 18.0\n",
      "Engine 42, RUL [-24.04236794], Rounded RUL 7.0, Real RUL 10.0\n",
      "Engine 43, RUL [ 74.52222443], Rounded RUL 74.0, Real RUL 59.0\n",
      "Engine 44, RUL [ 101.2229538], Rounded RUL 101.0, Real RUL 109.0\n",
      "Engine 45, RUL [ 80.99051666], Rounded RUL 80.0, Real RUL 114.0\n",
      "Engine 46, RUL [ 45.69776917], Rounded RUL 45.0, Real RUL 47.0\n",
      "Engine 47, RUL [ 109.70919037], Rounded RUL 109.0, Real RUL 135.0\n",
      "Engine 48, RUL [ 103.38038635], Rounded RUL 103.0, Real RUL 92.0\n",
      "Engine 49, RUL [ 10.49051476], Rounded RUL 10.0, Real RUL 21.0\n",
      "Engine 50, RUL [ 101.75536346], Rounded RUL 101.0, Real RUL 79.0\n",
      "Engine 51, RUL [ 103.25442505], Rounded RUL 103.0, Real RUL 114.0\n",
      "Engine 52, RUL [ 22.37379646], Rounded RUL 22.0, Real RUL 29.0\n",
      "Engine 53, RUL [ 30.5907402], Rounded RUL 30.0, Real RUL 26.0\n",
      "Engine 54, RUL [ 113.06076813], Rounded RUL 113.0, Real RUL 97.0\n",
      "Engine 55, RUL [ 112.6749115], Rounded RUL 112.0, Real RUL 137.0\n",
      "Engine 56, RUL [ 25.51041603], Rounded RUL 25.0, Real RUL 15.0\n",
      "Engine 57, RUL [ 99.88402557], Rounded RUL 99.0, Real RUL 103.0\n",
      "Engine 58, RUL [ 59.24208069], Rounded RUL 59.0, Real RUL 37.0\n",
      "Engine 59, RUL [ 102.84668732], Rounded RUL 102.0, Real RUL 114.0\n",
      "Engine 60, RUL [ 105.34845734], Rounded RUL 105.0, Real RUL 100.0\n",
      "Engine 61, RUL [ 6.01569366], Rounded RUL 7.0, Real RUL 21.0\n",
      "Engine 62, RUL [ 47.51390839], Rounded RUL 47.0, Real RUL 54.0\n",
      "Engine 63, RUL [ 81.5185318], Rounded RUL 81.0, Real RUL 72.0\n",
      "Engine 64, RUL [ 22.53077126], Rounded RUL 22.0, Real RUL 28.0\n",
      "Engine 65, RUL [ 119.14234161], Rounded RUL 119.0, Real RUL 128.0\n",
      "Engine 66, RUL [ 13.04767418], Rounded RUL 13.0, Real RUL 14.0\n",
      "Engine 67, RUL [ 125.0276413], Rounded RUL 125.0, Real RUL 77.0\n",
      "Engine 68, RUL [-1.47484994], Rounded RUL 7.0, Real RUL 8.0\n",
      "Engine 69, RUL [ 116.56835938], Rounded RUL 116.0, Real RUL 121.0\n",
      "Engine 70, RUL [ 88.54787445], Rounded RUL 88.0, Real RUL 94.0\n",
      "Engine 71, RUL [ 108.41495514], Rounded RUL 108.0, Real RUL 118.0\n",
      "Engine 72, RUL [ 73.75984955], Rounded RUL 73.0, Real RUL 50.0\n",
      "Engine 73, RUL [ 104.12935638], Rounded RUL 104.0, Real RUL 131.0\n",
      "Engine 74, RUL [ 103.19806671], Rounded RUL 103.0, Real RUL 126.0\n",
      "Engine 75, RUL [ 108.00786591], Rounded RUL 108.0, Real RUL 113.0\n",
      "Engine 76, RUL [ 3.85701919], Rounded RUL 7.0, Real RUL 10.0\n",
      "Engine 77, RUL [ 42.23910522], Rounded RUL 42.0, Real RUL 34.0\n",
      "Engine 78, RUL [ 143.08966064], Rounded RUL 143.0, Real RUL 107.0\n",
      "Engine 79, RUL [ 98.13866425], Rounded RUL 98.0, Real RUL 63.0\n",
      "Engine 80, RUL [ 94.04663849], Rounded RUL 94.0, Real RUL 90.0\n",
      "Engine 81, RUL [ 9.31724358], Rounded RUL 9.0, Real RUL 8.0\n",
      "Engine 82, RUL [-11.63832664], Rounded RUL 7.0, Real RUL 9.0\n",
      "Engine 83, RUL [ 128.62451172], Rounded RUL 128.0, Real RUL 137.0\n",
      "Engine 84, RUL [ 80.81678772], Rounded RUL 80.0, Real RUL 58.0\n",
      "Engine 85, RUL [ 133.47654724], Rounded RUL 133.0, Real RUL 118.0\n",
      "Engine 86, RUL [ 110.59143829], Rounded RUL 110.0, Real RUL 89.0\n",
      "Engine 87, RUL [ 111.65113068], Rounded RUL 111.0, Real RUL 116.0\n",
      "Engine 88, RUL [ 114.18558502], Rounded RUL 114.0, Real RUL 115.0\n",
      "Engine 89, RUL [ 109.54380798], Rounded RUL 109.0, Real RUL 136.0\n",
      "Engine 90, RUL [ 25.29687691], Rounded RUL 25.0, Real RUL 28.0\n",
      "Engine 91, RUL [ 31.22451019], Rounded RUL 31.0, Real RUL 38.0\n",
      "Engine 92, RUL [ 27.96838951], Rounded RUL 27.0, Real RUL 20.0\n",
      "Engine 93, RUL [ 44.03593445], Rounded RUL 44.0, Real RUL 85.0\n",
      "Engine 94, RUL [ 71.82382202], Rounded RUL 71.0, Real RUL 55.0\n",
      "Engine 95, RUL [ 111.08158875], Rounded RUL 111.0, Real RUL 128.0\n",
      "Engine 96, RUL [ 94.53353882], Rounded RUL 94.0, Real RUL 137.0\n",
      "Engine 97, RUL [ 84.14319611], Rounded RUL 84.0, Real RUL 82.0\n",
      "Engine 98, RUL [ 67.63722992], Rounded RUL 67.0, Real RUL 59.0\n",
      "Engine 99, RUL [ 111.02549744], Rounded RUL 111.0, Real RUL 117.0\n",
      "Engine 100, RUL [-2.00359607], Rounded RUL 7.0, Real RUL 20.0\n",
      "{'loss': 293.95393615722656, 'score_1': 293.95393615722656, 'rhs': 514.80665067617804, 'rmse': 16.260688792299053}\n",
      "RMSE: 17.145084897929976\n",
      "RMSE2: 16.260688792299053\n",
      "RHS: 514.806650676178\n",
      "Time : 19.466857 seconds\n"
     ]
    }
   ],
   "source": [
    "tModel.evaluateModel([\"rhs\"], round=2, setLimits=[7,145])\n",
    "print(\"scores\")\n",
    "\n",
    "#print(tModel.y_pred)\n",
    "\n",
    "cScores = tModel.scores\n",
    "rmse = math.sqrt(cScores['score_1'])\n",
    "rmse2 = cScores['rmse']\n",
    "rhs = cScores['rhs']\n",
    "time = tModel.trainTime\n",
    "\n",
    "i = 1\n",
    "for prediction in tModel.y_pred:\n",
    "    print('Engine {}, RUL {}, Rounded RUL {}, Real RUL {}'.format(i, prediction, \n",
    "                                                                    tModel.y_pred_rectified[i-1], \n",
    "                                                                    tModel.y_test[i-1]))\n",
    "    i = i+1\n",
    "\n",
    "print(cScores)\n",
    "print(\"RMSE: {}\".format(rmse))\n",
    "print(\"RMSE2: {}\".format(rmse2))\n",
    "print(\"RHS: {}\".format(rhs))\n",
    "print(\"Time : {} seconds\".format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_optmize_fun(x, selected_features=['T24', 'T30', 'T50', 'P30', 'Nf', 'Nc', 'Ps30', 'phi', 'NRf', 'NRc', \n",
    "                     'BPR', 'htBleed', 'W31', 'W32'], datasetNumber = '1', scaler = None, verbose=0, epochs=250, \n",
    "                  saveToFile = None, iterations = 0):\n",
    "    \n",
    "    #Clear the previous tensorflow graph\n",
    "    K.clear_session()\n",
    "    \n",
    "    #Extract the tunning variables from the input vector\n",
    "    #Round the values to the nearest integer since this implementation is for real numbers\n",
    "    x = x.astype(int)\n",
    "    windows_size = x[0]\n",
    "    window_stride = x[1]\n",
    "    constantRUL = x[2]\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Creating model\")\n",
    "    #Shared parameters for the models\n",
    "    optimizer = Adam(lr=0, beta_1=0.5)\n",
    "    lossFunction = \"mean_squared_error\"\n",
    "    metrics = [\"mse\"]\n",
    "    \n",
    "    #Define the model\n",
    "    nFeatures = len(selected_features)\n",
    "    shapeSN = nFeatures*windows_size\n",
    "    modelRULSN = RULmodel_SN_1(shapeSN)\n",
    "    modelRULSN.compile(optimizer = optimizer, loss = lossFunction, metrics = metrics)\n",
    "\n",
    "    #load the data using the selected parameters\n",
    "    tModel = TunableModel(selected_features, scaler = min_max_scaler, window_stride = window_stride, \n",
    "                          window_size = windows_size, constRul = constantRUL, datasetNumber = datasetNumber, \n",
    "                         epochs=epochs)\n",
    "    \n",
    "    tModel.loadData()\n",
    "    \n",
    "    #Add the models to the tunableModel object\n",
    "    tModel.addModel(\"RUL_SN_1_optmizable\", modelRULSN)\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Training model\")\n",
    "    #Train the model\n",
    "    lrate = LearningRateScheduler(CMAPSAuxFunctions.step_decay)\n",
    "    tModel.trainCurrentModel(learningRateScheduler=lrate, verbose=verbose)\n",
    "    time = tModel.getModelTimes(tModel.currentModelName)\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Training time {}\".format(time))\n",
    "    \n",
    "    if iterations == 0:\n",
    "        print(\"Assesing model performance\")\n",
    "    #Assess the model performance\n",
    "    tModel.evaluateCurrentModel([\"rhs\"], crossValidation=True)\n",
    "    cScores = tModel.getModelScores(tModel.currentModelName)\n",
    "    rmse = math.sqrt(cScores['score_1'])\n",
    "    rhs = cScores['rhs']\n",
    "    #print(\"The score for this model is: {}\".format(rmse))\n",
    "    \n",
    "    msgStr = \"The model variables are \" + str(x) + \"\\tThe scores are: [RMSE:{:.4f}, RHS:{:.4f}]\\n\".format(rmse, rhs)\n",
    "    \n",
    "    if saveToFile is not None:\n",
    "        #print(msgStr)\n",
    "        saveToFile.write(msgStr)\n",
    "    else:\n",
    "        print(msgStr)\n",
    "    \n",
    "    #Return RMSE as the performance metric to steer the search\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotRUL(cycles, rulArray, engineUnit):\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.plot(cycles, rulArray, 'bo-', label='RUL')\n",
    "    plt.xlabel(\"Time (Cycle)\")\n",
    "    plt.ylabel(\"RUL\")\n",
    "    plt.title(\"Test Engine Unit #{}\".format(engineUnit))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def plotRUL_Engine(tModel, engineUnit, selectedFeatures, time_window, constRUL, stride, y_test):\n",
    "\n",
    "    df = tModel.df_test\n",
    "    df_engine = df[df['Unit Number'] == engineUnit]\n",
    "    \n",
    "    X_test2, _, _, _ = CMAPSAuxFunctions.create_windowed_data(df_engine, selected_features, 'test', time_window=time_window, \n",
    "                                                     constRUL=constRUL, stride=stride)\n",
    "    \n",
    "    X_test2 = tModel.dataScaler.transform(X_test2)\n",
    "    nnPred = tModel.model.predict(X_test2)\n",
    "    \n",
    "    maxCycle = X_test2.shape[0]\n",
    "    faultCycle = tModel.y_test[engineUnit-1]\n",
    "    cycles = np.arange(maxCycle)\n",
    "    rulArray = np.arange(faultCycle, maxCycle+faultCycle)\n",
    "    rulArray[rulArray > constRUL] = constRUL\n",
    "    rulArray = np.flipud(rulArray)\n",
    "    \n",
    "    plotRUL(cycles, rulArray, engineUnit)\n",
    "    plt.plot(cycles, nnPred, 'go-', label='NN Pred')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotRUL_Engine(tModel, engineUnit, selectedFeatures, time_window, stride, constRUL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2  16 -10   6   9  11  17  -5   4  -9  -5 -21 -10   2  27  22  10  -3\n",
      "  11  -9  35  13  10 -13 -28  -6  39   9  16 -14  -1   3  -5   0   5   4\n",
      "   9  12 -13   2  -4  -3  15  -9 -34   0 -27  11  -9  23 -11  -6   6  17\n",
      " -23  12  -4  20 -11   3 -14  -6   8  -7  -9  -4  50  -1  -5  -6  -8  24\n",
      " -26 -24  -4  -3   7  36  35   3  -1  -2  -7  21  14  21  -2  -2 -27  -4\n",
      "  -7   7 -44  16 -16 -45   5   8  -9 -13]\n",
      "[   4  256  100   36   81  121  289   25   16   81   25  441  100    4  729\n",
      "  484  100    9  121   81 1225  169  100  169  784   36 1521   81  256  196\n",
      "    1    9   25    0   25   16   81  144  169    4   16    9  225   81 1156\n",
      "    0  729  121   81  529  121   36   36  289  529  144   16  400  121    9\n",
      "  196   36   64   49   81   16 2500    1   25   36   64  576  676  576   16\n",
      "    9   49 1296 1225    9    1    4   49  441  196  441    4    4  729   16\n",
      "   49   49 1936  256  256 2025   25   64   81  169]\n",
      "27057\n",
      "16.44901212839239\n"
     ]
    }
   ],
   "source": [
    "l = np.array([  2,  16, -10,   6,   9,  11,  17,  -5,   4,  -9,  -5, -21, -10,   2,  27,\n",
    "  22,  10,  -3,  11,  -9,  35,  13,  10, -13, -28,  -6,  39,   9,  16, -14,\n",
    "  -1,   3,  -5,   0,   5,   4,   9,  12, -13,   2,  -4,  -3,  15,  -9, -34,\n",
    "   0, -27,  11,  -9,  23, -11,  -6,   6,  17, -23,  12,  -4,  20, -11,   3,\n",
    " -14,  -6,   8,  -7,  -9,  -4,  50,  -1,  -5,  -6,  -8,  24, -26, -24,  -4,\n",
    "  -3,   7,  36,  35,   3,  -1,  -2,  -7,  21,  14,  21,  -2,  -2, -27,  -4,\n",
    "  -7,   7, -44,  16, -16, -45,   5,   8,  -9, -13])\n",
    "\n",
    "print(l)\n",
    "l2 = l**2\n",
    "print(l2)\n",
    "suma = np.sum(l2)\n",
    "print(suma)\n",
    "r2 = math.sqrt(suma/100)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
